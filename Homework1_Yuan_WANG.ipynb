{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Homework1_Yuan_WANG.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f0ea6c7499794e859029ffa423d8d655": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fe11a8049c4548d7beaf08cdc95e8f5d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_79acd213907e4660a3fe3757cc054be3",
              "IPY_MODEL_bbf912265e6a404699865e7c8309b639"
            ]
          }
        },
        "fe11a8049c4548d7beaf08cdc95e8f5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "79acd213907e4660a3fe3757cc054be3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ed6cc448084244c5a518ea052e7c3023",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a31c3e9863e14196b2bbe8c6f9dc7c26"
          }
        },
        "bbf912265e6a404699865e7c8309b639": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bf6eec1c1c384b738653ee8d4a1ab55a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:30&lt;00:00, 16565255.98it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_02f352f664bd4747a267cdd258cd2c42"
          }
        },
        "ed6cc448084244c5a518ea052e7c3023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a31c3e9863e14196b2bbe8c6f9dc7c26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf6eec1c1c384b738653ee8d4a1ab55a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "02f352f664bd4747a267cdd258cd2c42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_LTBtfMBvW_"
      },
      "source": [
        "# Machine Learning II: Deep Learning and Applications\n",
        "# Homework 1\n",
        "\n",
        "**Due date: Feb 15**\n",
        "\n",
        "### Instructions\n",
        "- Make a copy of this notebook in your own Colab and complete the questions there.\n",
        "- You can add more cells if necessary. You may also add descriptions to your code, though it is not mandatory.\n",
        "- Make sure the notebook can run through by *Runtime -> Run all*. **Keep all cell outputs** for grading.\n",
        "- Submit the link of your notebook [here](https://docs.google.com/forms/d/e/1FAIpQLSfLdYWxbNatd0cYDPfivw0TYYxFbp3j2zXF_Ymwb2QgHfasOw/viewform?usp=pp_url). Please **enable editing or comments** so that you can receive feedback from TAs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T33dD1e8tii2"
      },
      "source": [
        "Install PyTorch and TorchVision."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJB3VQYDCUmh"
      },
      "source": [
        "!pip install -q torch torchvision torchtext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3l_Dl6qxCXmv"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "from torchvision import transforms"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uevQtU7NtZ_-"
      },
      "source": [
        "## 1. Tensor Operations (30 points) I would maybe add a section with an exercise about torch.scatter and torch.gather\n",
        "\n",
        "Tensor operations are important in deep learning models. In this part, you are required to implement some common tensor operations in PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DeQOItkeQCx"
      },
      "source": [
        "### 1) Tensor squeezing, unsqueezing and viewing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAOmBE5ODwpP"
      },
      "source": [
        "Tensor squeezing, unsqueezing and viewing are important methods to change the dimension of a Tensor, and the corresponding functions are [torch.squeeze](https://pytorch.org/docs/stable/torch.html#torch.squeeze), [torch.unsqueeze](https://pytorch.org/docs/stable/torch.html#torch.unsqueeze) and [torch.Tensor.view](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view). Please read the documents of the functions, and finish the following practice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVrM80YxFSjb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f18ecf3f-07b2-417e-ee0f-d77f207116da"
      },
      "source": [
        "# x is a tensor with size being (3, 2)\n",
        "x = torch.Tensor([[1, 2], [3, 4], [5, 6]])\n",
        "\n",
        "# Add two new dimensions to x by using the function torch.unsqueeze, so that the size of x becomes (3, 1, 2, 1).\n",
        "x=x.unsqueeze(1).unsqueeze(3)\n",
        "print(x.size())\n",
        "\n",
        "# Remove the two dimensions justed added by using the function torch.squeeze, and change the size of x back to (3, 2).\n",
        "x=x.squeeze(1).squeeze(2)\n",
        "print(x.size())\n",
        "\n",
        "# x is now a two-dimensional tensor, or in other words a matrix. Now use the function torch.Tensor.view and change x to a one-dimensional vector with size being (6).\n",
        "y=x.view(-1)\n",
        "print(y.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 1, 2, 1])\n",
            "torch.Size([3, 2])\n",
            "torch.Size([6])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liuR-U0wea0n"
      },
      "source": [
        "### 2) Tensor concatenation and stack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkbnt6v8Bo-j"
      },
      "source": [
        "Tensor concatenation and stack are operations to combine small tensors into big tensors. The corresponding functions are [torch.cat](https://pytorch.org/docs/stable/torch.html#torch.cat) and [torch.stack](https://pytorch.org/docs/stable/torch.html#torch.stack). Please read the documents of the functions, and finish the following practice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9KqXu3Stfjh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63d4b324-ee94-464a-a768-7f6453694f53"
      },
      "source": [
        "# x is a tensor with size being (3, 2)\n",
        "x = torch.Tensor([[1, 2], [3, 4], [5, 6]])\n",
        "\n",
        "# y is a tensor with size being (3, 2)\n",
        "y = torch.Tensor([[-1, -2], [-3, -4], [-5, -6]])\n",
        "\n",
        "# Our goal is to generate a tensor z with size as (2, 3, 2), and z[0,:,:] = x, z[1,:,:] = y.\n",
        "# Use torch.stack to generate such a z\n",
        "z=torch.stack((x,y),0)\n",
        "print(z)\n",
        "print(z.size())\n",
        "print(z[0,:,:])\n",
        "print(z[1,:,:])\n",
        "\n",
        "# Use torch.cat and torch.unsqueeze to generate such a z\n",
        "y=y.unsqueeze(0)\n",
        "x=x.unsqueeze(0)\n",
        "z_1=torch.cat((x,y),0)\n",
        "print(z_1)\n",
        "print(z_1.size())\n",
        "print(z_1[0,:,:])\n",
        "print(z_1[1,:,:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 1.,  2.],\n",
            "         [ 3.,  4.],\n",
            "         [ 5.,  6.]],\n",
            "\n",
            "        [[-1., -2.],\n",
            "         [-3., -4.],\n",
            "         [-5., -6.]]])\n",
            "torch.Size([2, 3, 2])\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.]])\n",
            "tensor([[-1., -2.],\n",
            "        [-3., -4.],\n",
            "        [-5., -6.]])\n",
            "tensor([[[ 1.,  2.],\n",
            "         [ 3.,  4.],\n",
            "         [ 5.,  6.]],\n",
            "\n",
            "        [[-1., -2.],\n",
            "         [-3., -4.],\n",
            "         [-5., -6.]]])\n",
            "torch.Size([2, 3, 2])\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.]])\n",
            "tensor([[-1., -2.],\n",
            "        [-3., -4.],\n",
            "        [-5., -6.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGw4eEo-eeHm"
      },
      "source": [
        "### 3) Tensor expansion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAII9eJgJFK2"
      },
      "source": [
        "Tensor expansion is to expand a tensor into a larger tensor along singleton dimensions. The corresponding functions are [torch.Tensor.expand](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.expand) and [torch.Tensor.expand_as](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.expand_as). Please read the documents of the functions, and finish the following practice. \n",
        "\n",
        "Finally, explains as a comment in a or two sentence what the differences between the following functions are:\n",
        "```\n",
        "torch.Tensor.view()\n",
        "torch.Tensor.expand()\n",
        "torch.Tensor.reshape()\n",
        "torch.Tensor.repeat()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQbFte-AJzVL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdd24331-eea6-4d24-bede-7a3c2f4f560d"
      },
      "source": [
        "# x is a tensor with size being (3)\n",
        "x = torch.Tensor([1, 2, 3])\n",
        "\n",
        "# Our goal is to generate a tensor z with size (2, 3), so that z[0,:] = x, z[1,:] = x.\n",
        "z = x.repeat(2,1)\n",
        "print(z.size())\n",
        "\n",
        "# [TO DO]\n",
        "# Change the size of x into (1, 3) by using torch.unsqueeze.\n",
        "x = torch.unsqueeze(x,dim=0)\n",
        "print(x.size())\n",
        "\n",
        "# Then expand the new tensor to the target tensor by using torch.Tensor.expand.\n",
        "x = x.expand(2,3)\n",
        "print(x.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3])\n",
            "torch.Size([1, 3])\n",
            "torch.Size([2, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKhSLdacuA_C"
      },
      "source": [
        "\n",
        "Both view() and reshape() can change the shape of tensors. View() returns a tensor that will always share its data with the original tensor. It also imposes some contiguity constraints on the shapes of the two tensors. Reshape() doesn't impose any contiguity constraints, but also doesn't guarantee data sharing. The new tensor may be a view of the original tensor, or it may be a new tensor altogether.\n",
        "\n",
        "Both expand() and repeat() can extend the sie of data dimension. Expand() returns a new view of the self tensor with singleton dimensions expanded to a larger size. The function does not allocate new memory for the returned tensor and the returned tensor memory is not continuous. Repeat()\n",
        "will always allocate new memory. The repeated dimension can be of any size. It returns a tensor continuous in memory.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rFL_Shoef3m"
      },
      "source": [
        "### 4) Tensor reduction in a given dimension"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmEoJVw0LL9H"
      },
      "source": [
        "In deep learning, we often need to compute the mean/sum/max/min value in a given dimension of a tensor. Please read the document of [torch.mean](https://pytorch.org/docs/stable/torch.html#torch.mean), [torch.sum](https://pytorch.org/docs/stable/torch.html#torch.sum), [torch.max](https://pytorch.org/docs/stable/torch.html#torch.max), [torch.min](https://pytorch.org/docs/stable/torch.html#torch.min), [torch.topk](https://pytorch.org/docs/stable/torch.html#torch.topk), and finish the following practice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7dlZwe4MNxo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "195745ce-4f01-4286-b4b3-abf868588c97"
      },
      "source": [
        "# x is a random tensor with size being (10, 50)\n",
        "x = torch.randn(10, 50)\n",
        "\n",
        "# Compute the mean value for each row of x.\n",
        "# You need to generate a tensor x_mean of size (10), and x_mean[k] is the mean value of the k-th row of x.\n",
        "x_mean=torch.mean(x,1)\n",
        "print(x_mean)\n",
        "print(x_mean.size())\n",
        "\n",
        "# Compute the sum value for each row of x.\n",
        "# You need to generate a tensor x_sum of size (10).\n",
        "x_sum=torch.sum(x,1)\n",
        "print(x_sum)\n",
        "print(x_sum.size())\n",
        "\n",
        "# Compute the max value for each row of x.\n",
        "# You need to generate a tensor x_max of size (10).\n",
        "x_max=torch.max(x,1)\n",
        "print(x_max)\n",
        "print(x_max[0].size())\n",
        "\n",
        "# Compute the min value for each row of x.\n",
        "# You need to generate a tensor x_min of size (10).\n",
        "x_min=torch.min(x,1)\n",
        "print(x_min)\n",
        "print(x_min[0].size())\n",
        "\n",
        "# Compute the top-5 values for each row of x.\n",
        "# You need to generate a tensor x_top of size (10, 5), and x_top[k, :] is the top-5 values of the k-th row of x.\n",
        "x_top=torch.topk(x,5,dim=1)\n",
        "print(x_top)\n",
        "print(x_top[0].size())\n",
        "print(x_top[0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 0.2907,  0.3141,  0.1453, -0.0350,  0.2437, -0.2295, -0.1550, -0.1387,\n",
            "         0.0547,  0.1513])\n",
            "torch.Size([10])\n",
            "tensor([ 14.5354,  15.7028,   7.2634,  -1.7480,  12.1848, -11.4731,  -7.7511,\n",
            "         -6.9354,   2.7367,   7.5640])\n",
            "torch.Size([10])\n",
            "torch.return_types.max(\n",
            "values=tensor([2.7532, 1.9567, 2.3505, 2.6061, 2.6494, 2.1894, 1.6555, 1.8030, 2.0893,\n",
            "        2.4529]),\n",
            "indices=tensor([17, 16, 39, 32,  7, 15, 15,  0, 42, 30]))\n",
            "torch.Size([10])\n",
            "torch.return_types.min(\n",
            "values=tensor([-1.8455, -2.8486, -2.1515, -2.3523, -2.3358, -2.6973, -2.7683, -2.5374,\n",
            "        -1.8652, -1.3727]),\n",
            "indices=tensor([16, 35, 33, 21, 30,  3, 40, 29, 27, 41]))\n",
            "torch.Size([10])\n",
            "torch.return_types.topk(\n",
            "values=tensor([[2.7532, 2.3683, 2.0239, 2.0200, 1.5970],\n",
            "        [1.9567, 1.9246, 1.7585, 1.7551, 1.7241],\n",
            "        [2.3505, 1.7645, 1.6955, 1.5206, 1.4551],\n",
            "        [2.6061, 2.0457, 1.3977, 1.3504, 1.2687],\n",
            "        [2.6494, 2.2386, 2.0532, 1.7910, 1.7772],\n",
            "        [2.1894, 2.0419, 1.8023, 1.7271, 1.2758],\n",
            "        [1.6555, 1.6488, 1.6288, 1.5088, 1.4706],\n",
            "        [1.8030, 1.7256, 1.7187, 1.6188, 1.3178],\n",
            "        [2.0893, 1.3478, 1.2859, 1.2726, 1.2716],\n",
            "        [2.4529, 1.8159, 1.7026, 1.5568, 1.4882]]),\n",
            "indices=tensor([[17, 43, 30, 32, 39],\n",
            "        [16, 48, 39,  5, 26],\n",
            "        [39, 21, 25, 35, 38],\n",
            "        [32, 14, 22, 27,  5],\n",
            "        [ 7, 34, 26, 23, 38],\n",
            "        [15,  2, 16, 28, 10],\n",
            "        [15,  1, 44, 43, 46],\n",
            "        [ 0, 44, 15, 13,  5],\n",
            "        [42, 39, 48, 21, 47],\n",
            "        [30, 14, 17, 42,  0]]))\n",
            "torch.Size([10, 5])\n",
            "tensor([[2.7532, 2.3683, 2.0239, 2.0200, 1.5970],\n",
            "        [1.9567, 1.9246, 1.7585, 1.7551, 1.7241],\n",
            "        [2.3505, 1.7645, 1.6955, 1.5206, 1.4551],\n",
            "        [2.6061, 2.0457, 1.3977, 1.3504, 1.2687],\n",
            "        [2.6494, 2.2386, 2.0532, 1.7910, 1.7772],\n",
            "        [2.1894, 2.0419, 1.8023, 1.7271, 1.2758],\n",
            "        [1.6555, 1.6488, 1.6288, 1.5088, 1.4706],\n",
            "        [1.8030, 1.7256, 1.7187, 1.6188, 1.3178],\n",
            "        [2.0893, 1.3478, 1.2859, 1.2726, 1.2716],\n",
            "        [2.4529, 1.8159, 1.7026, 1.5568, 1.4882]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-bmI72yr7Gm"
      },
      "source": [
        "# 5) More complicated operations on tensors\n",
        "\n",
        "In deep learning we often want to only change part of a tensor, or only gather values from specific indices. For these purposes, we often use ```torch.gather``` or ```torch.scatter```, see their definition [here](https://pytorch.org/docs/stable/tensors.html?highlight=scatter#torch.Tensor.scatter). \n",
        "\n",
        "Note that you **do not have to** use these functions and some parts of the question may not require them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVUKcSlLtf-r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9001806-c8c7-41a5-a785-9a7c6f885e12"
      },
      "source": [
        "ind = torch.randint(50,(10,50))\n",
        "x = torch.randn(10,50,50)\n",
        "# select for all i,j the values x[i,j,k] where ind[i,j] = k in a tensor\n",
        "# the tensor should have shape (10,50)\n",
        "t1 = torch.zeros(ind.shape[0],ind.shape[1])\n",
        "for i in range(ind.shape[0]):\n",
        "  for j in range(ind.shape[1]):\n",
        "    t1[i,j] = x[i,j,ind[i,j]]    \n",
        "\n",
        "print(t1.shape)\n",
        "\n",
        "# double for all i,j the values x[i,j,k] where ind[i,j] = k leaving all other values in x untouched\n",
        "# the returned tensor should have shape (10,50,50)\n",
        "t2=x.detach().clone()\n",
        "for i in range(ind.shape[0]):\n",
        "  for j in range(ind.shape[1]):\n",
        "    t2[i,j,ind[i,j]] *= 2\n",
        "\n",
        "print(t2.shape)\n",
        "\n",
        "\n",
        "ind = ind[:, 0]\n",
        "# select the values from x[i,l,j] where l = ind[k] for all i,j,k\n",
        "# the returned tensor should have shape (10,10,50)\n",
        "t3 = torch.zeros(x.shape[0],ind.shape[0],x.shape[2])\n",
        "for k in range(ind.shape[0]):\n",
        "  for i in range(x.shape[0]):\n",
        "    for j in range(x.shape[2]):\n",
        "      t3[i,k,j] = x[i,ind[k],j]\n",
        "\n",
        "print(t3.shape)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 50])\n",
            "torch.Size([10, 50, 50])\n",
            "torch.Size([10, 10, 50])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I49qjiqHB9oa"
      },
      "source": [
        "## Convolutional Neural Networks (40 points)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JePbG5pSt1xv"
      },
      "source": [
        "Implement a convolutional neural network for image classification on CIFAR-10 dataset.\n",
        "\n",
        "CIFAR-10 is an image dataset of 10 categories. Each image has a size of 32x32 pixels. The following code will download the dataset, and split it into `train` and `test`.\n",
        "\n",
        "For this question, we split the train data into training (80%) and validation (20%) for hyperparameter tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnPc57fIwQj0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "f0ea6c7499794e859029ffa423d8d655",
            "fe11a8049c4548d7beaf08cdc95e8f5d",
            "79acd213907e4660a3fe3757cc054be3",
            "bbf912265e6a404699865e7c8309b639",
            "ed6cc448084244c5a518ea052e7c3023",
            "a31c3e9863e14196b2bbe8c6f9dc7c26",
            "bf6eec1c1c384b738653ee8d4a1ab55a",
            "02f352f664bd4747a267cdd258cd2c42"
          ]
        },
        "outputId": "0ae91b26-d325-4e5b-ed08-bc5f5933bf8b"
      },
      "source": [
        "t= torchvision.transforms.ToTensor()\n",
        "train_dataset = torchvision.datasets.CIFAR10(\"./data\", train=True, download=True, transform=t)\n",
        "test_dataset = torchvision.datasets.CIFAR10(\"./data\", train=False, download=True, transform=t)\n",
        "\n",
        "N = len(train_dataset)\n",
        "indices = np.arange(N)\n",
        "np.random.shuffle(indices)\n",
        "n = int(0.8 * N)\n",
        "print('{} for training,\\t{} for validation'.format(n, N-n))\n",
        "train_indices = indices[:n]\n",
        "valid_indices = indices[n:]\n",
        "train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
        "valid_sampler = torch.utils.data.SubsetRandomSampler(valid_indices)\n",
        "\n",
        "# train a model\n",
        "# DO NOT MODIFY\n",
        "def train(model, dataloader, optimizer, criterion):\n",
        "    total_loss, total_correct, total_prediction = 0.0, 0.0, 0.0\n",
        "    model.train()\n",
        "    for X, y in dataloader:\n",
        "        logits = model(X.cuda())\n",
        "        predictions = torch.max(logits, dim=-1)[1]\n",
        "        loss = criterion(logits, y.cuda())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        total_correct += torch.eq(predictions, y.cuda()).sum().item()\n",
        "        total_prediction += y.size(0)\n",
        "    return total_loss / len(dataloader), total_correct / total_prediction\n",
        "\n",
        "# evaluate a model\n",
        "# DO NOT MODIFY\n",
        "def evaluate(model, dataloader, criterion):  \n",
        "    total_loss, total_correct, total_prediction = 0.0, 0.0, 0.0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            logits = model(X.cuda())\n",
        "            predictions = torch.max(logits, dim=-1)[1]\n",
        "            loss = criterion(logits, y.cuda())\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_correct += torch.eq(predictions, y.cuda()).sum().item()\n",
        "            total_prediction += y.size(0)\n",
        "    return total_loss / len(dataloader), total_correct / total_prediction"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0ea6c7499794e859029ffa423d8d655",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "40000 for training,\t10000 for validation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieBpiwMwi6wD"
      },
      "source": [
        "The following code visualizes some samples in the dataset. You may use it to debug your model if necessary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzZ_UvgNwSYa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "c1ddf914-dc74-4383-ee2c-3a745037a6cf"
      },
      "source": [
        "def plot(data, labels=None, num_sample=5):\n",
        "  n = min(len(data), num_sample)\n",
        "  for i in range(n):\n",
        "    plt.subplot(1, n, i+1)\n",
        "    plt.imshow(data[i], cmap=\"gray\")\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    if labels is not None:\n",
        "      plt.title(labels[i])\n",
        "\n",
        "train_dataset.labels = [train_dataset.classes[target] for target in train_dataset.targets]\n",
        "plot(train_dataset.data, train_dataset.labels)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwzKmdcuCv1D"
      },
      "source": [
        "### 1) Basic CNN implementation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbEYo5WgjTtm"
      },
      "source": [
        "Consider a basic CNN model\n",
        "\n",
        "- It has 3 convolutional layers, followed by a linear layer.\n",
        "- Each convolutional layer has a kernel size of 3, a padding of 1.\n",
        "- ReLU activation is applied on every hidden layer.\n",
        "\n",
        "Please implement this model in the following section. You will need to tune the hyperparameters and fill the results in the table."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZKyE2GUfL-Z"
      },
      "source": [
        "#### a) Implement convolutional layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P_aYytExtq9"
      },
      "source": [
        "Implement the initialization function and the forward function of the CNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDmCKUD1LBFk"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "\n",
        "    def __init__(self, channels):\n",
        "        super(CNN, self).__init__()\n",
        "        self.channels = channels\n",
        "        self.layer = nn.Sequential(\n",
        "            Conv(3, self.channels),\n",
        "            Conv(self.channels, self.channels),\n",
        "            Conv(self.channels, self.channels),\n",
        "        )\n",
        "        self.out_player = nn.Sequential(\n",
        "            nn.Linear(self.channels * 32 * 32, 256),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10),\n",
        "            nn.Softmax(dim=-1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.layer(x)\n",
        "        h = h.reshape(-1, self.channels * 32 * 32)\n",
        "        result = self.out_player(h)\n",
        "        return result\n",
        "\n",
        "class Conv(nn.Module):\n",
        "\n",
        "    def __init__(self, inchannels, outchannels):\n",
        "        super(Conv, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=inchannels, out_channels=outchannels, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(outchannels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer(x)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_YaASPpgRiL"
      },
      "source": [
        "#### b) Tune hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygMcDdpy6XWP"
      },
      "source": [
        "Train the CNN model on CIFAR-10 dataset. Tune the number of channels (in CNN), optimizer, learning rate and the number of epochs for best validation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMAfH60vP3B2"
      },
      "source": [
        "from itertools import product"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezqosnJbwUGC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d3f233c-0bf9-44a7-87d3-68a8714160d9"
      },
      "source": [
        "\n",
        "# tune the optimizer type and hyperparameters with the following code as an example\n",
        "parameters = dict(\n",
        "    channels= [128,256,512],\n",
        "    EPOCHS= [30,50],\n",
        "    lr =[2e-4,1e-4,1e-3],\n",
        "    optimier=[torch.optim.SGD,torch.optim.Adam],\n",
        "    batch_size= [128]\n",
        ")\n",
        "param_values = [v for v in parameters.values()]\n",
        "with open(\"read.txt\",\"w\") as f:     \n",
        "    # call your model here\n",
        "    for channel,EPOCHS,lr,optim_type,batch_size in product(*param_values):\n",
        "        print(channel,EPOCHS,lr,optim_type,batch_size)\n",
        "        train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "        valid_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
        "        test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "        model = CNN(channel).cuda()\n",
        "        optimizer = optim_type(model.parameters(),lr=lr)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        # train and test the model\n",
        "        # you can reuse the following coding block for hyperparameter tuning\n",
        "        # feel free to try more advanced training strategies\n",
        "        best_valid_acc = 0.0\n",
        "        best_state_dict = copy.deepcopy(model.state_dict())\n",
        "        for epoch in range(EPOCHS):\n",
        "            train_loss, train_acc = train(model, train_dataloader, optimizer, criterion)\n",
        "            valid_loss, valid_acc = evaluate(model, valid_dataloader, criterion)\n",
        "            print('Epoch {} | Train loss {:.3f} | Valid loss {:.3f} | Valid acc {:.3f}'.format(epoch, train_loss, valid_loss,valid_acc))\n",
        "            f.write('Epoch {} | Train loss {:.3f} | Valid loss {:.3f} | Valid acc {:.3f}\\n'.format(epoch, train_loss, valid_loss,valid_acc))\n",
        "            if valid_acc > best_valid_acc:\n",
        "                best_valid_acc = valid_acc\n",
        "                best_state_dict = copy.deepcopy(model.state_dict())\n",
        "                torch.save(model.state_dict(),f\"{channel}{lr}.pt\")\n",
        "        print(\"Finally!\")\n",
        "        f.write(f\"best_valid_acc{best_valid_acc}\\n\")\n",
        "        print(\"best_valid_acc\",best_valid_acc)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128 30 0.0002 <class 'torch.optim.sgd.SGD'> 128\n",
            "Epoch 0 | Train loss 2.302 | Valid loss 2.301 | Valid acc 0.113\n",
            "Epoch 1 | Train loss 2.300 | Valid loss 2.299 | Valid acc 0.140\n",
            "Epoch 2 | Train loss 2.297 | Valid loss 2.296 | Valid acc 0.145\n",
            "Epoch 3 | Train loss 2.294 | Valid loss 2.292 | Valid acc 0.137\n",
            "Epoch 4 | Train loss 2.290 | Valid loss 2.287 | Valid acc 0.141\n",
            "Epoch 5 | Train loss 2.285 | Valid loss 2.282 | Valid acc 0.161\n",
            "Epoch 6 | Train loss 2.280 | Valid loss 2.276 | Valid acc 0.189\n",
            "Epoch 7 | Train loss 2.274 | Valid loss 2.269 | Valid acc 0.211\n",
            "Epoch 8 | Train loss 2.268 | Valid loss 2.262 | Valid acc 0.228\n",
            "Epoch 9 | Train loss 2.262 | Valid loss 2.257 | Valid acc 0.237\n",
            "Epoch 10 | Train loss 2.256 | Valid loss 2.249 | Valid acc 0.242\n",
            "Epoch 11 | Train loss 2.250 | Valid loss 2.244 | Valid acc 0.251\n",
            "Epoch 12 | Train loss 2.244 | Valid loss 2.238 | Valid acc 0.256\n",
            "Epoch 13 | Train loss 2.239 | Valid loss 2.232 | Valid acc 0.258\n",
            "Epoch 14 | Train loss 2.233 | Valid loss 2.227 | Valid acc 0.261\n",
            "Epoch 15 | Train loss 2.229 | Valid loss 2.221 | Valid acc 0.263\n",
            "Epoch 16 | Train loss 2.224 | Valid loss 2.217 | Valid acc 0.267\n",
            "Epoch 17 | Train loss 2.220 | Valid loss 2.213 | Valid acc 0.270\n",
            "Epoch 18 | Train loss 2.216 | Valid loss 2.209 | Valid acc 0.273\n",
            "Epoch 19 | Train loss 2.212 | Valid loss 2.204 | Valid acc 0.276\n",
            "Epoch 20 | Train loss 2.209 | Valid loss 2.201 | Valid acc 0.281\n",
            "Epoch 21 | Train loss 2.204 | Valid loss 2.197 | Valid acc 0.287\n",
            "Epoch 22 | Train loss 2.201 | Valid loss 2.192 | Valid acc 0.293\n",
            "Epoch 23 | Train loss 2.197 | Valid loss 2.189 | Valid acc 0.298\n",
            "Epoch 24 | Train loss 2.194 | Valid loss 2.183 | Valid acc 0.305\n",
            "Epoch 25 | Train loss 2.191 | Valid loss 2.181 | Valid acc 0.309\n",
            "Epoch 26 | Train loss 2.186 | Valid loss 2.177 | Valid acc 0.315\n",
            "Epoch 27 | Train loss 2.182 | Valid loss 2.171 | Valid acc 0.320\n",
            "Epoch 28 | Train loss 2.180 | Valid loss 2.169 | Valid acc 0.328\n",
            "Epoch 29 | Train loss 2.175 | Valid loss 2.164 | Valid acc 0.334\n",
            "Finally!\n",
            "best_valid_acc 0.3335\n",
            "128 30 0.0002 <class 'torch.optim.adam.Adam'> 128\n",
            "Epoch 0 | Train loss 2.090 | Valid loss 2.014 | Valid acc 0.442\n",
            "Epoch 1 | Train loss 1.993 | Valid loss 1.944 | Valid acc 0.514\n",
            "Epoch 2 | Train loss 1.935 | Valid loss 1.912 | Valid acc 0.548\n",
            "Epoch 3 | Train loss 1.883 | Valid loss 1.859 | Valid acc 0.599\n",
            "Epoch 4 | Train loss 1.844 | Valid loss 1.859 | Valid acc 0.598\n",
            "Epoch 5 | Train loss 1.814 | Valid loss 1.817 | Valid acc 0.638\n",
            "Epoch 6 | Train loss 1.792 | Valid loss 1.803 | Valid acc 0.659\n",
            "Epoch 7 | Train loss 1.768 | Valid loss 1.796 | Valid acc 0.663\n",
            "Epoch 8 | Train loss 1.750 | Valid loss 1.784 | Valid acc 0.674\n",
            "Epoch 9 | Train loss 1.739 | Valid loss 1.793 | Valid acc 0.667\n",
            "Epoch 10 | Train loss 1.725 | Valid loss 1.769 | Valid acc 0.692\n",
            "Epoch 11 | Train loss 1.710 | Valid loss 1.756 | Valid acc 0.706\n",
            "Epoch 12 | Train loss 1.696 | Valid loss 1.763 | Valid acc 0.696\n",
            "Epoch 13 | Train loss 1.689 | Valid loss 1.757 | Valid acc 0.704\n",
            "Epoch 14 | Train loss 1.680 | Valid loss 1.748 | Valid acc 0.714\n",
            "Epoch 15 | Train loss 1.670 | Valid loss 1.743 | Valid acc 0.717\n",
            "Epoch 16 | Train loss 1.658 | Valid loss 1.747 | Valid acc 0.713\n",
            "Epoch 17 | Train loss 1.650 | Valid loss 1.747 | Valid acc 0.712\n",
            "Epoch 18 | Train loss 1.642 | Valid loss 1.736 | Valid acc 0.723\n",
            "Epoch 19 | Train loss 1.636 | Valid loss 1.742 | Valid acc 0.719\n",
            "Epoch 20 | Train loss 1.629 | Valid loss 1.733 | Valid acc 0.726\n",
            "Epoch 21 | Train loss 1.620 | Valid loss 1.749 | Valid acc 0.712\n",
            "Epoch 22 | Train loss 1.616 | Valid loss 1.756 | Valid acc 0.700\n",
            "Epoch 23 | Train loss 1.608 | Valid loss 1.747 | Valid acc 0.712\n",
            "Epoch 24 | Train loss 1.600 | Valid loss 1.727 | Valid acc 0.733\n",
            "Epoch 25 | Train loss 1.600 | Valid loss 1.736 | Valid acc 0.724\n",
            "Epoch 26 | Train loss 1.591 | Valid loss 1.717 | Valid acc 0.740\n",
            "Epoch 27 | Train loss 1.590 | Valid loss 1.721 | Valid acc 0.743\n",
            "Epoch 28 | Train loss 1.588 | Valid loss 1.735 | Valid acc 0.724\n",
            "Epoch 29 | Train loss 1.583 | Valid loss 1.735 | Valid acc 0.727\n",
            "Finally!\n",
            "best_valid_acc 0.7434\n",
            "128 30 0.0001 <class 'torch.optim.sgd.SGD'> 128\n",
            "Epoch 0 | Train loss 2.302 | Valid loss 2.302 | Valid acc 0.113\n",
            "Epoch 1 | Train loss 2.301 | Valid loss 2.301 | Valid acc 0.159\n",
            "Epoch 2 | Train loss 2.300 | Valid loss 2.300 | Valid acc 0.194\n",
            "Epoch 3 | Train loss 2.299 | Valid loss 2.298 | Valid acc 0.213\n",
            "Epoch 4 | Train loss 2.297 | Valid loss 2.296 | Valid acc 0.218\n",
            "Epoch 5 | Train loss 2.296 | Valid loss 2.295 | Valid acc 0.220\n",
            "Epoch 6 | Train loss 2.294 | Valid loss 2.292 | Valid acc 0.219\n",
            "Epoch 7 | Train loss 2.292 | Valid loss 2.290 | Valid acc 0.210\n",
            "Epoch 8 | Train loss 2.289 | Valid loss 2.288 | Valid acc 0.209\n",
            "Epoch 9 | Train loss 2.287 | Valid loss 2.285 | Valid acc 0.203\n",
            "Epoch 10 | Train loss 2.284 | Valid loss 2.282 | Valid acc 0.202\n",
            "Epoch 11 | Train loss 2.281 | Valid loss 2.278 | Valid acc 0.203\n",
            "Epoch 12 | Train loss 2.278 | Valid loss 2.275 | Valid acc 0.206\n",
            "Epoch 13 | Train loss 2.275 | Valid loss 2.272 | Valid acc 0.214\n",
            "Epoch 14 | Train loss 2.271 | Valid loss 2.269 | Valid acc 0.224\n",
            "Epoch 15 | Train loss 2.268 | Valid loss 2.265 | Valid acc 0.230\n",
            "Epoch 16 | Train loss 2.265 | Valid loss 2.262 | Valid acc 0.240\n",
            "Epoch 17 | Train loss 2.262 | Valid loss 2.259 | Valid acc 0.248\n",
            "Epoch 18 | Train loss 2.260 | Valid loss 2.257 | Valid acc 0.254\n",
            "Epoch 19 | Train loss 2.257 | Valid loss 2.253 | Valid acc 0.258\n",
            "Epoch 20 | Train loss 2.254 | Valid loss 2.251 | Valid acc 0.265\n",
            "Epoch 21 | Train loss 2.251 | Valid loss 2.248 | Valid acc 0.267\n",
            "Epoch 22 | Train loss 2.249 | Valid loss 2.244 | Valid acc 0.269\n",
            "Epoch 23 | Train loss 2.245 | Valid loss 2.240 | Valid acc 0.271\n",
            "Epoch 24 | Train loss 2.243 | Valid loss 2.238 | Valid acc 0.272\n",
            "Epoch 25 | Train loss 2.240 | Valid loss 2.235 | Valid acc 0.275\n",
            "Epoch 26 | Train loss 2.237 | Valid loss 2.232 | Valid acc 0.276\n",
            "Epoch 27 | Train loss 2.234 | Valid loss 2.228 | Valid acc 0.276\n",
            "Epoch 28 | Train loss 2.232 | Valid loss 2.225 | Valid acc 0.276\n",
            "Epoch 29 | Train loss 2.229 | Valid loss 2.221 | Valid acc 0.277\n",
            "Finally!\n",
            "best_valid_acc 0.277\n",
            "128 30 0.0001 <class 'torch.optim.adam.Adam'> 128\n",
            "Epoch 0 | Train loss 2.079 | Valid loss 1.993 | Valid acc 0.461\n",
            "Epoch 1 | Train loss 1.971 | Valid loss 1.954 | Valid acc 0.502\n",
            "Epoch 2 | Train loss 1.921 | Valid loss 1.909 | Valid acc 0.552\n",
            "Epoch 3 | Train loss 1.880 | Valid loss 1.888 | Valid acc 0.569\n",
            "Epoch 4 | Train loss 1.853 | Valid loss 1.871 | Valid acc 0.587\n",
            "Epoch 5 | Train loss 1.829 | Valid loss 1.862 | Valid acc 0.596\n",
            "Epoch 6 | Train loss 1.812 | Valid loss 1.862 | Valid acc 0.601\n",
            "Epoch 7 | Train loss 1.793 | Valid loss 1.846 | Valid acc 0.615\n",
            "Epoch 8 | Train loss 1.777 | Valid loss 1.835 | Valid acc 0.624\n",
            "Epoch 9 | Train loss 1.762 | Valid loss 1.838 | Valid acc 0.623\n",
            "Epoch 10 | Train loss 1.748 | Valid loss 1.825 | Valid acc 0.635\n",
            "Epoch 11 | Train loss 1.735 | Valid loss 1.825 | Valid acc 0.638\n",
            "Epoch 12 | Train loss 1.723 | Valid loss 1.775 | Valid acc 0.684\n",
            "Epoch 13 | Train loss 1.665 | Valid loss 1.763 | Valid acc 0.698\n",
            "Epoch 14 | Train loss 1.642 | Valid loss 1.746 | Valid acc 0.715\n",
            "Epoch 15 | Train loss 1.626 | Valid loss 1.740 | Valid acc 0.722\n",
            "Epoch 16 | Train loss 1.613 | Valid loss 1.759 | Valid acc 0.703\n",
            "Epoch 17 | Train loss 1.602 | Valid loss 1.737 | Valid acc 0.723\n",
            "Epoch 18 | Train loss 1.591 | Valid loss 1.738 | Valid acc 0.720\n",
            "Epoch 19 | Train loss 1.585 | Valid loss 1.739 | Valid acc 0.723\n",
            "Epoch 20 | Train loss 1.575 | Valid loss 1.730 | Valid acc 0.728\n",
            "Epoch 21 | Train loss 1.572 | Valid loss 1.738 | Valid acc 0.721\n",
            "Epoch 22 | Train loss 1.563 | Valid loss 1.728 | Valid acc 0.731\n",
            "Epoch 23 | Train loss 1.560 | Valid loss 1.727 | Valid acc 0.733\n",
            "Epoch 24 | Train loss 1.555 | Valid loss 1.727 | Valid acc 0.735\n",
            "Epoch 25 | Train loss 1.551 | Valid loss 1.735 | Valid acc 0.724\n",
            "Epoch 26 | Train loss 1.548 | Valid loss 1.739 | Valid acc 0.720\n",
            "Epoch 27 | Train loss 1.549 | Valid loss 1.726 | Valid acc 0.735\n",
            "Epoch 28 | Train loss 1.543 | Valid loss 1.735 | Valid acc 0.726\n",
            "Epoch 29 | Train loss 1.540 | Valid loss 1.731 | Valid acc 0.728\n",
            "Finally!\n",
            "best_valid_acc 0.7351\n",
            "128 30 0.001 <class 'torch.optim.sgd.SGD'> 128\n",
            "Epoch 0 | Train loss 2.298 | Valid loss 2.291 | Valid acc 0.161\n",
            "Epoch 1 | Train loss 2.281 | Valid loss 2.266 | Valid acc 0.203\n",
            "Epoch 2 | Train loss 2.254 | Valid loss 2.234 | Valid acc 0.267\n",
            "Epoch 3 | Train loss 2.224 | Valid loss 2.202 | Valid acc 0.294\n",
            "Epoch 4 | Train loss 2.197 | Valid loss 2.176 | Valid acc 0.315\n",
            "Epoch 5 | Train loss 2.176 | Valid loss 2.153 | Valid acc 0.343\n",
            "Epoch 6 | Train loss 2.154 | Valid loss 2.131 | Valid acc 0.363\n",
            "Epoch 7 | Train loss 2.136 | Valid loss 2.115 | Valid acc 0.375\n",
            "Epoch 8 | Train loss 2.122 | Valid loss 2.099 | Valid acc 0.384\n",
            "Epoch 9 | Train loss 2.108 | Valid loss 2.088 | Valid acc 0.398\n",
            "Epoch 10 | Train loss 2.097 | Valid loss 2.075 | Valid acc 0.412\n",
            "Epoch 11 | Train loss 2.086 | Valid loss 2.067 | Valid acc 0.419\n",
            "Epoch 12 | Train loss 2.077 | Valid loss 2.055 | Valid acc 0.427\n",
            "Epoch 13 | Train loss 2.067 | Valid loss 2.048 | Valid acc 0.432\n",
            "Epoch 14 | Train loss 2.059 | Valid loss 2.040 | Valid acc 0.442\n",
            "Epoch 15 | Train loss 2.053 | Valid loss 2.032 | Valid acc 0.444\n",
            "Epoch 16 | Train loss 2.045 | Valid loss 2.028 | Valid acc 0.450\n",
            "Epoch 17 | Train loss 2.037 | Valid loss 2.021 | Valid acc 0.457\n",
            "Epoch 18 | Train loss 2.031 | Valid loss 2.012 | Valid acc 0.463\n",
            "Epoch 19 | Train loss 2.025 | Valid loss 2.007 | Valid acc 0.469\n",
            "Epoch 20 | Train loss 2.019 | Valid loss 2.003 | Valid acc 0.473\n",
            "Epoch 21 | Train loss 2.012 | Valid loss 1.996 | Valid acc 0.481\n",
            "Epoch 22 | Train loss 2.006 | Valid loss 1.989 | Valid acc 0.487\n",
            "Epoch 23 | Train loss 1.999 | Valid loss 1.986 | Valid acc 0.496\n",
            "Epoch 24 | Train loss 1.993 | Valid loss 1.979 | Valid acc 0.504\n",
            "Epoch 25 | Train loss 1.987 | Valid loss 1.974 | Valid acc 0.506\n",
            "Epoch 26 | Train loss 1.982 | Valid loss 1.968 | Valid acc 0.513\n",
            "Epoch 27 | Train loss 1.975 | Valid loss 1.962 | Valid acc 0.517\n",
            "Epoch 28 | Train loss 1.970 | Valid loss 1.958 | Valid acc 0.522\n",
            "Epoch 29 | Train loss 1.965 | Valid loss 1.955 | Valid acc 0.525\n",
            "Finally!\n",
            "best_valid_acc 0.5247\n",
            "128 30 0.001 <class 'torch.optim.adam.Adam'> 128\n",
            "Epoch 0 | Train loss 2.296 | Valid loss 2.306 | Valid acc 0.156\n",
            "Epoch 1 | Train loss 2.293 | Valid loss 2.294 | Valid acc 0.168\n",
            "Epoch 2 | Train loss 2.286 | Valid loss 2.293 | Valid acc 0.167\n",
            "Epoch 3 | Train loss 2.301 | Valid loss 2.309 | Valid acc 0.152\n",
            "Epoch 4 | Train loss 2.282 | Valid loss 2.290 | Valid acc 0.170\n",
            "Epoch 5 | Train loss 2.275 | Valid loss 2.277 | Valid acc 0.185\n",
            "Epoch 6 | Train loss 2.260 | Valid loss 2.259 | Valid acc 0.203\n",
            "Epoch 7 | Train loss 2.284 | Valid loss 2.329 | Valid acc 0.133\n",
            "Epoch 8 | Train loss 2.327 | Valid loss 2.326 | Valid acc 0.136\n",
            "Epoch 9 | Train loss 2.323 | Valid loss 2.327 | Valid acc 0.133\n",
            "Epoch 10 | Train loss 2.326 | Valid loss 2.319 | Valid acc 0.141\n",
            "Epoch 11 | Train loss 2.321 | Valid loss 2.323 | Valid acc 0.139\n",
            "Epoch 12 | Train loss 2.316 | Valid loss 2.302 | Valid acc 0.157\n",
            "Epoch 13 | Train loss 2.320 | Valid loss 2.342 | Valid acc 0.120\n",
            "Epoch 14 | Train loss 2.334 | Valid loss 2.318 | Valid acc 0.144\n",
            "Epoch 15 | Train loss 2.319 | Valid loss 2.322 | Valid acc 0.140\n",
            "Epoch 16 | Train loss 2.324 | Valid loss 2.338 | Valid acc 0.124\n",
            "Epoch 17 | Train loss 2.331 | Valid loss 2.328 | Valid acc 0.133\n",
            "Epoch 18 | Train loss 2.333 | Valid loss 2.327 | Valid acc 0.133\n",
            "Epoch 19 | Train loss 2.330 | Valid loss 2.334 | Valid acc 0.126\n",
            "Epoch 20 | Train loss 2.340 | Valid loss 2.339 | Valid acc 0.121\n",
            "Epoch 21 | Train loss 2.351 | Valid loss 2.356 | Valid acc 0.105\n",
            "Epoch 22 | Train loss 2.347 | Valid loss 2.339 | Valid acc 0.122\n",
            "Epoch 23 | Train loss 2.334 | Valid loss 2.317 | Valid acc 0.141\n",
            "Epoch 24 | Train loss 2.323 | Valid loss 2.323 | Valid acc 0.138\n",
            "Epoch 25 | Train loss 2.336 | Valid loss 2.339 | Valid acc 0.122\n",
            "Epoch 26 | Train loss 2.338 | Valid loss 2.339 | Valid acc 0.123\n",
            "Epoch 27 | Train loss 2.353 | Valid loss 2.357 | Valid acc 0.104\n",
            "Epoch 28 | Train loss 2.358 | Valid loss 2.357 | Valid acc 0.104\n",
            "Epoch 29 | Train loss 2.357 | Valid loss 2.352 | Valid acc 0.110\n",
            "Finally!\n",
            "best_valid_acc 0.2025\n",
            "128 50 0.0002 <class 'torch.optim.sgd.SGD'> 128\n",
            "Epoch 0 | Train loss 2.302 | Valid loss 2.301 | Valid acc 0.138\n",
            "Epoch 1 | Train loss 2.300 | Valid loss 2.299 | Valid acc 0.168\n",
            "Epoch 2 | Train loss 2.298 | Valid loss 2.296 | Valid acc 0.196\n",
            "Epoch 3 | Train loss 2.295 | Valid loss 2.293 | Valid acc 0.217\n",
            "Epoch 4 | Train loss 2.292 | Valid loss 2.289 | Valid acc 0.234\n",
            "Epoch 5 | Train loss 2.288 | Valid loss 2.284 | Valid acc 0.248\n",
            "Epoch 6 | Train loss 2.283 | Valid loss 2.279 | Valid acc 0.255\n",
            "Epoch 7 | Train loss 2.277 | Valid loss 2.273 | Valid acc 0.255\n",
            "Epoch 8 | Train loss 2.271 | Valid loss 2.266 | Valid acc 0.253\n",
            "Epoch 9 | Train loss 2.264 | Valid loss 2.259 | Valid acc 0.252\n",
            "Epoch 10 | Train loss 2.258 | Valid loss 2.251 | Valid acc 0.250\n",
            "Epoch 11 | Train loss 2.252 | Valid loss 2.244 | Valid acc 0.252\n",
            "Epoch 12 | Train loss 2.246 | Valid loss 2.239 | Valid acc 0.254\n",
            "Epoch 13 | Train loss 2.241 | Valid loss 2.232 | Valid acc 0.257\n",
            "Epoch 14 | Train loss 2.235 | Valid loss 2.228 | Valid acc 0.259\n",
            "Epoch 15 | Train loss 2.230 | Valid loss 2.223 | Valid acc 0.264\n",
            "Epoch 16 | Train loss 2.226 | Valid loss 2.218 | Valid acc 0.268\n",
            "Epoch 17 | Train loss 2.221 | Valid loss 2.214 | Valid acc 0.271\n",
            "Epoch 18 | Train loss 2.216 | Valid loss 2.208 | Valid acc 0.273\n",
            "Epoch 19 | Train loss 2.213 | Valid loss 2.203 | Valid acc 0.277\n",
            "Epoch 20 | Train loss 2.208 | Valid loss 2.198 | Valid acc 0.280\n",
            "Epoch 21 | Train loss 2.204 | Valid loss 2.196 | Valid acc 0.282\n",
            "Epoch 22 | Train loss 2.200 | Valid loss 2.191 | Valid acc 0.287\n",
            "Epoch 23 | Train loss 2.196 | Valid loss 2.187 | Valid acc 0.292\n",
            "Epoch 24 | Train loss 2.193 | Valid loss 2.181 | Valid acc 0.297\n",
            "Epoch 25 | Train loss 2.189 | Valid loss 2.178 | Valid acc 0.301\n",
            "Epoch 26 | Train loss 2.186 | Valid loss 2.175 | Valid acc 0.305\n",
            "Epoch 27 | Train loss 2.183 | Valid loss 2.170 | Valid acc 0.310\n",
            "Epoch 28 | Train loss 2.179 | Valid loss 2.165 | Valid acc 0.314\n",
            "Epoch 29 | Train loss 2.175 | Valid loss 2.161 | Valid acc 0.321\n",
            "Epoch 30 | Train loss 2.171 | Valid loss 2.156 | Valid acc 0.330\n",
            "Epoch 31 | Train loss 2.166 | Valid loss 2.151 | Valid acc 0.338\n",
            "Epoch 32 | Train loss 2.163 | Valid loss 2.148 | Valid acc 0.345\n",
            "Epoch 33 | Train loss 2.159 | Valid loss 2.144 | Valid acc 0.349\n",
            "Epoch 34 | Train loss 2.155 | Valid loss 2.140 | Valid acc 0.349\n",
            "Epoch 35 | Train loss 2.152 | Valid loss 2.138 | Valid acc 0.353\n",
            "Epoch 36 | Train loss 2.150 | Valid loss 2.135 | Valid acc 0.355\n",
            "Epoch 37 | Train loss 2.147 | Valid loss 2.131 | Valid acc 0.356\n",
            "Epoch 38 | Train loss 2.144 | Valid loss 2.127 | Valid acc 0.361\n",
            "Epoch 39 | Train loss 2.141 | Valid loss 2.123 | Valid acc 0.364\n",
            "Epoch 40 | Train loss 2.138 | Valid loss 2.122 | Valid acc 0.369\n",
            "Epoch 41 | Train loss 2.135 | Valid loss 2.118 | Valid acc 0.371\n",
            "Epoch 42 | Train loss 2.132 | Valid loss 2.115 | Valid acc 0.375\n",
            "Epoch 43 | Train loss 2.128 | Valid loss 2.111 | Valid acc 0.376\n",
            "Epoch 44 | Train loss 2.126 | Valid loss 2.108 | Valid acc 0.381\n",
            "Epoch 45 | Train loss 2.123 | Valid loss 2.106 | Valid acc 0.381\n",
            "Epoch 46 | Train loss 2.120 | Valid loss 2.102 | Valid acc 0.382\n",
            "Epoch 47 | Train loss 2.119 | Valid loss 2.100 | Valid acc 0.385\n",
            "Epoch 48 | Train loss 2.117 | Valid loss 2.100 | Valid acc 0.388\n",
            "Epoch 49 | Train loss 2.113 | Valid loss 2.095 | Valid acc 0.389\n",
            "Finally!\n",
            "best_valid_acc 0.3886\n",
            "128 50 0.0002 <class 'torch.optim.adam.Adam'> 128\n",
            "Epoch 0 | Train loss 2.074 | Valid loss 1.992 | Valid acc 0.467\n",
            "Epoch 1 | Train loss 1.970 | Valid loss 1.920 | Valid acc 0.535\n",
            "Epoch 2 | Train loss 1.922 | Valid loss 1.901 | Valid acc 0.555\n",
            "Epoch 3 | Train loss 1.883 | Valid loss 1.896 | Valid acc 0.559\n",
            "Epoch 4 | Train loss 1.847 | Valid loss 1.845 | Valid acc 0.613\n",
            "Epoch 5 | Train loss 1.825 | Valid loss 1.823 | Valid acc 0.635\n",
            "Epoch 6 | Train loss 1.798 | Valid loss 1.827 | Valid acc 0.631\n",
            "Epoch 7 | Train loss 1.779 | Valid loss 1.789 | Valid acc 0.670\n",
            "Epoch 8 | Train loss 1.760 | Valid loss 1.813 | Valid acc 0.644\n",
            "Epoch 9 | Train loss 1.742 | Valid loss 1.777 | Valid acc 0.679\n",
            "Epoch 10 | Train loss 1.731 | Valid loss 1.773 | Valid acc 0.686\n",
            "Epoch 11 | Train loss 1.716 | Valid loss 1.776 | Valid acc 0.683\n",
            "Epoch 12 | Train loss 1.700 | Valid loss 1.762 | Valid acc 0.699\n",
            "Epoch 13 | Train loss 1.691 | Valid loss 1.792 | Valid acc 0.666\n",
            "Epoch 14 | Train loss 1.680 | Valid loss 1.753 | Valid acc 0.708\n",
            "Epoch 15 | Train loss 1.670 | Valid loss 1.746 | Valid acc 0.715\n",
            "Epoch 16 | Train loss 1.662 | Valid loss 1.744 | Valid acc 0.715\n",
            "Epoch 17 | Train loss 1.652 | Valid loss 1.745 | Valid acc 0.713\n",
            "Epoch 18 | Train loss 1.644 | Valid loss 1.739 | Valid acc 0.720\n",
            "Epoch 19 | Train loss 1.636 | Valid loss 1.737 | Valid acc 0.720\n",
            "Epoch 20 | Train loss 1.627 | Valid loss 1.736 | Valid acc 0.727\n",
            "Epoch 21 | Train loss 1.619 | Valid loss 1.750 | Valid acc 0.711\n",
            "Epoch 22 | Train loss 1.613 | Valid loss 1.741 | Valid acc 0.719\n",
            "Epoch 23 | Train loss 1.609 | Valid loss 1.734 | Valid acc 0.725\n",
            "Epoch 24 | Train loss 1.604 | Valid loss 1.730 | Valid acc 0.727\n",
            "Epoch 25 | Train loss 1.597 | Valid loss 1.754 | Valid acc 0.709\n",
            "Epoch 26 | Train loss 1.594 | Valid loss 1.734 | Valid acc 0.724\n",
            "Epoch 27 | Train loss 1.588 | Valid loss 1.733 | Valid acc 0.726\n",
            "Epoch 28 | Train loss 1.586 | Valid loss 1.727 | Valid acc 0.731\n",
            "Epoch 29 | Train loss 1.582 | Valid loss 1.729 | Valid acc 0.731\n",
            "Epoch 30 | Train loss 1.579 | Valid loss 1.737 | Valid acc 0.721\n",
            "Epoch 31 | Train loss 1.574 | Valid loss 1.728 | Valid acc 0.731\n",
            "Epoch 32 | Train loss 1.572 | Valid loss 1.723 | Valid acc 0.736\n",
            "Epoch 33 | Train loss 1.568 | Valid loss 1.725 | Valid acc 0.734\n",
            "Epoch 34 | Train loss 1.565 | Valid loss 1.729 | Valid acc 0.731\n",
            "Epoch 35 | Train loss 1.564 | Valid loss 1.728 | Valid acc 0.730\n",
            "Epoch 36 | Train loss 1.559 | Valid loss 1.733 | Valid acc 0.730\n",
            "Epoch 37 | Train loss 1.561 | Valid loss 1.729 | Valid acc 0.731\n",
            "Epoch 38 | Train loss 1.558 | Valid loss 1.735 | Valid acc 0.724\n",
            "Epoch 39 | Train loss 1.555 | Valid loss 1.722 | Valid acc 0.737\n",
            "Epoch 40 | Train loss 1.553 | Valid loss 1.727 | Valid acc 0.734\n",
            "Epoch 41 | Train loss 1.551 | Valid loss 1.725 | Valid acc 0.736\n",
            "Epoch 42 | Train loss 1.549 | Valid loss 1.731 | Valid acc 0.728\n",
            "Epoch 43 | Train loss 1.548 | Valid loss 1.734 | Valid acc 0.728\n",
            "Epoch 44 | Train loss 1.547 | Valid loss 1.727 | Valid acc 0.735\n",
            "Epoch 45 | Train loss 1.542 | Valid loss 1.719 | Valid acc 0.741\n",
            "Epoch 46 | Train loss 1.544 | Valid loss 1.729 | Valid acc 0.730\n",
            "Epoch 47 | Train loss 1.540 | Valid loss 1.722 | Valid acc 0.737\n",
            "Epoch 48 | Train loss 1.540 | Valid loss 1.732 | Valid acc 0.727\n",
            "Epoch 49 | Train loss 1.542 | Valid loss 1.725 | Valid acc 0.737\n",
            "Finally!\n",
            "best_valid_acc 0.7414\n",
            "128 50 0.0001 <class 'torch.optim.sgd.SGD'> 128\n",
            "Epoch 0 | Train loss 2.302 | Valid loss 2.301 | Valid acc 0.115\n",
            "Epoch 1 | Train loss 2.301 | Valid loss 2.301 | Valid acc 0.132\n",
            "Epoch 2 | Train loss 2.300 | Valid loss 2.300 | Valid acc 0.142\n",
            "Epoch 3 | Train loss 2.299 | Valid loss 2.299 | Valid acc 0.148\n",
            "Epoch 4 | Train loss 2.298 | Valid loss 2.297 | Valid acc 0.152\n",
            "Epoch 5 | Train loss 2.297 | Valid loss 2.296 | Valid acc 0.155\n",
            "Epoch 6 | Train loss 2.295 | Valid loss 2.294 | Valid acc 0.158\n",
            "Epoch 7 | Train loss 2.294 | Valid loss 2.293 | Valid acc 0.162\n",
            "Epoch 8 | Train loss 2.292 | Valid loss 2.291 | Valid acc 0.167\n",
            "Epoch 9 | Train loss 2.290 | Valid loss 2.289 | Valid acc 0.173\n",
            "Epoch 10 | Train loss 2.288 | Valid loss 2.286 | Valid acc 0.180\n",
            "Epoch 11 | Train loss 2.286 | Valid loss 2.284 | Valid acc 0.192\n",
            "Epoch 12 | Train loss 2.283 | Valid loss 2.281 | Valid acc 0.194\n",
            "Epoch 13 | Train loss 2.281 | Valid loss 2.278 | Valid acc 0.199\n",
            "Epoch 14 | Train loss 2.278 | Valid loss 2.276 | Valid acc 0.205\n",
            "Epoch 15 | Train loss 2.275 | Valid loss 2.272 | Valid acc 0.210\n",
            "Epoch 16 | Train loss 2.272 | Valid loss 2.270 | Valid acc 0.215\n",
            "Epoch 17 | Train loss 2.270 | Valid loss 2.266 | Valid acc 0.214\n",
            "Epoch 18 | Train loss 2.267 | Valid loss 2.263 | Valid acc 0.218\n",
            "Epoch 19 | Train loss 2.264 | Valid loss 2.260 | Valid acc 0.224\n",
            "Epoch 20 | Train loss 2.261 | Valid loss 2.257 | Valid acc 0.235\n",
            "Epoch 21 | Train loss 2.258 | Valid loss 2.255 | Valid acc 0.236\n",
            "Epoch 22 | Train loss 2.256 | Valid loss 2.251 | Valid acc 0.243\n",
            "Epoch 23 | Train loss 2.253 | Valid loss 2.249 | Valid acc 0.248\n",
            "Epoch 24 | Train loss 2.250 | Valid loss 2.246 | Valid acc 0.253\n",
            "Epoch 25 | Train loss 2.248 | Valid loss 2.242 | Valid acc 0.259\n",
            "Epoch 26 | Train loss 2.245 | Valid loss 2.241 | Valid acc 0.266\n",
            "Epoch 27 | Train loss 2.243 | Valid loss 2.236 | Valid acc 0.267\n",
            "Epoch 28 | Train loss 2.241 | Valid loss 2.236 | Valid acc 0.275\n",
            "Epoch 29 | Train loss 2.238 | Valid loss 2.232 | Valid acc 0.278\n",
            "Epoch 30 | Train loss 2.236 | Valid loss 2.229 | Valid acc 0.286\n",
            "Epoch 31 | Train loss 2.234 | Valid loss 2.227 | Valid acc 0.291\n",
            "Epoch 32 | Train loss 2.231 | Valid loss 2.224 | Valid acc 0.295\n",
            "Epoch 33 | Train loss 2.229 | Valid loss 2.222 | Valid acc 0.298\n",
            "Epoch 34 | Train loss 2.227 | Valid loss 2.219 | Valid acc 0.299\n",
            "Epoch 35 | Train loss 2.225 | Valid loss 2.216 | Valid acc 0.304\n",
            "Epoch 36 | Train loss 2.222 | Valid loss 2.213 | Valid acc 0.306\n",
            "Epoch 37 | Train loss 2.220 | Valid loss 2.212 | Valid acc 0.311\n",
            "Epoch 38 | Train loss 2.218 | Valid loss 2.208 | Valid acc 0.312\n",
            "Epoch 39 | Train loss 2.216 | Valid loss 2.206 | Valid acc 0.315\n",
            "Epoch 40 | Train loss 2.213 | Valid loss 2.204 | Valid acc 0.316\n",
            "Epoch 41 | Train loss 2.210 | Valid loss 2.203 | Valid acc 0.316\n",
            "Epoch 42 | Train loss 2.208 | Valid loss 2.198 | Valid acc 0.317\n",
            "Epoch 43 | Train loss 2.207 | Valid loss 2.199 | Valid acc 0.318\n",
            "Epoch 44 | Train loss 2.205 | Valid loss 2.195 | Valid acc 0.318\n",
            "Epoch 45 | Train loss 2.203 | Valid loss 2.193 | Valid acc 0.318\n",
            "Epoch 46 | Train loss 2.201 | Valid loss 2.189 | Valid acc 0.319\n",
            "Epoch 47 | Train loss 2.198 | Valid loss 2.188 | Valid acc 0.320\n",
            "Epoch 48 | Train loss 2.196 | Valid loss 2.185 | Valid acc 0.321\n",
            "Epoch 49 | Train loss 2.194 | Valid loss 2.183 | Valid acc 0.322\n",
            "Finally!\n",
            "best_valid_acc 0.3217\n",
            "128 50 0.0001 <class 'torch.optim.adam.Adam'> 128\n",
            "Epoch 0 | Train loss 2.053 | Valid loss 1.947 | Valid acc 0.514\n",
            "Epoch 1 | Train loss 1.936 | Valid loss 1.898 | Valid acc 0.562\n",
            "Epoch 2 | Train loss 1.877 | Valid loss 1.863 | Valid acc 0.599\n",
            "Epoch 3 | Train loss 1.829 | Valid loss 1.822 | Valid acc 0.638\n",
            "Epoch 4 | Train loss 1.796 | Valid loss 1.811 | Valid acc 0.651\n",
            "Epoch 5 | Train loss 1.768 | Valid loss 1.785 | Valid acc 0.678\n",
            "Epoch 6 | Train loss 1.747 | Valid loss 1.771 | Valid acc 0.689\n",
            "Epoch 7 | Train loss 1.725 | Valid loss 1.768 | Valid acc 0.693\n",
            "Epoch 8 | Train loss 1.707 | Valid loss 1.759 | Valid acc 0.705\n",
            "Epoch 9 | Train loss 1.690 | Valid loss 1.756 | Valid acc 0.701\n",
            "Epoch 10 | Train loss 1.675 | Valid loss 1.747 | Valid acc 0.716\n",
            "Epoch 11 | Train loss 1.659 | Valid loss 1.740 | Valid acc 0.722\n",
            "Epoch 12 | Train loss 1.647 | Valid loss 1.745 | Valid acc 0.718\n",
            "Epoch 13 | Train loss 1.636 | Valid loss 1.757 | Valid acc 0.704\n",
            "Epoch 14 | Train loss 1.625 | Valid loss 1.736 | Valid acc 0.724\n",
            "Epoch 15 | Train loss 1.613 | Valid loss 1.737 | Valid acc 0.727\n",
            "Epoch 16 | Train loss 1.605 | Valid loss 1.732 | Valid acc 0.728\n",
            "Epoch 17 | Train loss 1.595 | Valid loss 1.730 | Valid acc 0.728\n",
            "Epoch 18 | Train loss 1.587 | Valid loss 1.729 | Valid acc 0.729\n",
            "Epoch 19 | Train loss 1.582 | Valid loss 1.738 | Valid acc 0.721\n",
            "Epoch 20 | Train loss 1.575 | Valid loss 1.722 | Valid acc 0.740\n",
            "Epoch 21 | Train loss 1.570 | Valid loss 1.720 | Valid acc 0.742\n",
            "Epoch 22 | Train loss 1.566 | Valid loss 1.726 | Valid acc 0.733\n",
            "Epoch 23 | Train loss 1.561 | Valid loss 1.732 | Valid acc 0.727\n",
            "Epoch 24 | Train loss 1.555 | Valid loss 1.729 | Valid acc 0.730\n",
            "Epoch 25 | Train loss 1.552 | Valid loss 1.726 | Valid acc 0.735\n",
            "Epoch 26 | Train loss 1.547 | Valid loss 1.731 | Valid acc 0.728\n",
            "Epoch 27 | Train loss 1.545 | Valid loss 1.738 | Valid acc 0.721\n",
            "Epoch 28 | Train loss 1.543 | Valid loss 1.721 | Valid acc 0.736\n",
            "Epoch 29 | Train loss 1.539 | Valid loss 1.727 | Valid acc 0.736\n",
            "Epoch 30 | Train loss 1.535 | Valid loss 1.725 | Valid acc 0.734\n",
            "Epoch 31 | Train loss 1.535 | Valid loss 1.722 | Valid acc 0.736\n",
            "Epoch 32 | Train loss 1.533 | Valid loss 1.723 | Valid acc 0.738\n",
            "Epoch 33 | Train loss 1.531 | Valid loss 1.716 | Valid acc 0.744\n",
            "Epoch 34 | Train loss 1.531 | Valid loss 1.719 | Valid acc 0.741\n",
            "Epoch 35 | Train loss 1.528 | Valid loss 1.721 | Valid acc 0.739\n",
            "Epoch 36 | Train loss 1.527 | Valid loss 1.726 | Valid acc 0.734\n",
            "Epoch 37 | Train loss 1.525 | Valid loss 1.725 | Valid acc 0.735\n",
            "Epoch 38 | Train loss 1.523 | Valid loss 1.733 | Valid acc 0.729\n",
            "Epoch 39 | Train loss 1.521 | Valid loss 1.724 | Valid acc 0.735\n",
            "Epoch 40 | Train loss 1.521 | Valid loss 1.732 | Valid acc 0.726\n",
            "Epoch 41 | Train loss 1.521 | Valid loss 1.722 | Valid acc 0.736\n",
            "Epoch 42 | Train loss 1.517 | Valid loss 1.728 | Valid acc 0.730\n",
            "Epoch 43 | Train loss 1.517 | Valid loss 1.726 | Valid acc 0.732\n",
            "Epoch 44 | Train loss 1.516 | Valid loss 1.723 | Valid acc 0.735\n",
            "Epoch 45 | Train loss 1.516 | Valid loss 1.723 | Valid acc 0.734\n",
            "Epoch 46 | Train loss 1.516 | Valid loss 1.727 | Valid acc 0.733\n",
            "Epoch 47 | Train loss 1.515 | Valid loss 1.727 | Valid acc 0.734\n",
            "Epoch 48 | Train loss 1.513 | Valid loss 1.727 | Valid acc 0.733\n",
            "Epoch 49 | Train loss 1.514 | Valid loss 1.728 | Valid acc 0.731\n",
            "Finally!\n",
            "best_valid_acc 0.744\n",
            "128 50 0.001 <class 'torch.optim.sgd.SGD'> 128\n",
            "Epoch 0 | Train loss 2.299 | Valid loss 2.293 | Valid acc 0.253\n",
            "Epoch 1 | Train loss 2.285 | Valid loss 2.273 | Valid acc 0.286\n",
            "Epoch 2 | Train loss 2.260 | Valid loss 2.238 | Valid acc 0.289\n",
            "Epoch 3 | Train loss 2.227 | Valid loss 2.202 | Valid acc 0.314\n",
            "Epoch 4 | Train loss 2.196 | Valid loss 2.171 | Valid acc 0.334\n",
            "Epoch 5 | Train loss 2.170 | Valid loss 2.147 | Valid acc 0.344\n",
            "Epoch 6 | Train loss 2.149 | Valid loss 2.129 | Valid acc 0.359\n",
            "Epoch 7 | Train loss 2.132 | Valid loss 2.110 | Valid acc 0.370\n",
            "Epoch 8 | Train loss 2.117 | Valid loss 2.098 | Valid acc 0.387\n",
            "Epoch 9 | Train loss 2.103 | Valid loss 2.082 | Valid acc 0.403\n",
            "Epoch 10 | Train loss 2.092 | Valid loss 2.070 | Valid acc 0.415\n",
            "Epoch 11 | Train loss 2.080 | Valid loss 2.061 | Valid acc 0.423\n",
            "Epoch 12 | Train loss 2.071 | Valid loss 2.052 | Valid acc 0.426\n",
            "Epoch 13 | Train loss 2.063 | Valid loss 2.045 | Valid acc 0.433\n",
            "Epoch 14 | Train loss 2.055 | Valid loss 2.036 | Valid acc 0.441\n",
            "Epoch 15 | Train loss 2.047 | Valid loss 2.031 | Valid acc 0.445\n",
            "Epoch 16 | Train loss 2.041 | Valid loss 2.021 | Valid acc 0.454\n",
            "Epoch 17 | Train loss 2.034 | Valid loss 2.016 | Valid acc 0.461\n",
            "Epoch 18 | Train loss 2.028 | Valid loss 2.012 | Valid acc 0.463\n",
            "Epoch 19 | Train loss 2.021 | Valid loss 2.007 | Valid acc 0.469\n",
            "Epoch 20 | Train loss 2.016 | Valid loss 2.001 | Valid acc 0.474\n",
            "Epoch 21 | Train loss 2.011 | Valid loss 1.997 | Valid acc 0.483\n",
            "Epoch 22 | Train loss 2.003 | Valid loss 1.990 | Valid acc 0.489\n",
            "Epoch 23 | Train loss 1.999 | Valid loss 1.986 | Valid acc 0.491\n",
            "Epoch 24 | Train loss 1.992 | Valid loss 1.978 | Valid acc 0.501\n",
            "Epoch 25 | Train loss 1.987 | Valid loss 1.976 | Valid acc 0.503\n",
            "Epoch 26 | Train loss 1.982 | Valid loss 1.971 | Valid acc 0.504\n",
            "Epoch 27 | Train loss 1.977 | Valid loss 1.967 | Valid acc 0.513\n",
            "Epoch 28 | Train loss 1.971 | Valid loss 1.959 | Valid acc 0.518\n",
            "Epoch 29 | Train loss 1.967 | Valid loss 1.959 | Valid acc 0.519\n",
            "Epoch 30 | Train loss 1.961 | Valid loss 1.953 | Valid acc 0.525\n",
            "Epoch 31 | Train loss 1.956 | Valid loss 1.947 | Valid acc 0.530\n",
            "Epoch 32 | Train loss 1.952 | Valid loss 1.945 | Valid acc 0.530\n",
            "Epoch 33 | Train loss 1.946 | Valid loss 1.940 | Valid acc 0.534\n",
            "Epoch 34 | Train loss 1.943 | Valid loss 1.937 | Valid acc 0.539\n",
            "Epoch 35 | Train loss 1.938 | Valid loss 1.933 | Valid acc 0.545\n",
            "Epoch 36 | Train loss 1.932 | Valid loss 1.931 | Valid acc 0.546\n",
            "Epoch 37 | Train loss 1.928 | Valid loss 1.928 | Valid acc 0.549\n",
            "Epoch 38 | Train loss 1.924 | Valid loss 1.922 | Valid acc 0.554\n",
            "Epoch 39 | Train loss 1.919 | Valid loss 1.920 | Valid acc 0.558\n",
            "Epoch 40 | Train loss 1.916 | Valid loss 1.917 | Valid acc 0.558\n",
            "Epoch 41 | Train loss 1.911 | Valid loss 1.913 | Valid acc 0.564\n",
            "Epoch 42 | Train loss 1.909 | Valid loss 1.910 | Valid acc 0.566\n",
            "Epoch 43 | Train loss 1.904 | Valid loss 1.906 | Valid acc 0.567\n",
            "Epoch 44 | Train loss 1.900 | Valid loss 1.902 | Valid acc 0.571\n",
            "Epoch 45 | Train loss 1.896 | Valid loss 1.900 | Valid acc 0.573\n",
            "Epoch 46 | Train loss 1.893 | Valid loss 1.897 | Valid acc 0.577\n",
            "Epoch 47 | Train loss 1.889 | Valid loss 1.898 | Valid acc 0.575\n",
            "Epoch 48 | Train loss 1.885 | Valid loss 1.893 | Valid acc 0.584\n",
            "Epoch 49 | Train loss 1.883 | Valid loss 1.889 | Valid acc 0.587\n",
            "Finally!\n",
            "best_valid_acc 0.5869\n",
            "128 50 0.001 <class 'torch.optim.adam.Adam'> 128\n",
            "Epoch 0 | Train loss 2.308 | Valid loss 2.302 | Valid acc 0.160\n",
            "Epoch 1 | Train loss 2.302 | Valid loss 2.293 | Valid acc 0.169\n",
            "Epoch 2 | Train loss 2.297 | Valid loss 2.307 | Valid acc 0.154\n",
            "Epoch 3 | Train loss 2.323 | Valid loss 2.362 | Valid acc 0.099\n",
            "Epoch 4 | Train loss 2.361 | Valid loss 2.363 | Valid acc 0.099\n",
            "Epoch 5 | Train loss 2.361 | Valid loss 2.362 | Valid acc 0.099\n",
            "Epoch 6 | Train loss 2.361 | Valid loss 2.362 | Valid acc 0.099\n",
            "Epoch 7 | Train loss 2.361 | Valid loss 2.360 | Valid acc 0.099\n",
            "Epoch 8 | Train loss 2.361 | Valid loss 2.362 | Valid acc 0.099\n",
            "Epoch 9 | Train loss 2.361 | Valid loss 2.362 | Valid acc 0.099\n",
            "Epoch 10 | Train loss 2.361 | Valid loss 2.362 | Valid acc 0.099\n",
            "Epoch 11 | Train loss 2.352 | Valid loss 2.334 | Valid acc 0.128\n",
            "Epoch 12 | Train loss 2.321 | Valid loss 2.331 | Valid acc 0.131\n",
            "Epoch 13 | Train loss 2.321 | Valid loss 2.324 | Valid acc 0.138\n",
            "Epoch 14 | Train loss 2.315 | Valid loss 2.363 | Valid acc 0.100\n",
            "Epoch 15 | Train loss 2.304 | Valid loss 2.301 | Valid acc 0.160\n",
            "Epoch 16 | Train loss 2.298 | Valid loss 2.301 | Valid acc 0.160\n",
            "Epoch 17 | Train loss 2.302 | Valid loss 2.309 | Valid acc 0.154\n",
            "Epoch 18 | Train loss 2.304 | Valid loss 2.310 | Valid acc 0.149\n",
            "Epoch 19 | Train loss 2.309 | Valid loss 2.313 | Valid acc 0.149\n",
            "Epoch 20 | Train loss 2.311 | Valid loss 2.312 | Valid acc 0.149\n",
            "Epoch 21 | Train loss 2.312 | Valid loss 2.316 | Valid acc 0.144\n",
            "Epoch 22 | Train loss 2.321 | Valid loss 2.299 | Valid acc 0.162\n",
            "Epoch 23 | Train loss 2.298 | Valid loss 2.297 | Valid acc 0.163\n",
            "Epoch 24 | Train loss 2.297 | Valid loss 2.297 | Valid acc 0.165\n",
            "Epoch 25 | Train loss 2.296 | Valid loss 2.300 | Valid acc 0.163\n",
            "Epoch 26 | Train loss 2.296 | Valid loss 2.298 | Valid acc 0.164\n",
            "Epoch 27 | Train loss 2.296 | Valid loss 2.298 | Valid acc 0.164\n",
            "Epoch 28 | Train loss 2.302 | Valid loss 2.305 | Valid acc 0.156\n",
            "Epoch 29 | Train loss 2.304 | Valid loss 2.304 | Valid acc 0.156\n",
            "Epoch 30 | Train loss 2.305 | Valid loss 2.308 | Valid acc 0.153\n",
            "Epoch 31 | Train loss 2.319 | Valid loss 2.323 | Valid acc 0.137\n",
            "Epoch 32 | Train loss 2.335 | Valid loss 2.339 | Valid acc 0.120\n",
            "Epoch 33 | Train loss 2.326 | Valid loss 2.325 | Valid acc 0.136\n",
            "Epoch 34 | Train loss 2.325 | Valid loss 2.324 | Valid acc 0.138\n",
            "Epoch 35 | Train loss 2.323 | Valid loss 2.327 | Valid acc 0.134\n",
            "Epoch 36 | Train loss 2.329 | Valid loss 2.337 | Valid acc 0.124\n",
            "Epoch 37 | Train loss 2.332 | Valid loss 2.316 | Valid acc 0.146\n",
            "Epoch 38 | Train loss 2.311 | Valid loss 2.316 | Valid acc 0.146\n",
            "Epoch 39 | Train loss 2.312 | Valid loss 2.314 | Valid acc 0.147\n",
            "Epoch 40 | Train loss 2.312 | Valid loss 2.312 | Valid acc 0.148\n",
            "Epoch 41 | Train loss 2.317 | Valid loss 2.311 | Valid acc 0.150\n",
            "Epoch 42 | Train loss 2.336 | Valid loss 2.354 | Valid acc 0.108\n",
            "Epoch 43 | Train loss 2.354 | Valid loss 2.354 | Valid acc 0.107\n",
            "Epoch 44 | Train loss 2.356 | Valid loss 2.361 | Valid acc 0.100\n",
            "Epoch 45 | Train loss 2.361 | Valid loss 2.362 | Valid acc 0.099\n",
            "Epoch 46 | Train loss 2.361 | Valid loss 2.362 | Valid acc 0.099\n",
            "Epoch 47 | Train loss 2.361 | Valid loss 2.361 | Valid acc 0.099\n",
            "Epoch 48 | Train loss 2.361 | Valid loss 2.362 | Valid acc 0.099\n",
            "Epoch 49 | Train loss 2.361 | Valid loss 2.362 | Valid acc 0.099\n",
            "Finally!\n",
            "best_valid_acc 0.1689\n",
            "256 30 0.0002 <class 'torch.optim.sgd.SGD'> 128\n",
            "Epoch 0 | Train loss 2.301 | Valid loss 2.299 | Valid acc 0.181\n",
            "Epoch 1 | Train loss 2.297 | Valid loss 2.294 | Valid acc 0.214\n",
            "Epoch 2 | Train loss 2.291 | Valid loss 2.286 | Valid acc 0.235\n",
            "Epoch 3 | Train loss 2.283 | Valid loss 2.277 | Valid acc 0.253\n",
            "Epoch 4 | Train loss 2.273 | Valid loss 2.266 | Valid acc 0.255\n",
            "Epoch 5 | Train loss 2.263 | Valid loss 2.256 | Valid acc 0.257\n",
            "Epoch 6 | Train loss 2.252 | Valid loss 2.243 | Valid acc 0.263\n",
            "Epoch 7 | Train loss 2.242 | Valid loss 2.233 | Valid acc 0.272\n",
            "Epoch 8 | Train loss 2.232 | Valid loss 2.223 | Valid acc 0.284\n",
            "Epoch 9 | Train loss 2.222 | Valid loss 2.212 | Valid acc 0.295\n",
            "Epoch 10 | Train loss 2.213 | Valid loss 2.202 | Valid acc 0.305\n",
            "Epoch 11 | Train loss 2.205 | Valid loss 2.194 | Valid acc 0.314\n",
            "Epoch 12 | Train loss 2.196 | Valid loss 2.183 | Valid acc 0.324\n",
            "Epoch 13 | Train loss 2.188 | Valid loss 2.174 | Valid acc 0.333\n",
            "Epoch 14 | Train loss 2.180 | Valid loss 2.166 | Valid acc 0.338\n",
            "Epoch 15 | Train loss 2.173 | Valid loss 2.158 | Valid acc 0.344\n",
            "Epoch 16 | Train loss 2.166 | Valid loss 2.149 | Valid acc 0.350\n",
            "Epoch 17 | Train loss 2.159 | Valid loss 2.142 | Valid acc 0.357\n",
            "Epoch 18 | Train loss 2.154 | Valid loss 2.136 | Valid acc 0.362\n",
            "Epoch 19 | Train loss 2.148 | Valid loss 2.131 | Valid acc 0.368\n",
            "Epoch 20 | Train loss 2.140 | Valid loss 2.125 | Valid acc 0.372\n",
            "Epoch 21 | Train loss 2.135 | Valid loss 2.118 | Valid acc 0.377\n",
            "Epoch 22 | Train loss 2.130 | Valid loss 2.115 | Valid acc 0.383\n",
            "Epoch 23 | Train loss 2.126 | Valid loss 2.107 | Valid acc 0.388\n",
            "Epoch 24 | Train loss 2.121 | Valid loss 2.104 | Valid acc 0.390\n",
            "Epoch 25 | Train loss 2.116 | Valid loss 2.100 | Valid acc 0.394\n",
            "Epoch 26 | Train loss 2.113 | Valid loss 2.095 | Valid acc 0.398\n",
            "Epoch 27 | Train loss 2.109 | Valid loss 2.091 | Valid acc 0.400\n",
            "Epoch 28 | Train loss 2.106 | Valid loss 2.087 | Valid acc 0.402\n",
            "Epoch 29 | Train loss 2.102 | Valid loss 2.083 | Valid acc 0.407\n",
            "Finally!\n",
            "best_valid_acc 0.4067\n",
            "256 30 0.0002 <class 'torch.optim.adam.Adam'> 128\n",
            "Epoch 0 | Train loss 2.182 | Valid loss 2.127 | Valid acc 0.330\n",
            "Epoch 1 | Train loss 2.126 | Valid loss 2.088 | Valid acc 0.371\n",
            "Epoch 2 | Train loss 2.097 | Valid loss 2.086 | Valid acc 0.371\n",
            "Epoch 3 | Train loss 2.073 | Valid loss 2.032 | Valid acc 0.427\n",
            "Epoch 4 | Train loss 2.047 | Valid loss 2.020 | Valid acc 0.438\n",
            "Epoch 5 | Train loss 2.022 | Valid loss 1.989 | Valid acc 0.468\n",
            "Epoch 6 | Train loss 2.005 | Valid loss 1.990 | Valid acc 0.468\n",
            "Epoch 7 | Train loss 1.990 | Valid loss 1.984 | Valid acc 0.477\n",
            "Epoch 8 | Train loss 1.979 | Valid loss 1.961 | Valid acc 0.498\n",
            "Epoch 9 | Train loss 1.969 | Valid loss 1.950 | Valid acc 0.510\n",
            "Epoch 10 | Train loss 1.953 | Valid loss 1.941 | Valid acc 0.519\n",
            "Epoch 11 | Train loss 1.946 | Valid loss 1.936 | Valid acc 0.522\n",
            "Epoch 12 | Train loss 1.939 | Valid loss 1.924 | Valid acc 0.537\n",
            "Epoch 13 | Train loss 1.929 | Valid loss 1.935 | Valid acc 0.524\n",
            "Epoch 14 | Train loss 1.927 | Valid loss 1.959 | Valid acc 0.499\n",
            "Epoch 15 | Train loss 1.916 | Valid loss 1.909 | Valid acc 0.551\n",
            "Epoch 16 | Train loss 1.904 | Valid loss 1.905 | Valid acc 0.557\n",
            "Epoch 17 | Train loss 1.896 | Valid loss 1.908 | Valid acc 0.551\n",
            "Epoch 18 | Train loss 1.887 | Valid loss 1.899 | Valid acc 0.563\n",
            "Epoch 19 | Train loss 1.885 | Valid loss 1.900 | Valid acc 0.564\n",
            "Epoch 20 | Train loss 1.878 | Valid loss 1.884 | Valid acc 0.574\n",
            "Epoch 21 | Train loss 1.867 | Valid loss 1.902 | Valid acc 0.562\n",
            "Epoch 22 | Train loss 1.860 | Valid loss 1.878 | Valid acc 0.580\n",
            "Epoch 23 | Train loss 1.856 | Valid loss 1.873 | Valid acc 0.586\n",
            "Epoch 24 | Train loss 1.854 | Valid loss 1.872 | Valid acc 0.588\n",
            "Epoch 25 | Train loss 1.850 | Valid loss 1.867 | Valid acc 0.593\n",
            "Epoch 26 | Train loss 1.839 | Valid loss 1.857 | Valid acc 0.602\n",
            "Epoch 27 | Train loss 1.837 | Valid loss 1.854 | Valid acc 0.607\n",
            "Epoch 28 | Train loss 1.830 | Valid loss 1.839 | Valid acc 0.618\n",
            "Epoch 29 | Train loss 1.827 | Valid loss 1.850 | Valid acc 0.609\n",
            "Finally!\n",
            "best_valid_acc 0.6182\n",
            "256 30 0.0001 <class 'torch.optim.sgd.SGD'> 128\n",
            "Epoch 0 | Train loss 2.302 | Valid loss 2.301 | Valid acc 0.128\n",
            "Epoch 1 | Train loss 2.299 | Valid loss 2.298 | Valid acc 0.126\n",
            "Epoch 2 | Train loss 2.297 | Valid loss 2.295 | Valid acc 0.128\n",
            "Epoch 3 | Train loss 2.293 | Valid loss 2.291 | Valid acc 0.142\n",
            "Epoch 4 | Train loss 2.289 | Valid loss 2.286 | Valid acc 0.157\n",
            "Epoch 5 | Train loss 2.284 | Valid loss 2.280 | Valid acc 0.163\n",
            "Epoch 6 | Train loss 2.279 | Valid loss 2.275 | Valid acc 0.176\n",
            "Epoch 7 | Train loss 2.274 | Valid loss 2.270 | Valid acc 0.190\n",
            "Epoch 8 | Train loss 2.268 | Valid loss 2.264 | Valid acc 0.203\n",
            "Epoch 9 | Train loss 2.263 | Valid loss 2.260 | Valid acc 0.214\n",
            "Epoch 10 | Train loss 2.258 | Valid loss 2.253 | Valid acc 0.221\n",
            "Epoch 11 | Train loss 2.253 | Valid loss 2.248 | Valid acc 0.230\n",
            "Epoch 12 | Train loss 2.248 | Valid loss 2.242 | Valid acc 0.233\n",
            "Epoch 13 | Train loss 2.242 | Valid loss 2.236 | Valid acc 0.241\n",
            "Epoch 14 | Train loss 2.237 | Valid loss 2.229 | Valid acc 0.247\n",
            "Epoch 15 | Train loss 2.232 | Valid loss 2.224 | Valid acc 0.251\n",
            "Epoch 16 | Train loss 2.228 | Valid loss 2.220 | Valid acc 0.256\n",
            "Epoch 17 | Train loss 2.223 | Valid loss 2.213 | Valid acc 0.259\n",
            "Epoch 18 | Train loss 2.219 | Valid loss 2.208 | Valid acc 0.260\n",
            "Epoch 19 | Train loss 2.213 | Valid loss 2.204 | Valid acc 0.264\n",
            "Epoch 20 | Train loss 2.210 | Valid loss 2.200 | Valid acc 0.269\n",
            "Epoch 21 | Train loss 2.206 | Valid loss 2.196 | Valid acc 0.274\n",
            "Epoch 22 | Train loss 2.203 | Valid loss 2.192 | Valid acc 0.280\n",
            "Epoch 23 | Train loss 2.198 | Valid loss 2.187 | Valid acc 0.284\n",
            "Epoch 24 | Train loss 2.195 | Valid loss 2.185 | Valid acc 0.290\n",
            "Epoch 25 | Train loss 2.193 | Valid loss 2.180 | Valid acc 0.293\n",
            "Epoch 26 | Train loss 2.189 | Valid loss 2.177 | Valid acc 0.300\n",
            "Epoch 27 | Train loss 2.186 | Valid loss 2.175 | Valid acc 0.304\n",
            "Epoch 28 | Train loss 2.183 | Valid loss 2.173 | Valid acc 0.308\n",
            "Epoch 29 | Train loss 2.180 | Valid loss 2.168 | Valid acc 0.315\n",
            "Finally!\n",
            "best_valid_acc 0.3149\n",
            "256 30 0.0001 <class 'torch.optim.adam.Adam'> 128\n",
            "Epoch 0 | Train loss 2.103 | Valid loss 1.995 | Valid acc 0.464\n",
            "Epoch 1 | Train loss 1.997 | Valid loss 1.965 | Valid acc 0.495\n",
            "Epoch 2 | Train loss 1.961 | Valid loss 1.943 | Valid acc 0.515\n",
            "Epoch 3 | Train loss 1.928 | Valid loss 1.922 | Valid acc 0.537\n",
            "Epoch 4 | Train loss 1.903 | Valid loss 1.903 | Valid acc 0.557\n",
            "Epoch 5 | Train loss 1.876 | Valid loss 1.884 | Valid acc 0.572\n",
            "Epoch 6 | Train loss 1.851 | Valid loss 1.856 | Valid acc 0.603\n",
            "Epoch 7 | Train loss 1.827 | Valid loss 1.809 | Valid acc 0.648\n",
            "Epoch 8 | Train loss 1.793 | Valid loss 1.798 | Valid acc 0.661\n",
            "Epoch 9 | Train loss 1.767 | Valid loss 1.786 | Valid acc 0.672\n",
            "Epoch 10 | Train loss 1.751 | Valid loss 1.794 | Valid acc 0.663\n",
            "Epoch 11 | Train loss 1.730 | Valid loss 1.765 | Valid acc 0.695\n",
            "Epoch 12 | Train loss 1.718 | Valid loss 1.763 | Valid acc 0.698\n",
            "Epoch 13 | Train loss 1.706 | Valid loss 1.756 | Valid acc 0.702\n",
            "Epoch 14 | Train loss 1.693 | Valid loss 1.760 | Valid acc 0.700\n",
            "Epoch 15 | Train loss 1.683 | Valid loss 1.751 | Valid acc 0.708\n",
            "Epoch 16 | Train loss 1.672 | Valid loss 1.742 | Valid acc 0.718\n",
            "Epoch 17 | Train loss 1.661 | Valid loss 1.737 | Valid acc 0.722\n",
            "Epoch 18 | Train loss 1.652 | Valid loss 1.734 | Valid acc 0.728\n",
            "Epoch 19 | Train loss 1.643 | Valid loss 1.735 | Valid acc 0.726\n",
            "Epoch 20 | Train loss 1.636 | Valid loss 1.733 | Valid acc 0.726\n",
            "Epoch 21 | Train loss 1.625 | Valid loss 1.729 | Valid acc 0.731\n",
            "Epoch 22 | Train loss 1.619 | Valid loss 1.729 | Valid acc 0.732\n",
            "Epoch 23 | Train loss 1.614 | Valid loss 1.729 | Valid acc 0.731\n",
            "Epoch 24 | Train loss 1.610 | Valid loss 1.725 | Valid acc 0.735\n",
            "Epoch 25 | Train loss 1.604 | Valid loss 1.733 | Valid acc 0.725\n",
            "Epoch 26 | Train loss 1.602 | Valid loss 1.730 | Valid acc 0.729\n",
            "Epoch 27 | Train loss 1.591 | Valid loss 1.721 | Valid acc 0.739\n",
            "Epoch 28 | Train loss 1.591 | Valid loss 1.720 | Valid acc 0.738\n",
            "Epoch 29 | Train loss 1.583 | Valid loss 1.723 | Valid acc 0.736\n",
            "Finally!\n",
            "best_valid_acc 0.7391\n",
            "256 30 0.001 <class 'torch.optim.sgd.SGD'> 128\n",
            "Epoch 0 | Train loss 2.285 | Valid loss 2.256 | Valid acc 0.229\n",
            "Epoch 1 | Train loss 2.233 | Valid loss 2.204 | Valid acc 0.279\n",
            "Epoch 2 | Train loss 2.190 | Valid loss 2.160 | Valid acc 0.339\n",
            "Epoch 3 | Train loss 2.155 | Valid loss 2.123 | Valid acc 0.374\n",
            "Epoch 4 | Train loss 2.126 | Valid loss 2.099 | Valid acc 0.395\n",
            "Epoch 5 | Train loss 2.105 | Valid loss 2.078 | Valid acc 0.411\n",
            "Epoch 6 | Train loss 2.088 | Valid loss 2.066 | Valid acc 0.420\n",
            "Epoch 7 | Train loss 2.074 | Valid loss 2.052 | Valid acc 0.428\n",
            "Epoch 8 | Train loss 2.063 | Valid loss 2.040 | Valid acc 0.436\n",
            "Epoch 9 | Train loss 2.053 | Valid loss 2.033 | Valid acc 0.444\n",
            "Epoch 10 | Train loss 2.042 | Valid loss 2.026 | Valid acc 0.451\n",
            "Epoch 11 | Train loss 2.034 | Valid loss 2.019 | Valid acc 0.462\n",
            "Epoch 12 | Train loss 2.026 | Valid loss 2.008 | Valid acc 0.468\n",
            "Epoch 13 | Train loss 2.017 | Valid loss 2.003 | Valid acc 0.478\n",
            "Epoch 14 | Train loss 2.009 | Valid loss 1.993 | Valid acc 0.485\n",
            "Epoch 15 | Train loss 2.002 | Valid loss 1.986 | Valid acc 0.496\n",
            "Epoch 16 | Train loss 1.993 | Valid loss 1.979 | Valid acc 0.502\n",
            "Epoch 17 | Train loss 1.984 | Valid loss 1.971 | Valid acc 0.512\n",
            "Epoch 18 | Train loss 1.978 | Valid loss 1.965 | Valid acc 0.517\n",
            "Epoch 19 | Train loss 1.969 | Valid loss 1.957 | Valid acc 0.523\n",
            "Epoch 20 | Train loss 1.963 | Valid loss 1.950 | Valid acc 0.530\n",
            "Epoch 21 | Train loss 1.955 | Valid loss 1.945 | Valid acc 0.538\n",
            "Epoch 22 | Train loss 1.950 | Valid loss 1.939 | Valid acc 0.541\n",
            "Epoch 23 | Train loss 1.943 | Valid loss 1.934 | Valid acc 0.544\n",
            "Epoch 24 | Train loss 1.937 | Valid loss 1.928 | Valid acc 0.552\n",
            "Epoch 25 | Train loss 1.931 | Valid loss 1.923 | Valid acc 0.557\n",
            "Epoch 26 | Train loss 1.925 | Valid loss 1.920 | Valid acc 0.558\n",
            "Epoch 27 | Train loss 1.920 | Valid loss 1.914 | Valid acc 0.565\n",
            "Epoch 28 | Train loss 1.913 | Valid loss 1.911 | Valid acc 0.570\n",
            "Epoch 29 | Train loss 1.909 | Valid loss 1.905 | Valid acc 0.573\n",
            "Finally!\n",
            "best_valid_acc 0.573\n",
            "256 30 0.001 <class 'torch.optim.adam.Adam'> 128\n",
            "Epoch 0 | Train loss 2.362 | Valid loss 2.358 | Valid acc 0.103\n",
            "Epoch 1 | Train loss 2.362 | Valid loss 2.358 | Valid acc 0.103\n",
            "Epoch 2 | Train loss 2.362 | Valid loss 2.359 | Valid acc 0.103\n",
            "Epoch 3 | Train loss 2.362 | Valid loss 2.357 | Valid acc 0.103\n",
            "Epoch 4 | Train loss 2.362 | Valid loss 2.359 | Valid acc 0.103\n",
            "Epoch 5 | Train loss 2.362 | Valid loss 2.359 | Valid acc 0.103\n",
            "Epoch 6 | Train loss 2.362 | Valid loss 2.359 | Valid acc 0.103\n",
            "Epoch 7 | Train loss 2.362 | Valid loss 2.357 | Valid acc 0.103\n",
            "Epoch 8 | Train loss 2.362 | Valid loss 2.359 | Valid acc 0.103\n",
            "Epoch 9 | Train loss 2.362 | Valid loss 2.359 | Valid acc 0.103\n",
            "Epoch 10 | Train loss 2.362 | Valid loss 2.357 | Valid acc 0.103\n",
            "Epoch 11 | Train loss 2.362 | Valid loss 2.359 | Valid acc 0.103\n",
            "Epoch 12 | Train loss 2.362 | Valid loss 2.359 | Valid acc 0.103\n",
            "Epoch 13 | Train loss 2.362 | Valid loss 2.359 | Valid acc 0.103\n",
            "Epoch 14 | Train loss 2.362 | Valid loss 2.358 | Valid acc 0.103\n",
            "Epoch 15 | Train loss 2.362 | Valid loss 2.357 | Valid acc 0.103\n",
            "Epoch 16 | Train loss 2.362 | Valid loss 2.358 | Valid acc 0.103\n",
            "Epoch 17 | Train loss 2.362 | Valid loss 2.358 | Valid acc 0.103\n",
            "Epoch 18 | Train loss 2.362 | Valid loss 2.358 | Valid acc 0.103\n",
            "Epoch 19 | Train loss 2.362 | Valid loss 2.358 | Valid acc 0.103\n",
            "Epoch 20 | Train loss 2.362 | Valid loss 2.358 | Valid acc 0.103\n",
            "Epoch 21 | Train loss 2.362 | Valid loss 2.359 | Valid acc 0.103\n",
            "Epoch 22 | Train loss 2.362 | Valid loss 2.357 | Valid acc 0.103\n",
            "Epoch 23 | Train loss 2.362 | Valid loss 2.358 | Valid acc 0.103\n",
            "Epoch 24 | Train loss 2.362 | Valid loss 2.357 | Valid acc 0.103\n",
            "Epoch 25 | Train loss 2.362 | Valid loss 2.357 | Valid acc 0.103\n",
            "Epoch 26 | Train loss 2.362 | Valid loss 2.359 | Valid acc 0.103\n",
            "Epoch 27 | Train loss 2.362 | Valid loss 2.359 | Valid acc 0.103\n",
            "Epoch 28 | Train loss 2.362 | Valid loss 2.358 | Valid acc 0.103\n",
            "Epoch 29 | Train loss 2.362 | Valid loss 2.357 | Valid acc 0.103\n",
            "Finally!\n",
            "best_valid_acc 0.1028\n",
            "256 50 0.0002 <class 'torch.optim.sgd.SGD'> 128\n",
            "Epoch 0 | Train loss 2.301 | Valid loss 2.298 | Valid acc 0.214\n",
            "Epoch 1 | Train loss 2.295 | Valid loss 2.292 | Valid acc 0.227\n",
            "Epoch 2 | Train loss 2.288 | Valid loss 2.282 | Valid acc 0.223\n",
            "Epoch 3 | Train loss 2.278 | Valid loss 2.271 | Valid acc 0.232\n",
            "Epoch 4 | Train loss 2.267 | Valid loss 2.259 | Valid acc 0.258\n",
            "Epoch 5 | Train loss 2.256 | Valid loss 2.248 | Valid acc 0.264\n",
            "Epoch 6 | Train loss 2.246 | Valid loss 2.238 | Valid acc 0.267\n",
            "Epoch 7 | Train loss 2.238 | Valid loss 2.228 | Valid acc 0.274\n",
            "Epoch 8 | Train loss 2.229 | Valid loss 2.219 | Valid acc 0.284\n",
            "Epoch 9 | Train loss 2.221 | Valid loss 2.210 | Valid acc 0.291\n",
            "Epoch 10 | Train loss 2.212 | Valid loss 2.200 | Valid acc 0.301\n",
            "Epoch 11 | Train loss 2.204 | Valid loss 2.192 | Valid acc 0.307\n",
            "Epoch 12 | Train loss 2.197 | Valid loss 2.185 | Valid acc 0.315\n",
            "Epoch 13 | Train loss 2.189 | Valid loss 2.176 | Valid acc 0.320\n",
            "Epoch 14 | Train loss 2.184 | Valid loss 2.171 | Valid acc 0.329\n",
            "Epoch 15 | Train loss 2.177 | Valid loss 2.163 | Valid acc 0.339\n",
            "Epoch 16 | Train loss 2.170 | Valid loss 2.155 | Valid acc 0.348\n",
            "Epoch 17 | Train loss 2.164 | Valid loss 2.149 | Valid acc 0.358\n",
            "Epoch 18 | Train loss 2.158 | Valid loss 2.141 | Valid acc 0.365\n",
            "Epoch 19 | Train loss 2.151 | Valid loss 2.133 | Valid acc 0.372\n",
            "Epoch 20 | Train loss 2.146 | Valid loss 2.127 | Valid acc 0.378\n",
            "Epoch 21 | Train loss 2.140 | Valid loss 2.121 | Valid acc 0.382\n",
            "Epoch 22 | Train loss 2.135 | Valid loss 2.115 | Valid acc 0.385\n",
            "Epoch 23 | Train loss 2.129 | Valid loss 2.109 | Valid acc 0.389\n",
            "Epoch 24 | Train loss 2.123 | Valid loss 2.104 | Valid acc 0.392\n",
            "Epoch 25 | Train loss 2.119 | Valid loss 2.098 | Valid acc 0.394\n",
            "Epoch 26 | Train loss 2.115 | Valid loss 2.095 | Valid acc 0.395\n",
            "Epoch 27 | Train loss 2.110 | Valid loss 2.091 | Valid acc 0.398\n",
            "Epoch 28 | Train loss 2.107 | Valid loss 2.088 | Valid acc 0.400\n",
            "Epoch 29 | Train loss 2.103 | Valid loss 2.083 | Valid acc 0.403\n",
            "Epoch 30 | Train loss 2.099 | Valid loss 2.080 | Valid acc 0.407\n",
            "Epoch 31 | Train loss 2.097 | Valid loss 2.074 | Valid acc 0.408\n",
            "Epoch 32 | Train loss 2.092 | Valid loss 2.073 | Valid acc 0.409\n",
            "Epoch 33 | Train loss 2.089 | Valid loss 2.068 | Valid acc 0.414\n",
            "Epoch 34 | Train loss 2.086 | Valid loss 2.067 | Valid acc 0.415\n",
            "Epoch 35 | Train loss 2.082 | Valid loss 2.063 | Valid acc 0.418\n",
            "Epoch 36 | Train loss 2.078 | Valid loss 2.060 | Valid acc 0.421\n",
            "Epoch 37 | Train loss 2.076 | Valid loss 2.059 | Valid acc 0.424\n",
            "Epoch 38 | Train loss 2.074 | Valid loss 2.054 | Valid acc 0.426\n",
            "Epoch 39 | Train loss 2.071 | Valid loss 2.050 | Valid acc 0.429\n",
            "Epoch 40 | Train loss 2.068 | Valid loss 2.050 | Valid acc 0.431\n",
            "Epoch 41 | Train loss 2.065 | Valid loss 2.049 | Valid acc 0.433\n",
            "Epoch 42 | Train loss 2.064 | Valid loss 2.044 | Valid acc 0.435\n",
            "Epoch 43 | Train loss 2.061 | Valid loss 2.040 | Valid acc 0.440\n",
            "Epoch 44 | Train loss 2.058 | Valid loss 2.038 | Valid acc 0.440\n",
            "Epoch 45 | Train loss 2.055 | Valid loss 2.035 | Valid acc 0.442\n",
            "Epoch 46 | Train loss 2.053 | Valid loss 2.036 | Valid acc 0.445\n",
            "Epoch 47 | Train loss 2.052 | Valid loss 2.034 | Valid acc 0.449\n",
            "Epoch 48 | Train loss 2.049 | Valid loss 2.030 | Valid acc 0.453\n",
            "Epoch 49 | Train loss 2.045 | Valid loss 2.028 | Valid acc 0.454\n",
            "Finally!\n",
            "best_valid_acc 0.4542\n",
            "256 50 0.0002 <class 'torch.optim.adam.Adam'> 128\n",
            "Epoch 0 | Train loss 2.154 | Valid loss 2.082 | Valid acc 0.378\n",
            "Epoch 1 | Train loss 2.073 | Valid loss 2.029 | Valid acc 0.431\n",
            "Epoch 2 | Train loss 2.030 | Valid loss 2.000 | Valid acc 0.457\n",
            "Epoch 3 | Train loss 2.003 | Valid loss 1.983 | Valid acc 0.476\n",
            "Epoch 4 | Train loss 1.981 | Valid loss 1.964 | Valid acc 0.494\n",
            "Epoch 5 | Train loss 1.944 | Valid loss 1.936 | Valid acc 0.521\n",
            "Epoch 6 | Train loss 1.913 | Valid loss 1.915 | Valid acc 0.545\n",
            "Epoch 7 | Train loss 1.897 | Valid loss 1.905 | Valid acc 0.555\n",
            "Epoch 8 | Train loss 1.876 | Valid loss 1.896 | Valid acc 0.565\n",
            "Epoch 9 | Train loss 1.863 | Valid loss 1.921 | Valid acc 0.538\n",
            "Epoch 10 | Train loss 1.847 | Valid loss 1.845 | Valid acc 0.614\n",
            "Epoch 11 | Train loss 1.834 | Valid loss 1.863 | Valid acc 0.597\n",
            "Epoch 12 | Train loss 1.826 | Valid loss 1.844 | Valid acc 0.617\n",
            "Epoch 13 | Train loss 1.809 | Valid loss 1.825 | Valid acc 0.636\n",
            "Epoch 14 | Train loss 1.802 | Valid loss 1.826 | Valid acc 0.633\n",
            "Epoch 15 | Train loss 1.795 | Valid loss 1.817 | Valid acc 0.642\n",
            "Epoch 16 | Train loss 1.783 | Valid loss 1.810 | Valid acc 0.651\n",
            "Epoch 17 | Train loss 1.774 | Valid loss 1.799 | Valid acc 0.660\n",
            "Epoch 18 | Train loss 1.767 | Valid loss 1.783 | Valid acc 0.676\n",
            "Epoch 19 | Train loss 1.752 | Valid loss 1.793 | Valid acc 0.665\n",
            "Epoch 20 | Train loss 1.747 | Valid loss 1.817 | Valid acc 0.644\n",
            "Epoch 21 | Train loss 1.743 | Valid loss 1.789 | Valid acc 0.669\n",
            "Epoch 22 | Train loss 1.738 | Valid loss 1.781 | Valid acc 0.679\n",
            "Epoch 23 | Train loss 1.731 | Valid loss 1.777 | Valid acc 0.684\n",
            "Epoch 24 | Train loss 1.728 | Valid loss 1.802 | Valid acc 0.655\n",
            "Epoch 25 | Train loss 1.717 | Valid loss 1.769 | Valid acc 0.692\n",
            "Epoch 26 | Train loss 1.713 | Valid loss 1.765 | Valid acc 0.694\n",
            "Epoch 27 | Train loss 1.706 | Valid loss 1.765 | Valid acc 0.696\n",
            "Epoch 28 | Train loss 1.701 | Valid loss 1.763 | Valid acc 0.696\n",
            "Epoch 29 | Train loss 1.698 | Valid loss 1.769 | Valid acc 0.694\n",
            "Epoch 30 | Train loss 1.689 | Valid loss 1.761 | Valid acc 0.697\n",
            "Epoch 31 | Train loss 1.684 | Valid loss 1.770 | Valid acc 0.691\n",
            "Epoch 32 | Train loss 1.679 | Valid loss 1.765 | Valid acc 0.695\n",
            "Epoch 33 | Train loss 1.672 | Valid loss 1.771 | Valid acc 0.688\n",
            "Epoch 34 | Train loss 1.672 | Valid loss 1.758 | Valid acc 0.700\n",
            "Epoch 35 | Train loss 1.665 | Valid loss 1.748 | Valid acc 0.712\n",
            "Epoch 36 | Train loss 1.663 | Valid loss 1.760 | Valid acc 0.699\n",
            "Epoch 37 | Train loss 1.657 | Valid loss 1.749 | Valid acc 0.709\n",
            "Epoch 38 | Train loss 1.651 | Valid loss 1.744 | Valid acc 0.714\n",
            "Epoch 39 | Train loss 1.650 | Valid loss 1.746 | Valid acc 0.713\n",
            "Epoch 40 | Train loss 1.645 | Valid loss 1.753 | Valid acc 0.707\n",
            "Epoch 41 | Train loss 1.640 | Valid loss 1.742 | Valid acc 0.720\n",
            "Epoch 42 | Train loss 1.640 | Valid loss 1.750 | Valid acc 0.711\n",
            "Epoch 43 | Train loss 1.635 | Valid loss 1.738 | Valid acc 0.725\n",
            "Epoch 44 | Train loss 1.632 | Valid loss 1.747 | Valid acc 0.713\n",
            "Epoch 45 | Train loss 1.627 | Valid loss 1.744 | Valid acc 0.713\n",
            "Epoch 46 | Train loss 1.626 | Valid loss 1.744 | Valid acc 0.715\n",
            "Epoch 47 | Train loss 1.624 | Valid loss 1.749 | Valid acc 0.709\n",
            "Epoch 48 | Train loss 1.623 | Valid loss 1.738 | Valid acc 0.721\n",
            "Epoch 49 | Train loss 1.623 | Valid loss 1.749 | Valid acc 0.711\n",
            "Finally!\n",
            "best_valid_acc 0.7246\n",
            "256 50 0.0001 <class 'torch.optim.sgd.SGD'> 128\n",
            "Epoch 0 | Train loss 2.302 | Valid loss 2.301 | Valid acc 0.131\n",
            "Epoch 1 | Train loss 2.301 | Valid loss 2.300 | Valid acc 0.133\n",
            "Epoch 2 | Train loss 2.299 | Valid loss 2.298 | Valid acc 0.138\n",
            "Epoch 3 | Train loss 2.297 | Valid loss 2.296 | Valid acc 0.144\n",
            "Epoch 4 | Train loss 2.295 | Valid loss 2.292 | Valid acc 0.156\n",
            "Epoch 5 | Train loss 2.291 | Valid loss 2.289 | Valid acc 0.169\n",
            "Epoch 6 | Train loss 2.288 | Valid loss 2.284 | Valid acc 0.179\n",
            "Epoch 7 | Train loss 2.284 | Valid loss 2.280 | Valid acc 0.192\n",
            "Epoch 8 | Train loss 2.280 | Valid loss 2.276 | Valid acc 0.207\n",
            "Epoch 9 | Train loss 2.275 | Valid loss 2.271 | Valid acc 0.220\n",
            "Epoch 10 | Train loss 2.270 | Valid loss 2.265 | Valid acc 0.231\n",
            "Epoch 11 | Train loss 2.265 | Valid loss 2.261 | Valid acc 0.238\n",
            "Epoch 12 | Train loss 2.260 | Valid loss 2.254 | Valid acc 0.244\n",
            "Epoch 13 | Train loss 2.255 | Valid loss 2.250 | Valid acc 0.251\n",
            "Epoch 14 | Train loss 2.249 | Valid loss 2.242 | Valid acc 0.254\n",
            "Epoch 15 | Train loss 2.244 | Valid loss 2.237 | Valid acc 0.260\n",
            "Epoch 16 | Train loss 2.239 | Valid loss 2.231 | Valid acc 0.265\n",
            "Epoch 17 | Train loss 2.234 | Valid loss 2.227 | Valid acc 0.272\n",
            "Epoch 18 | Train loss 2.230 | Valid loss 2.221 | Valid acc 0.281\n",
            "Epoch 19 | Train loss 2.225 | Valid loss 2.216 | Valid acc 0.286\n",
            "Epoch 20 | Train loss 2.221 | Valid loss 2.213 | Valid acc 0.295\n",
            "Epoch 21 | Train loss 2.216 | Valid loss 2.207 | Valid acc 0.301\n",
            "Epoch 22 | Train loss 2.212 | Valid loss 2.204 | Valid acc 0.308\n",
            "Epoch 23 | Train loss 2.208 | Valid loss 2.199 | Valid acc 0.313\n",
            "Epoch 24 | Train loss 2.204 | Valid loss 2.195 | Valid acc 0.318\n",
            "Epoch 25 | Train loss 2.200 | Valid loss 2.190 | Valid acc 0.322\n",
            "Epoch 26 | Train loss 2.196 | Valid loss 2.187 | Valid acc 0.331\n",
            "Epoch 27 | Train loss 2.193 | Valid loss 2.182 | Valid acc 0.338\n",
            "Epoch 28 | Train loss 2.189 | Valid loss 2.177 | Valid acc 0.342\n",
            "Epoch 29 | Train loss 2.185 | Valid loss 2.174 | Valid acc 0.347\n",
            "Epoch 30 | Train loss 2.181 | Valid loss 2.169 | Valid acc 0.351\n",
            "Epoch 31 | Train loss 2.178 | Valid loss 2.165 | Valid acc 0.355\n",
            "Epoch 32 | Train loss 2.174 | Valid loss 2.161 | Valid acc 0.358\n",
            "Epoch 33 | Train loss 2.171 | Valid loss 2.156 | Valid acc 0.360\n",
            "Epoch 34 | Train loss 2.166 | Valid loss 2.154 | Valid acc 0.362\n",
            "Epoch 35 | Train loss 2.163 | Valid loss 2.151 | Valid acc 0.364\n",
            "Epoch 36 | Train loss 2.160 | Valid loss 2.146 | Valid acc 0.365\n",
            "Epoch 37 | Train loss 2.157 | Valid loss 2.142 | Valid acc 0.367\n",
            "Epoch 38 | Train loss 2.154 | Valid loss 2.138 | Valid acc 0.368\n",
            "Epoch 39 | Train loss 2.150 | Valid loss 2.135 | Valid acc 0.372\n",
            "Epoch 40 | Train loss 2.147 | Valid loss 2.132 | Valid acc 0.370\n",
            "Epoch 41 | Train loss 2.144 | Valid loss 2.128 | Valid acc 0.373\n",
            "Epoch 42 | Train loss 2.143 | Valid loss 2.126 | Valid acc 0.373\n",
            "Epoch 43 | Train loss 2.140 | Valid loss 2.123 | Valid acc 0.374\n",
            "Epoch 44 | Train loss 2.135 | Valid loss 2.120 | Valid acc 0.376\n",
            "Epoch 45 | Train loss 2.133 | Valid loss 2.118 | Valid acc 0.378\n",
            "Epoch 46 | Train loss 2.132 | Valid loss 2.113 | Valid acc 0.379\n",
            "Epoch 47 | Train loss 2.127 | Valid loss 2.111 | Valid acc 0.381\n",
            "Epoch 48 | Train loss 2.125 | Valid loss 2.110 | Valid acc 0.383\n",
            "Epoch 49 | Train loss 2.124 | Valid loss 2.106 | Valid acc 0.385\n",
            "Finally!\n",
            "best_valid_acc 0.3852\n",
            "256 50 0.0001 <class 'torch.optim.adam.Adam'> 128\n",
            "Epoch 0 | Train loss 2.131 | Valid loss 2.037 | Valid acc 0.417\n",
            "Epoch 1 | Train loss 2.007 | Valid loss 1.957 | Valid acc 0.501\n",
            "Epoch 2 | Train loss 1.956 | Valid loss 1.919 | Valid acc 0.535\n",
            "Epoch 3 | Train loss 1.912 | Valid loss 1.895 | Valid acc 0.563\n",
            "Epoch 4 | Train loss 1.879 | Valid loss 1.869 | Valid acc 0.588\n",
            "Epoch 5 | Train loss 1.850 | Valid loss 1.853 | Valid acc 0.609\n",
            "Epoch 6 | Train loss 1.824 | Valid loss 1.826 | Valid acc 0.636\n",
            "Epoch 7 | Train loss 1.798 | Valid loss 1.826 | Valid acc 0.634\n",
            "Epoch 8 | Train loss 1.778 | Valid loss 1.800 | Valid acc 0.660\n",
            "Epoch 9 | Train loss 1.758 | Valid loss 1.785 | Valid acc 0.676\n",
            "Epoch 10 | Train loss 1.745 | Valid loss 1.780 | Valid acc 0.680\n",
            "Epoch 11 | Train loss 1.731 | Valid loss 1.768 | Valid acc 0.695\n",
            "Epoch 12 | Train loss 1.716 | Valid loss 1.773 | Valid acc 0.687\n",
            "Epoch 13 | Train loss 1.705 | Valid loss 1.765 | Valid acc 0.692\n",
            "Epoch 14 | Train loss 1.691 | Valid loss 1.752 | Valid acc 0.710\n",
            "Epoch 15 | Train loss 1.681 | Valid loss 1.748 | Valid acc 0.711\n",
            "Epoch 16 | Train loss 1.674 | Valid loss 1.756 | Valid acc 0.703\n",
            "Epoch 17 | Train loss 1.661 | Valid loss 1.740 | Valid acc 0.721\n",
            "Epoch 18 | Train loss 1.653 | Valid loss 1.739 | Valid acc 0.719\n",
            "Epoch 19 | Train loss 1.644 | Valid loss 1.734 | Valid acc 0.723\n",
            "Epoch 20 | Train loss 1.637 | Valid loss 1.740 | Valid acc 0.719\n",
            "Epoch 21 | Train loss 1.630 | Valid loss 1.742 | Valid acc 0.718\n",
            "Epoch 22 | Train loss 1.622 | Valid loss 1.730 | Valid acc 0.731\n",
            "Epoch 23 | Train loss 1.615 | Valid loss 1.736 | Valid acc 0.724\n",
            "Epoch 24 | Train loss 1.608 | Valid loss 1.728 | Valid acc 0.731\n",
            "Epoch 25 | Train loss 1.605 | Valid loss 1.722 | Valid acc 0.740\n",
            "Epoch 26 | Train loss 1.597 | Valid loss 1.728 | Valid acc 0.732\n",
            "Epoch 27 | Train loss 1.592 | Valid loss 1.722 | Valid acc 0.736\n",
            "Epoch 28 | Train loss 1.588 | Valid loss 1.725 | Valid acc 0.735\n",
            "Epoch 29 | Train loss 1.584 | Valid loss 1.731 | Valid acc 0.727\n",
            "Epoch 30 | Train loss 1.579 | Valid loss 1.724 | Valid acc 0.737\n",
            "Epoch 31 | Train loss 1.579 | Valid loss 1.728 | Valid acc 0.731\n",
            "Epoch 32 | Train loss 1.572 | Valid loss 1.717 | Valid acc 0.743\n",
            "Epoch 33 | Train loss 1.569 | Valid loss 1.722 | Valid acc 0.738\n",
            "Epoch 34 | Train loss 1.566 | Valid loss 1.732 | Valid acc 0.728\n",
            "Epoch 35 | Train loss 1.563 | Valid loss 1.719 | Valid acc 0.742\n",
            "Epoch 36 | Train loss 1.561 | Valid loss 1.721 | Valid acc 0.736\n",
            "Epoch 37 | Train loss 1.558 | Valid loss 1.719 | Valid acc 0.742\n",
            "Epoch 38 | Train loss 1.555 | Valid loss 1.721 | Valid acc 0.740\n",
            "Epoch 39 | Train loss 1.551 | Valid loss 1.715 | Valid acc 0.744\n",
            "Epoch 40 | Train loss 1.551 | Valid loss 1.717 | Valid acc 0.741\n",
            "Epoch 41 | Train loss 1.550 | Valid loss 1.718 | Valid acc 0.743\n",
            "Epoch 42 | Train loss 1.547 | Valid loss 1.724 | Valid acc 0.738\n",
            "Epoch 43 | Train loss 1.544 | Valid loss 1.723 | Valid acc 0.735\n",
            "Epoch 44 | Train loss 1.543 | Valid loss 1.720 | Valid acc 0.740\n",
            "Epoch 45 | Train loss 1.541 | Valid loss 1.724 | Valid acc 0.736\n",
            "Epoch 46 | Train loss 1.541 | Valid loss 1.720 | Valid acc 0.740\n",
            "Epoch 47 | Train loss 1.541 | Valid loss 1.720 | Valid acc 0.741\n",
            "Epoch 48 | Train loss 1.537 | Valid loss 1.723 | Valid acc 0.739\n",
            "Epoch 49 | Train loss 1.536 | Valid loss 1.728 | Valid acc 0.729\n",
            "Finally!\n",
            "best_valid_acc 0.7442\n",
            "256 50 0.001 <class 'torch.optim.sgd.SGD'> 128\n",
            "Epoch 0 | Train loss 2.285 | Valid loss 2.257 | Valid acc 0.216\n",
            "Epoch 1 | Train loss 2.235 | Valid loss 2.200 | Valid acc 0.301\n",
            "Epoch 2 | Train loss 2.187 | Valid loss 2.158 | Valid acc 0.327\n",
            "Epoch 3 | Train loss 2.155 | Valid loss 2.131 | Valid acc 0.357\n",
            "Epoch 4 | Train loss 2.132 | Valid loss 2.109 | Valid acc 0.373\n",
            "Epoch 5 | Train loss 2.113 | Valid loss 2.093 | Valid acc 0.391\n",
            "Epoch 6 | Train loss 2.096 | Valid loss 2.074 | Valid acc 0.410\n",
            "Epoch 7 | Train loss 2.081 | Valid loss 2.058 | Valid acc 0.420\n",
            "Epoch 8 | Train loss 2.067 | Valid loss 2.049 | Valid acc 0.432\n",
            "Epoch 9 | Train loss 2.055 | Valid loss 2.035 | Valid acc 0.444\n",
            "Epoch 10 | Train loss 2.044 | Valid loss 2.027 | Valid acc 0.452\n",
            "Epoch 11 | Train loss 2.036 | Valid loss 2.017 | Valid acc 0.459\n",
            "Epoch 12 | Train loss 2.026 | Valid loss 2.008 | Valid acc 0.466\n",
            "Epoch 13 | Train loss 2.019 | Valid loss 2.005 | Valid acc 0.477\n",
            "Epoch 14 | Train loss 2.010 | Valid loss 1.995 | Valid acc 0.482\n",
            "Epoch 15 | Train loss 2.002 | Valid loss 1.989 | Valid acc 0.488\n",
            "Epoch 16 | Train loss 1.995 | Valid loss 1.983 | Valid acc 0.495\n",
            "Epoch 17 | Train loss 1.985 | Valid loss 1.976 | Valid acc 0.503\n",
            "Epoch 18 | Train loss 1.980 | Valid loss 1.971 | Valid acc 0.505\n",
            "Epoch 19 | Train loss 1.974 | Valid loss 1.964 | Valid acc 0.513\n",
            "Epoch 20 | Train loss 1.965 | Valid loss 1.959 | Valid acc 0.518\n",
            "Epoch 21 | Train loss 1.960 | Valid loss 1.954 | Valid acc 0.523\n",
            "Epoch 22 | Train loss 1.952 | Valid loss 1.951 | Valid acc 0.527\n",
            "Epoch 23 | Train loss 1.946 | Valid loss 1.944 | Valid acc 0.532\n",
            "Epoch 24 | Train loss 1.940 | Valid loss 1.938 | Valid acc 0.535\n",
            "Epoch 25 | Train loss 1.934 | Valid loss 1.933 | Valid acc 0.540\n",
            "Epoch 26 | Train loss 1.930 | Valid loss 1.931 | Valid acc 0.546\n",
            "Epoch 27 | Train loss 1.924 | Valid loss 1.925 | Valid acc 0.549\n",
            "Epoch 28 | Train loss 1.918 | Valid loss 1.922 | Valid acc 0.553\n",
            "Epoch 29 | Train loss 1.913 | Valid loss 1.918 | Valid acc 0.554\n",
            "Epoch 30 | Train loss 1.908 | Valid loss 1.912 | Valid acc 0.563\n",
            "Epoch 31 | Train loss 1.903 | Valid loss 1.911 | Valid acc 0.565\n",
            "Epoch 32 | Train loss 1.898 | Valid loss 1.906 | Valid acc 0.570\n",
            "Epoch 33 | Train loss 1.893 | Valid loss 1.906 | Valid acc 0.566\n",
            "Epoch 34 | Train loss 1.889 | Valid loss 1.899 | Valid acc 0.577\n",
            "Epoch 35 | Train loss 1.884 | Valid loss 1.898 | Valid acc 0.580\n",
            "Epoch 36 | Train loss 1.880 | Valid loss 1.892 | Valid acc 0.582\n",
            "Epoch 37 | Train loss 1.877 | Valid loss 1.892 | Valid acc 0.582\n",
            "Epoch 38 | Train loss 1.872 | Valid loss 1.885 | Valid acc 0.588\n",
            "Epoch 39 | Train loss 1.866 | Valid loss 1.887 | Valid acc 0.589\n",
            "Epoch 40 | Train loss 1.864 | Valid loss 1.883 | Valid acc 0.592\n",
            "Epoch 41 | Train loss 1.858 | Valid loss 1.881 | Valid acc 0.596\n",
            "Epoch 42 | Train loss 1.855 | Valid loss 1.878 | Valid acc 0.597\n",
            "Epoch 43 | Train loss 1.851 | Valid loss 1.875 | Valid acc 0.601\n",
            "Epoch 44 | Train loss 1.847 | Valid loss 1.874 | Valid acc 0.605\n",
            "Epoch 45 | Train loss 1.844 | Valid loss 1.869 | Valid acc 0.606\n",
            "Epoch 46 | Train loss 1.840 | Valid loss 1.868 | Valid acc 0.606\n",
            "Epoch 47 | Train loss 1.836 | Valid loss 1.867 | Valid acc 0.609\n",
            "Epoch 48 | Train loss 1.831 | Valid loss 1.863 | Valid acc 0.612\n",
            "Epoch 49 | Train loss 1.829 | Valid loss 1.864 | Valid acc 0.610\n",
            "Finally!\n",
            "best_valid_acc 0.612\n",
            "256 50 0.001 <class 'torch.optim.adam.Adam'> 128\n",
            "Epoch 0 | Train loss 2.350 | Valid loss 2.363 | Valid acc 0.099\n",
            "Epoch 1 | Train loss 2.361 | Valid loss 2.362 | Valid acc 0.099\n",
            "Epoch 2 | Train loss 2.361 | Valid loss 2.363 | Valid acc 0.099\n",
            "Epoch 3 | Train loss 2.361 | Valid loss 2.362 | Valid acc 0.099\n",
            "Epoch 4 | Train loss 2.361 | Valid loss 2.363 | Valid acc 0.099\n",
            "Epoch 5 | Train loss 2.361 | Valid loss 2.363 | Valid acc 0.099\n",
            "Epoch 6 | Train loss 2.361 | Valid loss 2.363 | Valid acc 0.099\n",
            "Epoch 7 | Train loss 2.361 | Valid loss 2.363 | Valid acc 0.099\n",
            "Epoch 8 | Train loss 2.361 | Valid loss 2.361 | Valid acc 0.099\n",
            "Epoch 9 | Train loss 2.361 | Valid loss 2.362 | Valid acc 0.099\n",
            "Epoch 10 | Train loss 2.361 | Valid loss 2.363 | Valid acc 0.099\n",
            "Epoch 11 | Train loss 2.361 | Valid loss 2.363 | Valid acc 0.099\n",
            "Epoch 12 | Train loss 2.361 | Valid loss 2.361 | Valid acc 0.099\n",
            "Epoch 13 | Train loss 2.361 | Valid loss 2.363 | Valid acc 0.099\n",
            "Epoch 14 | Train loss 2.361 | Valid loss 2.363 | Valid acc 0.099\n",
            "Epoch 15 | Train loss 2.361 | Valid loss 2.363 | Valid acc 0.099\n",
            "Epoch 16 | Train loss 2.361 | Valid loss 2.362 | Valid acc 0.099\n",
            "Epoch 17 | Train loss 2.361 | Valid loss 2.360 | Valid acc 0.099\n",
            "Epoch 18 | Train loss 2.361 | Valid loss 2.360 | Valid acc 0.099\n",
            "Epoch 19 | Train loss 2.361 | Valid loss 2.361 | Valid acc 0.099\n",
            "Epoch 20 | Train loss 2.361 | Valid loss 2.361 | Valid acc 0.099\n",
            "Epoch 21 | Train loss 2.361 | Valid loss 2.362 | Valid acc 0.099\n",
            "Epoch 22 | Train loss 2.361 | Valid loss 2.362 | Valid acc 0.099\n",
            "Epoch 23 | Train loss 2.361 | Valid loss 2.363 | Valid acc 0.099\n",
            "Epoch 24 | Train loss 2.361 | Valid loss 2.362 | Valid acc 0.099\n",
            "Epoch 25 | Train loss 2.361 | Valid loss 2.363 | Valid acc 0.099\n",
            "Epoch 26 | Train loss 2.361 | Valid loss 2.362 | Valid acc 0.099\n",
            "Epoch 27 | Train loss 2.361 | Valid loss 2.361 | Valid acc 0.099\n",
            "Epoch 28 | Train loss 2.361 | Valid loss 2.363 | Valid acc 0.099\n",
            "Epoch 29 | Train loss 2.361 | Valid loss 2.363 | Valid acc 0.099\n",
            "Epoch 30 | Train loss 2.361 | Valid loss 2.362 | Valid acc 0.099\n",
            "Epoch 31 | Train loss 2.361 | Valid loss 2.363 | Valid acc 0.099\n",
            "Epoch 32 | Train loss 2.361 | Valid loss 2.362 | Valid acc 0.099\n",
            "Epoch 33 | Train loss 2.361 | Valid loss 2.361 | Valid acc 0.099\n",
            "Epoch 34 | Train loss 2.361 | Valid loss 2.363 | Valid acc 0.099\n",
            "Epoch 35 | Train loss 2.361 | Valid loss 2.361 | Valid acc 0.099\n",
            "Epoch 36 | Train loss 2.361 | Valid loss 2.363 | Valid acc 0.099\n",
            "Epoch 37 | Train loss 2.361 | Valid loss 2.362 | Valid acc 0.099\n",
            "Epoch 38 | Train loss 2.361 | Valid loss 2.362 | Valid acc 0.099\n",
            "Epoch 39 | Train loss 2.361 | Valid loss 2.362 | Valid acc 0.099\n",
            "Epoch 40 | Train loss 2.361 | Valid loss 2.363 | Valid acc 0.099\n",
            "Epoch 41 | Train loss 2.361 | Valid loss 2.362 | Valid acc 0.099\n",
            "Epoch 42 | Train loss 2.361 | Valid loss 2.361 | Valid acc 0.099\n",
            "Epoch 43 | Train loss 2.361 | Valid loss 2.363 | Valid acc 0.099\n",
            "Epoch 44 | Train loss 2.361 | Valid loss 2.362 | Valid acc 0.099\n",
            "Epoch 45 | Train loss 2.361 | Valid loss 2.363 | Valid acc 0.099\n",
            "Epoch 46 | Train loss 2.361 | Valid loss 2.363 | Valid acc 0.099\n",
            "Epoch 47 | Train loss 2.361 | Valid loss 2.362 | Valid acc 0.099\n",
            "Epoch 48 | Train loss 2.361 | Valid loss 2.361 | Valid acc 0.099\n",
            "Epoch 49 | Train loss 2.361 | Valid loss 2.363 | Valid acc 0.099\n",
            "Finally!\n",
            "best_valid_acc 0.0989\n",
            "512 30 0.0002 <class 'torch.optim.sgd.SGD'> 128\n",
            "Epoch 0 | Train loss 2.300 | Valid loss 2.295 | Valid acc 0.207\n",
            "Epoch 1 | Train loss 2.289 | Valid loss 2.280 | Valid acc 0.228\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-EHKzozkRbD"
      },
      "source": [
        "Write down **validation accuracy** of your model under different hyperparameter settings. \n",
        "\n",
        "**Hint:** You may need more epochs for SGD than Adam.\n",
        "\n",
        "| #channel for each layer \\ optimizer | SGD   | Adam  |\n",
        "|-------------------------------------|-------|-------|\n",
        "| (128, 128, 128)                     |   58.69    |    74.40   |\n",
        "| (256, 256, 256)                     |    61.20   |    74.42   |\n",
        "| (512, 512, 512)                     |    63.42   |    74.25   |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "go55LVSJd-vG"
      },
      "source": [
        "### 2) Full CNN implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G0eCj6OmOEE"
      },
      "source": [
        "Based on the CNN in the previous question, implement a full CNN model with max pooling layer.\n",
        "\n",
        "- Add a max pooling layer after each convolutional layer.\n",
        "- Each max pooling layer has a kernel size of 2 and a stride of 2.\n",
        "\n",
        "Please implement this model in the following section. You will need to tune the hyperparameters and fill the results in the table. You are also required to complete the questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMrKGlMQhCa0"
      },
      "source": [
        "#### a) Implement max pooling layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2INt6P3Myd1"
      },
      "source": [
        "Copy the CNN implementation in previous question. Implement max pooling layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHu3Ic2dM1S9"
      },
      "source": [
        "class CNN_Maxpool(nn.Module):\n",
        "\n",
        "    def __init__(self, channels=[128,128,128]):\n",
        "        super(CNN_Maxpool, self).__init__()\n",
        "        self.channels = [int(channel) for channel in channels]\n",
        "        self.layer = nn.Sequential(\n",
        "            Conv_maxpool(3, self.channels[0]),\n",
        "            Conv_maxpool(self.channels[0], self.channels[1]),\n",
        "            Conv_maxpool(self.channels[1], self.channels[2]),\n",
        "        )\n",
        "        self.out_player = nn.Sequential(\n",
        "            nn.Linear(self.channels[2] * 4 * 4, 256),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10),\n",
        "            nn.Softmax(dim=-1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.layer(x)\n",
        "        h = h.reshape(-1, self.channels[2] * 4 * 4)\n",
        "        result = self.out_player(h)\n",
        "        return result\n",
        "\n",
        "class Conv_maxpool(nn.Module):\n",
        "\n",
        "    def __init__(self, inchannels, outchannels):\n",
        "        super(Conv_maxpool, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=inchannels, out_channels=outchannels, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.MaxPool2d( kernel_size=2, stride=2),\n",
        "            nn.BatchNorm2d(outchannels),\n",
        "            nn.LeakyReLU(outchannels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer(x)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-A6AEOoigq68"
      },
      "source": [
        "#### b) Tune hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drH4MHSVNqwz"
      },
      "source": [
        "Based on best optimizer you found in the previous problem, tune the number of channels and learning rate for best validation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgRRWGjnwWj-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "005c19d2-3aa7-42e5-ca04-052f08d2a7a5"
      },
      "source": [
        "from itertools import product\n",
        "# tune the optimizer type and hyperparameters with the following code as an example\n",
        "\n",
        "parameters = dict(\n",
        "    channels = [[128,128,128],[128,256,512],[256,256,256],[256,512,1024],[512,512,512],[512,1024,2048]],\n",
        "    EPOCHS = [30],\n",
        "    lr = [1e-4,1e-3],\n",
        "    optimier = [torch.optim.SGD],\n",
        "    batch_size = [128]\n",
        ")\n",
        "param_values = [v for v in parameters.values()]\n",
        "with open(\"read2.txt\",\"w\") as f:   \n",
        "    # call your model here\n",
        "    for channel,EPOCHS,lr,optim_type,batch_size in product(*param_values):\n",
        "\n",
        "        train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "        valid_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
        "        test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "        model = CNN_Maxpool(channel).cuda()\n",
        "        optimizer = optim_type(model.parameters(),lr=lr)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        # train and test the model\n",
        "        # you can reuse the following coding block for hyperparameter tuning\n",
        "        # feel free to try more advanced training strategies\n",
        "        best_valid_acc = 0.0\n",
        "        best_state_dict = copy.deepcopy(model.state_dict())\n",
        "        for epoch in range(EPOCHS):\n",
        "            train_loss, train_acc = train(model, train_dataloader, optimizer, criterion)\n",
        "            valid_loss, valid_acc = evaluate(model, valid_dataloader, criterion)\n",
        "            print('Epoch {} | Train loss {:.3f} | Valid loss {:.3f} | Valid acc {:.3f}'.format(epoch, train_loss, valid_loss,valid_acc))\n",
        "            f.write('Epoch {} | Train loss {:.3f} | Valid loss {:.3f} | Valid acc {:.3f}\\n'.format(epoch, train_loss, valid_loss,valid_acc))\n",
        "            if valid_acc > best_valid_acc:\n",
        "                best_valid_acc = valid_acc\n",
        "                best_state_dict = copy.deepcopy(model.state_dict())\n",
        "                torch.save(model.state_dict(),f\"{channel}{lr}.pt\")\n",
        "        print(\"Finally!\")\n",
        "        f.write(f\"best_valid_acc{best_valid_acc}\\n\")\n",
        "        print(\"best_valid_acc\",best_valid_acc)\n",
        "\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 | Train loss 2.345 | Valid loss 2.305 | Valid acc 0.141\n",
            "Epoch 1 | Train loss 2.304 | Valid loss 2.277 | Valid acc 0.174\n",
            "Epoch 2 | Train loss 2.283 | Valid loss 2.260 | Valid acc 0.191\n",
            "Epoch 3 | Train loss 2.268 | Valid loss 2.245 | Valid acc 0.204\n",
            "Epoch 4 | Train loss 2.255 | Valid loss 2.235 | Valid acc 0.217\n",
            "Epoch 5 | Train loss 2.245 | Valid loss 2.225 | Valid acc 0.230\n",
            "Epoch 6 | Train loss 2.235 | Valid loss 2.213 | Valid acc 0.242\n",
            "Epoch 7 | Train loss 2.225 | Valid loss 2.204 | Valid acc 0.253\n",
            "Epoch 8 | Train loss 2.216 | Valid loss 2.185 | Valid acc 0.268\n",
            "Epoch 9 | Train loss 2.200 | Valid loss 2.164 | Valid acc 0.287\n",
            "Epoch 10 | Train loss 2.191 | Valid loss 2.155 | Valid acc 0.297\n",
            "Epoch 11 | Train loss 2.181 | Valid loss 2.148 | Valid acc 0.306\n",
            "Epoch 12 | Train loss 2.174 | Valid loss 2.139 | Valid acc 0.315\n",
            "Epoch 13 | Train loss 2.166 | Valid loss 2.135 | Valid acc 0.320\n",
            "Epoch 14 | Train loss 2.161 | Valid loss 2.127 | Valid acc 0.328\n",
            "Epoch 15 | Train loss 2.156 | Valid loss 2.128 | Valid acc 0.327\n",
            "Epoch 16 | Train loss 2.154 | Valid loss 2.123 | Valid acc 0.334\n",
            "Epoch 17 | Train loss 2.148 | Valid loss 2.116 | Valid acc 0.338\n",
            "Epoch 18 | Train loss 2.142 | Valid loss 2.113 | Valid acc 0.340\n",
            "Epoch 19 | Train loss 2.139 | Valid loss 2.115 | Valid acc 0.343\n",
            "Epoch 20 | Train loss 2.134 | Valid loss 2.109 | Valid acc 0.345\n",
            "Epoch 21 | Train loss 2.131 | Valid loss 2.109 | Valid acc 0.345\n",
            "Epoch 22 | Train loss 2.126 | Valid loss 2.107 | Valid acc 0.348\n",
            "Epoch 23 | Train loss 2.124 | Valid loss 2.105 | Valid acc 0.352\n",
            "Epoch 24 | Train loss 2.120 | Valid loss 2.101 | Valid acc 0.354\n",
            "Epoch 25 | Train loss 2.118 | Valid loss 2.097 | Valid acc 0.359\n",
            "Epoch 26 | Train loss 2.114 | Valid loss 2.097 | Valid acc 0.361\n",
            "Epoch 27 | Train loss 2.113 | Valid loss 2.095 | Valid acc 0.363\n",
            "Epoch 28 | Train loss 2.110 | Valid loss 2.092 | Valid acc 0.365\n",
            "Epoch 29 | Train loss 2.109 | Valid loss 2.089 | Valid acc 0.367\n",
            "Finally!\n",
            "best_valid_acc 0.3671\n",
            "Epoch 0 | Train loss 2.244 | Valid loss 2.156 | Valid acc 0.298\n",
            "Epoch 1 | Train loss 2.158 | Valid loss 2.093 | Valid acc 0.362\n",
            "Epoch 2 | Train loss 2.107 | Valid loss 2.061 | Valid acc 0.395\n",
            "Epoch 3 | Train loss 2.075 | Valid loss 2.038 | Valid acc 0.419\n",
            "Epoch 4 | Train loss 2.055 | Valid loss 2.019 | Valid acc 0.441\n",
            "Epoch 5 | Train loss 2.035 | Valid loss 2.009 | Valid acc 0.444\n",
            "Epoch 6 | Train loss 2.021 | Valid loss 1.999 | Valid acc 0.457\n",
            "Epoch 7 | Train loss 2.011 | Valid loss 1.991 | Valid acc 0.466\n",
            "Epoch 8 | Train loss 1.999 | Valid loss 1.979 | Valid acc 0.475\n",
            "Epoch 9 | Train loss 1.988 | Valid loss 1.974 | Valid acc 0.483\n",
            "Epoch 10 | Train loss 1.978 | Valid loss 1.970 | Valid acc 0.482\n",
            "Epoch 11 | Train loss 1.967 | Valid loss 1.966 | Valid acc 0.491\n",
            "Epoch 12 | Train loss 1.960 | Valid loss 1.955 | Valid acc 0.502\n",
            "Epoch 13 | Train loss 1.953 | Valid loss 1.955 | Valid acc 0.503\n",
            "Epoch 14 | Train loss 1.945 | Valid loss 1.948 | Valid acc 0.507\n",
            "Epoch 15 | Train loss 1.938 | Valid loss 1.946 | Valid acc 0.511\n",
            "Epoch 16 | Train loss 1.930 | Valid loss 1.939 | Valid acc 0.517\n",
            "Epoch 17 | Train loss 1.928 | Valid loss 1.936 | Valid acc 0.520\n",
            "Epoch 18 | Train loss 1.919 | Valid loss 1.934 | Valid acc 0.524\n",
            "Epoch 19 | Train loss 1.910 | Valid loss 1.923 | Valid acc 0.533\n",
            "Epoch 20 | Train loss 1.905 | Valid loss 1.920 | Valid acc 0.538\n",
            "Epoch 21 | Train loss 1.901 | Valid loss 1.918 | Valid acc 0.534\n",
            "Epoch 22 | Train loss 1.891 | Valid loss 1.915 | Valid acc 0.541\n",
            "Epoch 23 | Train loss 1.887 | Valid loss 1.915 | Valid acc 0.544\n",
            "Epoch 24 | Train loss 1.882 | Valid loss 1.914 | Valid acc 0.546\n",
            "Epoch 25 | Train loss 1.877 | Valid loss 1.908 | Valid acc 0.550\n",
            "Epoch 26 | Train loss 1.873 | Valid loss 1.903 | Valid acc 0.555\n",
            "Epoch 27 | Train loss 1.866 | Valid loss 1.909 | Valid acc 0.548\n",
            "Epoch 28 | Train loss 1.861 | Valid loss 1.900 | Valid acc 0.559\n",
            "Epoch 29 | Train loss 1.857 | Valid loss 1.895 | Valid acc 0.561\n",
            "Finally!\n",
            "best_valid_acc 0.5612\n",
            "Epoch 0 | Train loss 2.320 | Valid loss 2.289 | Valid acc 0.171\n",
            "Epoch 1 | Train loss 2.293 | Valid loss 2.274 | Valid acc 0.185\n",
            "Epoch 2 | Train loss 2.278 | Valid loss 2.265 | Valid acc 0.197\n",
            "Epoch 3 | Train loss 2.271 | Valid loss 2.251 | Valid acc 0.209\n",
            "Epoch 4 | Train loss 2.260 | Valid loss 2.242 | Valid acc 0.217\n",
            "Epoch 5 | Train loss 2.251 | Valid loss 2.233 | Valid acc 0.228\n",
            "Epoch 6 | Train loss 2.243 | Valid loss 2.221 | Valid acc 0.238\n",
            "Epoch 7 | Train loss 2.235 | Valid loss 2.221 | Valid acc 0.240\n",
            "Epoch 8 | Train loss 2.229 | Valid loss 2.217 | Valid acc 0.243\n",
            "Epoch 9 | Train loss 2.224 | Valid loss 2.210 | Valid acc 0.249\n",
            "Epoch 10 | Train loss 2.214 | Valid loss 2.185 | Valid acc 0.277\n",
            "Epoch 11 | Train loss 2.201 | Valid loss 2.170 | Valid acc 0.288\n",
            "Epoch 12 | Train loss 2.192 | Valid loss 2.162 | Valid acc 0.296\n",
            "Epoch 13 | Train loss 2.183 | Valid loss 2.153 | Valid acc 0.307\n",
            "Epoch 14 | Train loss 2.177 | Valid loss 2.147 | Valid acc 0.311\n",
            "Epoch 15 | Train loss 2.167 | Valid loss 2.144 | Valid acc 0.315\n",
            "Epoch 16 | Train loss 2.161 | Valid loss 2.143 | Valid acc 0.317\n",
            "Epoch 17 | Train loss 2.155 | Valid loss 2.132 | Valid acc 0.330\n",
            "Epoch 18 | Train loss 2.147 | Valid loss 2.122 | Valid acc 0.340\n",
            "Epoch 19 | Train loss 2.138 | Valid loss 2.115 | Valid acc 0.347\n",
            "Epoch 20 | Train loss 2.128 | Valid loss 2.109 | Valid acc 0.348\n",
            "Epoch 21 | Train loss 2.126 | Valid loss 2.099 | Valid acc 0.360\n",
            "Epoch 22 | Train loss 2.114 | Valid loss 2.096 | Valid acc 0.363\n",
            "Epoch 23 | Train loss 2.112 | Valid loss 2.095 | Valid acc 0.366\n",
            "Epoch 24 | Train loss 2.106 | Valid loss 2.088 | Valid acc 0.373\n",
            "Epoch 25 | Train loss 2.107 | Valid loss 2.084 | Valid acc 0.377\n",
            "Epoch 26 | Train loss 2.101 | Valid loss 2.079 | Valid acc 0.379\n",
            "Epoch 27 | Train loss 2.100 | Valid loss 2.080 | Valid acc 0.381\n",
            "Epoch 28 | Train loss 2.095 | Valid loss 2.083 | Valid acc 0.378\n",
            "Epoch 29 | Train loss 2.092 | Valid loss 2.077 | Valid acc 0.382\n",
            "Finally!\n",
            "best_valid_acc 0.3823\n",
            "Epoch 0 | Train loss 2.266 | Valid loss 2.217 | Valid acc 0.245\n",
            "Epoch 1 | Train loss 2.210 | Valid loss 2.194 | Valid acc 0.267\n",
            "Epoch 2 | Train loss 2.187 | Valid loss 2.165 | Valid acc 0.295\n",
            "Epoch 3 | Train loss 2.175 | Valid loss 2.149 | Valid acc 0.310\n",
            "Epoch 4 | Train loss 2.157 | Valid loss 2.118 | Valid acc 0.342\n",
            "Epoch 5 | Train loss 2.136 | Valid loss 2.109 | Valid acc 0.350\n",
            "Epoch 6 | Train loss 2.124 | Valid loss 2.116 | Valid acc 0.344\n",
            "Epoch 7 | Train loss 2.111 | Valid loss 2.089 | Valid acc 0.370\n",
            "Epoch 8 | Train loss 2.092 | Valid loss 2.087 | Valid acc 0.374\n",
            "Epoch 9 | Train loss 2.086 | Valid loss 2.070 | Valid acc 0.393\n",
            "Epoch 10 | Train loss 2.078 | Valid loss 2.059 | Valid acc 0.402\n",
            "Epoch 11 | Train loss 2.068 | Valid loss 2.052 | Valid acc 0.409\n",
            "Epoch 12 | Train loss 2.065 | Valid loss 2.046 | Valid acc 0.413\n",
            "Epoch 13 | Train loss 2.059 | Valid loss 2.057 | Valid acc 0.406\n",
            "Epoch 14 | Train loss 2.056 | Valid loss 2.053 | Valid acc 0.409\n",
            "Epoch 15 | Train loss 2.053 | Valid loss 2.039 | Valid acc 0.423\n",
            "Epoch 16 | Train loss 2.043 | Valid loss 2.030 | Valid acc 0.428\n",
            "Epoch 17 | Train loss 2.045 | Valid loss 2.027 | Valid acc 0.434\n",
            "Epoch 18 | Train loss 2.040 | Valid loss 2.025 | Valid acc 0.435\n",
            "Epoch 19 | Train loss 2.038 | Valid loss 2.017 | Valid acc 0.443\n",
            "Epoch 20 | Train loss 2.034 | Valid loss 2.028 | Valid acc 0.434\n",
            "Epoch 21 | Train loss 2.031 | Valid loss 2.021 | Valid acc 0.439\n",
            "Epoch 22 | Train loss 2.028 | Valid loss 2.020 | Valid acc 0.441\n",
            "Epoch 23 | Train loss 2.020 | Valid loss 2.028 | Valid acc 0.433\n",
            "Epoch 24 | Train loss 2.019 | Valid loss 2.009 | Valid acc 0.451\n",
            "Epoch 25 | Train loss 2.013 | Valid loss 2.019 | Valid acc 0.439\n",
            "Epoch 26 | Train loss 2.015 | Valid loss 2.017 | Valid acc 0.447\n",
            "Epoch 27 | Train loss 2.014 | Valid loss 2.013 | Valid acc 0.448\n",
            "Epoch 28 | Train loss 2.008 | Valid loss 2.001 | Valid acc 0.459\n",
            "Epoch 29 | Train loss 2.011 | Valid loss 2.016 | Valid acc 0.444\n",
            "Finally!\n",
            "best_valid_acc 0.459\n",
            "Epoch 0 | Train loss 2.340 | Valid loss 2.282 | Valid acc 0.173\n",
            "Epoch 1 | Train loss 2.282 | Valid loss 2.253 | Valid acc 0.203\n",
            "Epoch 2 | Train loss 2.260 | Valid loss 2.235 | Valid acc 0.222\n",
            "Epoch 3 | Train loss 2.239 | Valid loss 2.215 | Valid acc 0.241\n",
            "Epoch 4 | Train loss 2.225 | Valid loss 2.199 | Valid acc 0.258\n",
            "Epoch 5 | Train loss 2.210 | Valid loss 2.188 | Valid acc 0.269\n",
            "Epoch 6 | Train loss 2.203 | Valid loss 2.172 | Valid acc 0.284\n",
            "Epoch 7 | Train loss 2.191 | Valid loss 2.159 | Valid acc 0.296\n",
            "Epoch 8 | Train loss 2.179 | Valid loss 2.146 | Valid acc 0.311\n",
            "Epoch 9 | Train loss 2.168 | Valid loss 2.142 | Valid acc 0.317\n",
            "Epoch 10 | Train loss 2.162 | Valid loss 2.133 | Valid acc 0.323\n",
            "Epoch 11 | Train loss 2.155 | Valid loss 2.130 | Valid acc 0.329\n",
            "Epoch 12 | Train loss 2.148 | Valid loss 2.123 | Valid acc 0.334\n",
            "Epoch 13 | Train loss 2.144 | Valid loss 2.121 | Valid acc 0.338\n",
            "Epoch 14 | Train loss 2.139 | Valid loss 2.116 | Valid acc 0.340\n",
            "Epoch 15 | Train loss 2.133 | Valid loss 2.113 | Valid acc 0.343\n",
            "Epoch 16 | Train loss 2.130 | Valid loss 2.111 | Valid acc 0.349\n",
            "Epoch 17 | Train loss 2.126 | Valid loss 2.108 | Valid acc 0.352\n",
            "Epoch 18 | Train loss 2.120 | Valid loss 2.098 | Valid acc 0.357\n",
            "Epoch 19 | Train loss 2.117 | Valid loss 2.095 | Valid acc 0.360\n",
            "Epoch 20 | Train loss 2.113 | Valid loss 2.098 | Valid acc 0.362\n",
            "Epoch 21 | Train loss 2.108 | Valid loss 2.096 | Valid acc 0.362\n",
            "Epoch 22 | Train loss 2.104 | Valid loss 2.093 | Valid acc 0.365\n",
            "Epoch 23 | Train loss 2.100 | Valid loss 2.094 | Valid acc 0.364\n",
            "Epoch 24 | Train loss 2.101 | Valid loss 2.085 | Valid acc 0.371\n",
            "Epoch 25 | Train loss 2.095 | Valid loss 2.087 | Valid acc 0.370\n",
            "Epoch 26 | Train loss 2.092 | Valid loss 2.083 | Valid acc 0.373\n",
            "Epoch 27 | Train loss 2.090 | Valid loss 2.086 | Valid acc 0.371\n",
            "Epoch 28 | Train loss 2.086 | Valid loss 2.082 | Valid acc 0.378\n",
            "Epoch 29 | Train loss 2.082 | Valid loss 2.080 | Valid acc 0.376\n",
            "Finally!\n",
            "best_valid_acc 0.3775\n",
            "Epoch 0 | Train loss 2.245 | Valid loss 2.151 | Valid acc 0.306\n",
            "Epoch 1 | Train loss 2.163 | Valid loss 2.133 | Valid acc 0.325\n",
            "Epoch 2 | Train loss 2.133 | Valid loss 2.104 | Valid acc 0.356\n",
            "Epoch 3 | Train loss 2.111 | Valid loss 2.071 | Valid acc 0.386\n",
            "Epoch 4 | Train loss 2.098 | Valid loss 2.066 | Valid acc 0.392\n",
            "Epoch 5 | Train loss 2.078 | Valid loss 2.060 | Valid acc 0.399\n",
            "Epoch 6 | Train loss 2.065 | Valid loss 2.047 | Valid acc 0.413\n",
            "Epoch 7 | Train loss 2.056 | Valid loss 2.055 | Valid acc 0.403\n",
            "Epoch 8 | Train loss 2.056 | Valid loss 2.035 | Valid acc 0.424\n",
            "Epoch 9 | Train loss 2.047 | Valid loss 2.030 | Valid acc 0.429\n",
            "Epoch 10 | Train loss 2.030 | Valid loss 2.013 | Valid acc 0.445\n",
            "Epoch 11 | Train loss 2.017 | Valid loss 1.995 | Valid acc 0.465\n",
            "Epoch 12 | Train loss 2.009 | Valid loss 1.985 | Valid acc 0.475\n",
            "Epoch 13 | Train loss 2.003 | Valid loss 1.992 | Valid acc 0.467\n",
            "Epoch 14 | Train loss 1.993 | Valid loss 1.985 | Valid acc 0.476\n",
            "Epoch 15 | Train loss 1.984 | Valid loss 1.981 | Valid acc 0.479\n",
            "Epoch 16 | Train loss 1.981 | Valid loss 1.978 | Valid acc 0.479\n",
            "Epoch 17 | Train loss 1.974 | Valid loss 1.978 | Valid acc 0.482\n",
            "Epoch 18 | Train loss 1.967 | Valid loss 1.961 | Valid acc 0.499\n",
            "Epoch 19 | Train loss 1.961 | Valid loss 1.956 | Valid acc 0.502\n",
            "Epoch 20 | Train loss 1.958 | Valid loss 1.940 | Valid acc 0.518\n",
            "Epoch 21 | Train loss 1.953 | Valid loss 1.956 | Valid acc 0.504\n",
            "Epoch 22 | Train loss 1.946 | Valid loss 1.943 | Valid acc 0.516\n",
            "Epoch 23 | Train loss 1.943 | Valid loss 1.947 | Valid acc 0.514\n",
            "Epoch 24 | Train loss 1.938 | Valid loss 1.954 | Valid acc 0.507\n",
            "Epoch 25 | Train loss 1.930 | Valid loss 1.938 | Valid acc 0.521\n",
            "Epoch 26 | Train loss 1.927 | Valid loss 1.936 | Valid acc 0.522\n",
            "Epoch 27 | Train loss 1.921 | Valid loss 1.934 | Valid acc 0.526\n",
            "Epoch 28 | Train loss 1.918 | Valid loss 1.938 | Valid acc 0.521\n",
            "Epoch 29 | Train loss 1.913 | Valid loss 1.941 | Valid acc 0.516\n",
            "Finally!\n",
            "best_valid_acc 0.5259\n",
            "Epoch 0 | Train loss 2.308 | Valid loss 2.271 | Valid acc 0.189\n",
            "Epoch 1 | Train loss 2.276 | Valid loss 2.244 | Valid acc 0.215\n",
            "Epoch 2 | Train loss 2.238 | Valid loss 2.208 | Valid acc 0.251\n",
            "Epoch 3 | Train loss 2.207 | Valid loss 2.187 | Valid acc 0.272\n",
            "Epoch 4 | Train loss 2.196 | Valid loss 2.170 | Valid acc 0.288\n",
            "Epoch 5 | Train loss 2.187 | Valid loss 2.163 | Valid acc 0.298\n",
            "Epoch 6 | Train loss 2.179 | Valid loss 2.158 | Valid acc 0.301\n",
            "Epoch 7 | Train loss 2.177 | Valid loss 2.159 | Valid acc 0.299\n",
            "Epoch 8 | Train loss 2.168 | Valid loss 2.156 | Valid acc 0.304\n",
            "Epoch 9 | Train loss 2.164 | Valid loss 2.158 | Valid acc 0.303\n",
            "Epoch 10 | Train loss 2.166 | Valid loss 2.143 | Valid acc 0.318\n",
            "Epoch 11 | Train loss 2.159 | Valid loss 2.152 | Valid acc 0.308\n",
            "Epoch 12 | Train loss 2.153 | Valid loss 2.145 | Valid acc 0.317\n",
            "Epoch 13 | Train loss 2.153 | Valid loss 2.153 | Valid acc 0.310\n",
            "Epoch 14 | Train loss 2.148 | Valid loss 2.137 | Valid acc 0.322\n",
            "Epoch 15 | Train loss 2.144 | Valid loss 2.137 | Valid acc 0.323\n",
            "Epoch 16 | Train loss 2.137 | Valid loss 2.135 | Valid acc 0.325\n",
            "Epoch 17 | Train loss 2.136 | Valid loss 2.131 | Valid acc 0.329\n",
            "Epoch 18 | Train loss 2.129 | Valid loss 2.108 | Valid acc 0.349\n",
            "Epoch 19 | Train loss 2.125 | Valid loss 2.114 | Valid acc 0.346\n",
            "Epoch 20 | Train loss 2.120 | Valid loss 2.102 | Valid acc 0.357\n",
            "Epoch 21 | Train loss 2.115 | Valid loss 2.107 | Valid acc 0.353\n",
            "Epoch 22 | Train loss 2.111 | Valid loss 2.108 | Valid acc 0.354\n",
            "Epoch 23 | Train loss 2.109 | Valid loss 2.099 | Valid acc 0.360\n",
            "Epoch 24 | Train loss 2.101 | Valid loss 2.096 | Valid acc 0.365\n",
            "Epoch 25 | Train loss 2.102 | Valid loss 2.087 | Valid acc 0.374\n",
            "Epoch 26 | Train loss 2.095 | Valid loss 2.089 | Valid acc 0.372\n",
            "Epoch 27 | Train loss 2.093 | Valid loss 2.086 | Valid acc 0.374\n",
            "Epoch 28 | Train loss 2.089 | Valid loss 2.080 | Valid acc 0.377\n",
            "Epoch 29 | Train loss 2.090 | Valid loss 2.082 | Valid acc 0.376\n",
            "Finally!\n",
            "best_valid_acc 0.3768\n",
            "Epoch 0 | Train loss 2.306 | Valid loss 2.341 | Valid acc 0.121\n",
            "Epoch 1 | Train loss 2.287 | Valid loss 2.280 | Valid acc 0.181\n",
            "Epoch 2 | Train loss 2.257 | Valid loss 2.235 | Valid acc 0.223\n",
            "Epoch 3 | Train loss 2.247 | Valid loss 2.218 | Valid acc 0.242\n",
            "Epoch 4 | Train loss 2.225 | Valid loss 2.218 | Valid acc 0.241\n",
            "Epoch 5 | Train loss 2.229 | Valid loss 2.235 | Valid acc 0.226\n",
            "Epoch 6 | Train loss 2.233 | Valid loss 2.273 | Valid acc 0.188\n",
            "Epoch 7 | Train loss 2.243 | Valid loss 2.224 | Valid acc 0.237\n",
            "Epoch 8 | Train loss 2.228 | Valid loss 2.212 | Valid acc 0.250\n",
            "Epoch 9 | Train loss 2.232 | Valid loss 2.234 | Valid acc 0.226\n",
            "Epoch 10 | Train loss 2.223 | Valid loss 2.217 | Valid acc 0.245\n",
            "Epoch 11 | Train loss 2.216 | Valid loss 2.215 | Valid acc 0.245\n",
            "Epoch 12 | Train loss 2.217 | Valid loss 2.213 | Valid acc 0.248\n",
            "Epoch 13 | Train loss 2.215 | Valid loss 2.216 | Valid acc 0.246\n",
            "Epoch 14 | Train loss 2.209 | Valid loss 2.208 | Valid acc 0.254\n",
            "Epoch 15 | Train loss 2.206 | Valid loss 2.205 | Valid acc 0.257\n",
            "Epoch 16 | Train loss 2.210 | Valid loss 2.212 | Valid acc 0.249\n",
            "Epoch 17 | Train loss 2.220 | Valid loss 2.222 | Valid acc 0.240\n",
            "Epoch 18 | Train loss 2.199 | Valid loss 2.205 | Valid acc 0.257\n",
            "Epoch 19 | Train loss 2.206 | Valid loss 2.197 | Valid acc 0.264\n",
            "Epoch 20 | Train loss 2.198 | Valid loss 2.199 | Valid acc 0.262\n",
            "Epoch 21 | Train loss 2.202 | Valid loss 2.205 | Valid acc 0.257\n",
            "Epoch 22 | Train loss 2.201 | Valid loss 2.211 | Valid acc 0.252\n",
            "Epoch 23 | Train loss 2.203 | Valid loss 2.199 | Valid acc 0.260\n",
            "Epoch 24 | Train loss 2.206 | Valid loss 2.210 | Valid acc 0.251\n",
            "Epoch 25 | Train loss 2.207 | Valid loss 2.206 | Valid acc 0.254\n",
            "Epoch 26 | Train loss 2.204 | Valid loss 2.194 | Valid acc 0.266\n",
            "Epoch 27 | Train loss 2.202 | Valid loss 2.204 | Valid acc 0.257\n",
            "Epoch 28 | Train loss 2.201 | Valid loss 2.222 | Valid acc 0.239\n",
            "Epoch 29 | Train loss 2.207 | Valid loss 2.208 | Valid acc 0.250\n",
            "Finally!\n",
            "best_valid_acc 0.2664\n",
            "Epoch 0 | Train loss 2.301 | Valid loss 2.270 | Valid acc 0.190\n",
            "Epoch 1 | Train loss 2.259 | Valid loss 2.213 | Valid acc 0.247\n",
            "Epoch 2 | Train loss 2.218 | Valid loss 2.183 | Valid acc 0.275\n",
            "Epoch 3 | Train loss 2.190 | Valid loss 2.139 | Valid acc 0.321\n",
            "Epoch 4 | Train loss 2.165 | Valid loss 2.114 | Valid acc 0.343\n",
            "Epoch 5 | Train loss 2.138 | Valid loss 2.107 | Valid acc 0.355\n",
            "Epoch 6 | Train loss 2.123 | Valid loss 2.093 | Valid acc 0.366\n",
            "Epoch 7 | Train loss 2.109 | Valid loss 2.079 | Valid acc 0.377\n",
            "Epoch 8 | Train loss 2.100 | Valid loss 2.071 | Valid acc 0.387\n",
            "Epoch 9 | Train loss 2.095 | Valid loss 2.064 | Valid acc 0.393\n",
            "Epoch 10 | Train loss 2.086 | Valid loss 2.056 | Valid acc 0.402\n",
            "Epoch 11 | Train loss 2.078 | Valid loss 2.052 | Valid acc 0.406\n",
            "Epoch 12 | Train loss 2.070 | Valid loss 2.056 | Valid acc 0.404\n",
            "Epoch 13 | Train loss 2.064 | Valid loss 2.052 | Valid acc 0.407\n",
            "Epoch 14 | Train loss 2.056 | Valid loss 2.047 | Valid acc 0.413\n",
            "Epoch 15 | Train loss 2.052 | Valid loss 2.042 | Valid acc 0.419\n",
            "Epoch 16 | Train loss 2.047 | Valid loss 2.035 | Valid acc 0.424\n",
            "Epoch 17 | Train loss 2.043 | Valid loss 2.032 | Valid acc 0.429\n",
            "Epoch 18 | Train loss 2.039 | Valid loss 2.034 | Valid acc 0.426\n",
            "Epoch 19 | Train loss 2.030 | Valid loss 2.026 | Valid acc 0.432\n",
            "Epoch 20 | Train loss 2.030 | Valid loss 2.022 | Valid acc 0.440\n",
            "Epoch 21 | Train loss 2.028 | Valid loss 2.018 | Valid acc 0.443\n",
            "Epoch 22 | Train loss 2.023 | Valid loss 2.017 | Valid acc 0.443\n",
            "Epoch 23 | Train loss 2.017 | Valid loss 2.011 | Valid acc 0.451\n",
            "Epoch 24 | Train loss 2.013 | Valid loss 2.003 | Valid acc 0.456\n",
            "Epoch 25 | Train loss 2.009 | Valid loss 2.006 | Valid acc 0.454\n",
            "Epoch 26 | Train loss 2.006 | Valid loss 1.994 | Valid acc 0.465\n",
            "Epoch 27 | Train loss 1.997 | Valid loss 1.992 | Valid acc 0.466\n",
            "Epoch 28 | Train loss 1.997 | Valid loss 1.988 | Valid acc 0.473\n",
            "Epoch 29 | Train loss 1.994 | Valid loss 1.989 | Valid acc 0.471\n",
            "Finally!\n",
            "best_valid_acc 0.4733\n",
            "Epoch 0 | Train loss 2.290 | Valid loss 2.268 | Valid acc 0.192\n",
            "Epoch 1 | Train loss 2.263 | Valid loss 2.249 | Valid acc 0.211\n",
            "Epoch 2 | Train loss 2.244 | Valid loss 2.238 | Valid acc 0.223\n",
            "Epoch 3 | Train loss 2.237 | Valid loss 2.230 | Valid acc 0.231\n",
            "Epoch 4 | Train loss 2.235 | Valid loss 2.223 | Valid acc 0.235\n",
            "Epoch 5 | Train loss 2.228 | Valid loss 2.220 | Valid acc 0.240\n",
            "Epoch 6 | Train loss 2.224 | Valid loss 2.220 | Valid acc 0.242\n",
            "Epoch 7 | Train loss 2.222 | Valid loss 2.227 | Valid acc 0.235\n",
            "Epoch 8 | Train loss 2.221 | Valid loss 2.217 | Valid acc 0.244\n",
            "Epoch 9 | Train loss 2.215 | Valid loss 2.201 | Valid acc 0.257\n",
            "Epoch 10 | Train loss 2.214 | Valid loss 2.210 | Valid acc 0.251\n",
            "Epoch 11 | Train loss 2.209 | Valid loss 2.201 | Valid acc 0.259\n",
            "Epoch 12 | Train loss 2.212 | Valid loss 2.198 | Valid acc 0.263\n",
            "Epoch 13 | Train loss 2.208 | Valid loss 2.221 | Valid acc 0.242\n",
            "Epoch 14 | Train loss 2.206 | Valid loss 2.200 | Valid acc 0.261\n",
            "Epoch 15 | Train loss 2.201 | Valid loss 2.199 | Valid acc 0.262\n",
            "Epoch 16 | Train loss 2.202 | Valid loss 2.199 | Valid acc 0.261\n",
            "Epoch 17 | Train loss 2.198 | Valid loss 2.197 | Valid acc 0.266\n",
            "Epoch 18 | Train loss 2.197 | Valid loss 2.192 | Valid acc 0.269\n",
            "Epoch 19 | Train loss 2.199 | Valid loss 2.196 | Valid acc 0.262\n",
            "Epoch 20 | Train loss 2.194 | Valid loss 2.195 | Valid acc 0.266\n",
            "Epoch 21 | Train loss 2.193 | Valid loss 2.183 | Valid acc 0.277\n",
            "Epoch 22 | Train loss 2.191 | Valid loss 2.188 | Valid acc 0.271\n",
            "Epoch 23 | Train loss 2.191 | Valid loss 2.197 | Valid acc 0.265\n",
            "Epoch 24 | Train loss 2.190 | Valid loss 2.200 | Valid acc 0.261\n",
            "Epoch 25 | Train loss 2.197 | Valid loss 2.185 | Valid acc 0.275\n",
            "Epoch 26 | Train loss 2.187 | Valid loss 2.188 | Valid acc 0.275\n",
            "Epoch 27 | Train loss 2.187 | Valid loss 2.180 | Valid acc 0.280\n",
            "Epoch 28 | Train loss 2.190 | Valid loss 2.187 | Valid acc 0.273\n",
            "Epoch 29 | Train loss 2.186 | Valid loss 2.179 | Valid acc 0.280\n",
            "Finally!\n",
            "best_valid_acc 0.2803\n",
            "Epoch 0 | Train loss 2.286 | Valid loss 2.254 | Valid acc 0.208\n",
            "Epoch 1 | Train loss 2.255 | Valid loss 2.223 | Valid acc 0.237\n",
            "Epoch 2 | Train loss 2.236 | Valid loss 2.208 | Valid acc 0.253\n",
            "Epoch 3 | Train loss 2.229 | Valid loss 2.214 | Valid acc 0.248\n",
            "Epoch 4 | Train loss 2.206 | Valid loss 2.197 | Valid acc 0.262\n",
            "Epoch 5 | Train loss 2.196 | Valid loss 2.179 | Valid acc 0.282\n",
            "Epoch 6 | Train loss 2.196 | Valid loss 2.194 | Valid acc 0.268\n",
            "Epoch 7 | Train loss 2.190 | Valid loss 2.175 | Valid acc 0.287\n",
            "Epoch 8 | Train loss 2.177 | Valid loss 2.167 | Valid acc 0.295\n",
            "Epoch 9 | Train loss 2.180 | Valid loss 2.158 | Valid acc 0.304\n",
            "Epoch 10 | Train loss 2.173 | Valid loss 2.160 | Valid acc 0.302\n",
            "Epoch 11 | Train loss 2.170 | Valid loss 2.143 | Valid acc 0.320\n",
            "Epoch 12 | Train loss 2.165 | Valid loss 2.154 | Valid acc 0.308\n",
            "Epoch 13 | Train loss 2.164 | Valid loss 2.128 | Valid acc 0.332\n",
            "Epoch 14 | Train loss 2.158 | Valid loss 2.141 | Valid acc 0.322\n",
            "Epoch 15 | Train loss 2.154 | Valid loss 2.134 | Valid acc 0.328\n",
            "Epoch 16 | Train loss 2.152 | Valid loss 2.142 | Valid acc 0.320\n",
            "Epoch 17 | Train loss 2.146 | Valid loss 2.128 | Valid acc 0.334\n",
            "Epoch 18 | Train loss 2.147 | Valid loss 2.140 | Valid acc 0.324\n",
            "Epoch 19 | Train loss 2.150 | Valid loss 2.162 | Valid acc 0.299\n",
            "Epoch 20 | Train loss 2.141 | Valid loss 2.132 | Valid acc 0.330\n",
            "Epoch 21 | Train loss 2.140 | Valid loss 2.122 | Valid acc 0.341\n",
            "Epoch 22 | Train loss 2.139 | Valid loss 2.116 | Valid acc 0.343\n",
            "Epoch 23 | Train loss 2.146 | Valid loss 2.139 | Valid acc 0.322\n",
            "Epoch 24 | Train loss 2.139 | Valid loss 2.123 | Valid acc 0.337\n",
            "Epoch 25 | Train loss 2.133 | Valid loss 2.114 | Valid acc 0.346\n",
            "Epoch 26 | Train loss 2.131 | Valid loss 2.120 | Valid acc 0.341\n",
            "Epoch 27 | Train loss 2.131 | Valid loss 2.120 | Valid acc 0.341\n",
            "Epoch 28 | Train loss 2.131 | Valid loss 2.126 | Valid acc 0.334\n",
            "Epoch 29 | Train loss 2.127 | Valid loss 2.110 | Valid acc 0.349\n",
            "Finally!\n",
            "best_valid_acc 0.3491\n",
            "Epoch 0 | Train loss 2.359 | Valid loss 2.366 | Valid acc 0.097\n",
            "Epoch 1 | Train loss 2.360 | Valid loss 2.366 | Valid acc 0.097\n",
            "Epoch 2 | Train loss 2.360 | Valid loss 2.364 | Valid acc 0.097\n",
            "Epoch 3 | Train loss 2.360 | Valid loss 2.365 | Valid acc 0.097\n",
            "Epoch 4 | Train loss 2.333 | Valid loss 2.302 | Valid acc 0.157\n",
            "Epoch 5 | Train loss 2.320 | Valid loss 2.326 | Valid acc 0.135\n",
            "Epoch 6 | Train loss 2.309 | Valid loss 2.330 | Valid acc 0.131\n",
            "Epoch 7 | Train loss 2.314 | Valid loss 2.311 | Valid acc 0.150\n",
            "Epoch 8 | Train loss 2.310 | Valid loss 2.301 | Valid acc 0.160\n",
            "Epoch 9 | Train loss 2.293 | Valid loss 2.288 | Valid acc 0.171\n",
            "Epoch 10 | Train loss 2.288 | Valid loss 2.287 | Valid acc 0.173\n",
            "Epoch 11 | Train loss 2.304 | Valid loss 2.314 | Valid acc 0.147\n",
            "Epoch 12 | Train loss 2.291 | Valid loss 2.291 | Valid acc 0.169\n",
            "Epoch 13 | Train loss 2.288 | Valid loss 2.285 | Valid acc 0.174\n",
            "Epoch 14 | Train loss 2.286 | Valid loss 2.290 | Valid acc 0.173\n",
            "Epoch 15 | Train loss 2.288 | Valid loss 2.290 | Valid acc 0.172\n",
            "Epoch 16 | Train loss 2.290 | Valid loss 2.289 | Valid acc 0.170\n",
            "Epoch 17 | Train loss 2.290 | Valid loss 2.296 | Valid acc 0.166\n",
            "Epoch 18 | Train loss 2.293 | Valid loss 2.295 | Valid acc 0.166\n",
            "Epoch 19 | Train loss 2.289 | Valid loss 2.292 | Valid acc 0.169\n",
            "Epoch 20 | Train loss 2.290 | Valid loss 2.293 | Valid acc 0.170\n",
            "Epoch 21 | Train loss 2.294 | Valid loss 2.294 | Valid acc 0.167\n",
            "Epoch 22 | Train loss 2.292 | Valid loss 2.293 | Valid acc 0.169\n",
            "Epoch 23 | Train loss 2.342 | Valid loss 2.360 | Valid acc 0.101\n",
            "Epoch 24 | Train loss 2.361 | Valid loss 2.360 | Valid acc 0.101\n",
            "Epoch 25 | Train loss 2.361 | Valid loss 2.360 | Valid acc 0.101\n",
            "Epoch 26 | Train loss 2.361 | Valid loss 2.358 | Valid acc 0.101\n",
            "Epoch 27 | Train loss 2.361 | Valid loss 2.360 | Valid acc 0.101\n",
            "Epoch 28 | Train loss 2.361 | Valid loss 2.360 | Valid acc 0.101\n",
            "Epoch 29 | Train loss 2.361 | Valid loss 2.360 | Valid acc 0.101\n",
            "Finally!\n",
            "best_valid_acc 0.1742\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7Mu2ZZHoZU0"
      },
      "source": [
        "Write down the **validation accuracy** of your model under different hyperparameter settings.\n",
        "\n",
        "| #channel for each layer | validation accuracy |\n",
        "|-------------------------|---------------------|\n",
        "| (128, 128, 128)         |      56.12          |\n",
        "| (128, 256, 512)         |      45.90          |\n",
        "| (256, 256, 256)         |      52.59          |\n",
        "| (256, 512, 1024)        |      37.68          |\n",
        "| (512, 512, 512)         |      47.33          |\n",
        "| (512, 1024, 2048)       |      34.91          |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UCaz8nWoWWS"
      },
      "source": [
        "For the best model you have, test it on the test set.\n",
        "\n",
        "It is fine if you found some hyperparameter combination better than those listed in the tables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtidyfEvzEG1",
        "outputId": "469df540-7782-47fa-abac-e9f08dbfae83"
      },
      "source": [
        "# evaluate the model here\n",
        "# train the model on the training set, find the best model/hyperparameter with validation set, and apply this best model on the test set\n",
        "\n",
        "model = CNN(128).cuda()\n",
        "model.load_state_dict(best_state_dict)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "test_loss, test_acc = evaluate(model, test_dataloader, criterion)\n",
        "print('Test loss {:.3f} | Test acc {:.3f}'.format(test_loss, test_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss 1.726 | Test acc 0.732\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSbhC8f1or6_"
      },
      "source": [
        "How much **test accuracy** do you get?\n",
        "\n",
        "**Your Answer:** 0.732\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG3E9ZckomkX"
      },
      "source": [
        "What can you conclude for the design of CNN structure?\n",
        "\n",
        "**Your Answer:**The design of structure is important. More epoch training is needed. The Adam optimizer can be used for optimization in the early stage, and SGD can be used for fine-tuning in the later stage. We can use regularization, dropout, batchnormal and other methods to prevent overfitting, but it requres more epochs. The size of the learning rate affects the learning speed of its own model, and a better learning rate can be more beneficial to model learning. After adding maxpool , the model performs worse in my case. I assume it's because of loss of information and not enough depth of model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWO5rjXuPIH5"
      },
      "source": [
        "## Recurrent Neural Networks (40 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2AmIPwBJt9j"
      },
      "source": [
        "Next, let's use PyTorch to implement a recurrent neural network for sentiment analysis, i.e., classifying sentences into given sentiment labels, including positive, negative and neutral.\n",
        "\n",
        "We use a benckmark dataset (i.e., SST) for this task. First, let's download the SST dataset, and do some preprocessing to build vocabulary and split the dataset into training/validation/test sets. Also, let's define the training and evaluation function. Please do not modify the functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT8b2nr7Kq73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af07d68a-c80f-4e4b-d2c3-4a751ee5c688"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torchtext\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "\n",
        "TEXT = data.Field(sequential=True, batch_first=True, lower=True)\n",
        "LABEL = data.LabelField()\n",
        "\n",
        "# load data splits\n",
        "train_data, val_data, test_data = datasets.SST.splits(TEXT, LABEL)\n",
        "\n",
        "# build dictionary\n",
        "TEXT.build_vocab(train_data)\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "vocab_size = len(TEXT.vocab)\n",
        "label_size = len(LABEL.vocab)\n",
        "padding_idx = TEXT.vocab.stoi['<pad>']\n",
        "embedding_dim = 128\n",
        "hidden_dim = 128\n",
        "\n",
        "print(vocab_size,label_size,embedding_dim)\n",
        "# build iterators\n",
        "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
        "    (train_data, val_data, test_data), \n",
        "    batch_size=32)\n",
        "\n",
        "# train a model\n",
        "# DO NOT MODIFY\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    total_loss, total_correct, total_prediction = 0.0, 0.0, 0.0\n",
        "    model.train()\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(batch.text.cuda())\n",
        "        predictions = torch.max(logits, dim=-1)[1]\n",
        "        loss = criterion(logits, batch.label.cuda())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        total_correct += torch.eq(predictions, batch.label.cuda()).sum().item()\n",
        "        total_prediction += batch.label.size(0)\n",
        "    return total_loss / len(iterator), total_correct / total_prediction\n",
        "\n",
        "# evaluate a model\n",
        "# DO NOT MODIFY\n",
        "def evaluate(model, iterator, criterion):  \n",
        "    total_loss, total_correct, total_prediction = 0.0, 0.0, 0.0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            logits = model(batch.text.cuda())\n",
        "            predictions = torch.max(logits, dim=-1)[1]\n",
        "            loss = criterion(logits, batch.label.cuda())\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_correct += torch.eq(predictions, batch.label.cuda()).sum().item()\n",
        "            total_prediction += batch.label.size(0)\n",
        "    return total_loss / len(iterator), total_correct / total_prediction"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16581 3 128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbWxFDZdK6rf"
      },
      "source": [
        "Next, we are ready to build our RNN model for sentiment analysis. In the following codes, we have provided several hyperparameters we needed for building the model, including vocabulary size (vocab_size), the word embedding dimension (embedding_dim), the hidden layer dimension (hidden_dim), the number of layers (num_layers) and the number of sentence labels (label_size). Please fill in the missing codes, and implement a RNN model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWUKPgDGNQSr"
      },
      "source": [
        "class RNNClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, label_size, padding_idx):\n",
        "        super(RNNClassifier, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.label_size = label_size\n",
        "        self.num_layers = 1\n",
        "\n",
        "        # add the layers required for sentiment analysis.\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim, padding_idx=padding_idx)\n",
        "        self.rnn = nn.LSTM(self.embedding_dim, self.hidden_dim, num_layers=self.num_layers,  \n",
        "                           bidirectional=False, batch_first=True)\n",
        "        self.fc = nn.Linear(self.hidden_dim*self.num_layers, self.label_size)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.sf = nn.Softmax(dim=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "        \n",
        "    def zero_state(self, batch_size): \n",
        "        # implement the function, which returns an initial hidden state.\n",
        "        h0 = torch.zeros(self.num_layers,batch_size,self.hidden_dim ).cuda()\n",
        "        c0 = torch.zeros(self.num_layers, batch_size,self.hidden_dim ).cuda()\n",
        "        return h0,c0\n",
        "\n",
        "    def forward(self, text):\n",
        "        # implement the forward function of the model.\n",
        "        embedding = self.embedding(text)\n",
        "        h0,c0 = self.zero_state(text.shape[0])\n",
        "        output, (hidden, cell) = self.rnn(embedding,(h0,c0)) \n",
        "#         hidden = self.dropout(hidden)\n",
        "        hidden = self.relu(hidden)\n",
        "        out = self.fc(hidden)\n",
        "        out = self.sf(out[0])\n",
        "        return out"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBX_xc9MN0gw"
      },
      "source": [
        "Finally, we are ready to train the model and compute the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQrU0wuUOIgb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66443c74-94b7-4c20-d78f-9b95800f38fb"
      },
      "source": [
        "# tune the optimizer type and hyperparameters with the following code as an example\n",
        "batch_size = 128\n",
        "lr = 1e-4\n",
        "EPOCHS = 30\n",
        "\n",
        "# call your model here\n",
        "model = RNNClassifier(vocab_size, embedding_dim, hidden_dim, label_size, padding_idx)\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "model.cuda()\n",
        "criterion.cuda()\n",
        "\n",
        "# train and test the model\n",
        "# you can reuse the following coding block for hyperparameter tuning\n",
        "# feel free to try more advanced training strategies\n",
        "best_valid_acc = 0.0\n",
        "best_state_dict = copy.deepcopy(model.state_dict())\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss, train_acc = train(model, train_iter, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, val_iter, criterion)\n",
        "\n",
        "    print('Epoch {} | Train loss {:.3f} | Valid loss {:.3f} | Valid acc {:.3f}'.format(epoch, train_loss, valid_loss, valid_acc))\n",
        "\n",
        "    if valid_acc > best_valid_acc:\n",
        "        best_valid_acc = valid_acc\n",
        "        best_state_dict = copy.deepcopy(model.state_dict())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 | Train loss 1.098 | Valid loss 1.100 | Valid acc 0.307\n",
            "Epoch 1 | Train loss 1.097 | Valid loss 1.100 | Valid acc 0.313\n",
            "Epoch 2 | Train loss 1.097 | Valid loss 1.100 | Valid acc 0.312\n",
            "Epoch 3 | Train loss 1.097 | Valid loss 1.100 | Valid acc 0.317\n",
            "Epoch 4 | Train loss 1.097 | Valid loss 1.100 | Valid acc 0.315\n",
            "Epoch 5 | Train loss 1.097 | Valid loss 1.100 | Valid acc 0.317\n",
            "Epoch 6 | Train loss 1.097 | Valid loss 1.100 | Valid acc 0.324\n",
            "Epoch 7 | Train loss 1.097 | Valid loss 1.100 | Valid acc 0.323\n",
            "Epoch 8 | Train loss 1.097 | Valid loss 1.099 | Valid acc 0.320\n",
            "Epoch 9 | Train loss 1.097 | Valid loss 1.099 | Valid acc 0.322\n",
            "Epoch 10 | Train loss 1.097 | Valid loss 1.099 | Valid acc 0.323\n",
            "Epoch 11 | Train loss 1.096 | Valid loss 1.099 | Valid acc 0.322\n",
            "Epoch 12 | Train loss 1.096 | Valid loss 1.099 | Valid acc 0.323\n",
            "Epoch 13 | Train loss 1.096 | Valid loss 1.099 | Valid acc 0.324\n",
            "Epoch 14 | Train loss 1.096 | Valid loss 1.099 | Valid acc 0.322\n",
            "Epoch 15 | Train loss 1.096 | Valid loss 1.099 | Valid acc 0.322\n",
            "Epoch 16 | Train loss 1.096 | Valid loss 1.099 | Valid acc 0.322\n",
            "Epoch 17 | Train loss 1.096 | Valid loss 1.099 | Valid acc 0.322\n",
            "Epoch 18 | Train loss 1.096 | Valid loss 1.099 | Valid acc 0.320\n",
            "Epoch 19 | Train loss 1.096 | Valid loss 1.098 | Valid acc 0.322\n",
            "Epoch 20 | Train loss 1.096 | Valid loss 1.098 | Valid acc 0.318\n",
            "Epoch 21 | Train loss 1.095 | Valid loss 1.098 | Valid acc 0.319\n",
            "Epoch 22 | Train loss 1.095 | Valid loss 1.098 | Valid acc 0.315\n",
            "Epoch 23 | Train loss 1.095 | Valid loss 1.098 | Valid acc 0.316\n",
            "Epoch 24 | Train loss 1.095 | Valid loss 1.098 | Valid acc 0.314\n",
            "Epoch 25 | Train loss 1.095 | Valid loss 1.098 | Valid acc 0.312\n",
            "Epoch 26 | Train loss 1.095 | Valid loss 1.098 | Valid acc 0.312\n",
            "Epoch 27 | Train loss 1.095 | Valid loss 1.098 | Valid acc 0.311\n",
            "Epoch 28 | Train loss 1.095 | Valid loss 1.098 | Valid acc 0.312\n",
            "Epoch 29 | Train loss 1.095 | Valid loss 1.098 | Valid acc 0.311\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EgT69I1reZ4"
      },
      "source": [
        "Once we find the best hyperparameters for the validation set, we can now evaluate our model on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPDvglccrdWt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "189d155d-3bd6-490e-cff6-be05028920e6"
      },
      "source": [
        "# evaluate the model here\n",
        "# train the model on the training set, find the best model/hyperparameter with validation set, and apply this best model on the test set\n",
        "\n",
        "model.load_state_dict(best_state_dict)\n",
        "test_loss, test_acc = evaluate(model, test_iter, criterion)\n",
        "print('Test loss {:.3f} | Test acc {:.3f}'.format(test_loss, test_acc))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss 1.099 | Test acc 0.379\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbqSAz90zBYi"
      },
      "source": [
        "### 1) Implement the RNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_5KEDzgzVxT"
      },
      "source": [
        "The current codes of the RNN model are not complete, so let's first complete the codes to implement a standard RNN model by filling in the [block](https://colab.research.google.com/drive/1mhhF9FPHSmePtVQrhNBwRujfUkOjUspj#scrollTo=kWUKPgDGNQSr)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiDCl9J0zIKO"
      },
      "source": [
        "- **Subtask 1-1: Creating all the Required Layers in Your Model**\n",
        "\n",
        "Remember that when building a deep learning model, we first need to complete the **init** function by creating all the required layers. In our case, since we are using RNNs for sentence classification, we need an embedding layer to transform words into word embeddings, a RNN layer to transform word embeddings into sentence encodings, an activation function, and a linear layer as well as a softmax function for sentence classification.\n",
        "\n",
        "Based on that, please create all the necessary layers of your RNN model in the **init** function. Note that we have already added the word embedding layer for you."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tF_dE-TqzL0A"
      },
      "source": [
        "- **Subtask 1-2: Implementing the Function for Initializing Hidden States**\n",
        "\n",
        "Remember that when applying a RNN unit to transform word embeddings into sentence encodings, the RNN unit starts from an initial hidden vector with all zero values, and sequentially read each word to update the hidden vector. Finally, the hidden vector obtained after reading the last word is treated as the sentence encoding.\n",
        "\n",
        "In this step, please implement the **zero_state** function, which returns a batch of initial hidden vectors given a batch size. Hint: your function should return a tensor with all the values being zero, and you may refer to the [official document](https://pytorch.org/docs/stable/nn.html#rnn) for the correct shape of the tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGiPTOnY28Iq"
      },
      "source": [
        "- **Subtask 1-3: Implementing the Forward Function**\n",
        "\n",
        "Finally, we are ready to build the forward function, which takes a batch of sentences as inputs and returns the a batch of logits. To be more specific, the input is given by the tensor called $\\text{text}$, and the size of the tensor is $(B, L)$, with $B$ being the batch size, $L$ being the maximum length of sentencees in this batch and $\\text{text}[i, j]$ being the interger id of the $j$-th word in the $i$-th sentence. Given this tensor as input, your forward function should return a logit tensor of size $(B, C)$, with $B$ being the batch size and $C$ being the number of possible classes.\n",
        "\n",
        "Please implement the forward function based on the above instructions. Note that we have already applied the word embedding layer to the text input, and obtained a tensor called $\\text{embedding}$, and the size of the tensor is $(B, L, D)$, where $D$ is the word embedding dimension. You can directly operate on the $\\text{embedding}$ tensor to compute the logits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUL9zYw4y_IZ"
      },
      "source": [
        "### 2) Compare Different Optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeKKFSkzzUA_"
      },
      "source": [
        "In the previous task, we have implemented a RNN model for sentiment analysis, or more generally sentence classification.\n",
        "\n",
        "To better understand several concepts in deep learning, let's do some ablation studies by using the model we have just implemented.\n",
        "\n",
        "The first task is to try different optimizers for your model, where for each optimizer, you may also try different options of learning rate. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaaUJCC2oBna",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d99d7bcb-d255-4373-8ef1-f609ac849090"
      },
      "source": [
        "batch_size = 128\n",
        "# 1e-3,1e-2,1e-1\n",
        "lr = [1e-4,1e-3,1e-2,1e-1]\n",
        "EPOCHS = 30\n",
        "for i in lr:\n",
        "    # call your model here\n",
        "    model = RNNClassifier(vocab_size, embedding_dim, hidden_dim, label_size, padding_idx)\n",
        "    for j in range(3):\n",
        "        if j ==0:\n",
        "            optimizer = optim.SGD(model.parameters(), lr=i)\n",
        "        elif j==1:\n",
        "            optimizer = optim.Adam(model.parameters(), lr=i)\n",
        "        else:\n",
        "            optimizer = optim.RMSprop (model.parameters(), lr=i)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        model.cuda()\n",
        "        criterion.cuda()\n",
        "\n",
        "        # train and test the model\n",
        "        # you can reuse the following coding block for hyperparameter tuning\n",
        "        # feel free to try more advanced training strategies\n",
        "        best_valid_acc = 0.0\n",
        "        best_state_dict = copy.deepcopy(model.state_dict())\n",
        "        for epoch in range(EPOCHS):\n",
        "            train_loss, train_acc = train(model, train_iter, optimizer, criterion)\n",
        "            valid_loss, valid_acc = evaluate(model, val_iter, criterion)\n",
        "\n",
        "            print('lr {} Epoch {} | Train loss {:.3f} | Valid loss {:.3f} | Valid acc {:.3f}'.format(i,epoch, train_loss, valid_loss, valid_acc))\n",
        "\n",
        "            if valid_acc > best_valid_acc:\n",
        "                best_valid_acc = valid_acc\n",
        "                best_state_dict = copy.deepcopy(model.state_dict())\n",
        "        model.load_state_dict(best_state_dict)\n",
        "        test_loss, test_acc = evaluate(model, test_iter, criterion)\n",
        "        print('Test loss {:.3f} | Test acc {:.3f}'.format(test_loss, test_acc))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lr 0.0001 Epoch 0 | Train loss 1.103 | Valid loss 1.100 | Valid acc 0.342\n",
            "lr 0.0001 Epoch 1 | Train loss 1.102 | Valid loss 1.100 | Valid acc 0.343\n",
            "lr 0.0001 Epoch 2 | Train loss 1.102 | Valid loss 1.100 | Valid acc 0.346\n",
            "lr 0.0001 Epoch 3 | Train loss 1.102 | Valid loss 1.099 | Valid acc 0.352\n",
            "lr 0.0001 Epoch 4 | Train loss 1.102 | Valid loss 1.099 | Valid acc 0.354\n",
            "lr 0.0001 Epoch 5 | Train loss 1.102 | Valid loss 1.099 | Valid acc 0.357\n",
            "lr 0.0001 Epoch 6 | Train loss 1.102 | Valid loss 1.099 | Valid acc 0.360\n",
            "lr 0.0001 Epoch 7 | Train loss 1.102 | Valid loss 1.099 | Valid acc 0.362\n",
            "lr 0.0001 Epoch 8 | Train loss 1.101 | Valid loss 1.099 | Valid acc 0.362\n",
            "lr 0.0001 Epoch 9 | Train loss 1.101 | Valid loss 1.099 | Valid acc 0.369\n",
            "lr 0.0001 Epoch 10 | Train loss 1.101 | Valid loss 1.099 | Valid acc 0.363\n",
            "lr 0.0001 Epoch 11 | Train loss 1.101 | Valid loss 1.099 | Valid acc 0.362\n",
            "lr 0.0001 Epoch 12 | Train loss 1.101 | Valid loss 1.098 | Valid acc 0.364\n",
            "lr 0.0001 Epoch 13 | Train loss 1.101 | Valid loss 1.098 | Valid acc 0.369\n",
            "lr 0.0001 Epoch 14 | Train loss 1.101 | Valid loss 1.098 | Valid acc 0.376\n",
            "lr 0.0001 Epoch 15 | Train loss 1.101 | Valid loss 1.098 | Valid acc 0.378\n",
            "lr 0.0001 Epoch 16 | Train loss 1.101 | Valid loss 1.098 | Valid acc 0.381\n",
            "lr 0.0001 Epoch 17 | Train loss 1.100 | Valid loss 1.098 | Valid acc 0.376\n",
            "lr 0.0001 Epoch 18 | Train loss 1.100 | Valid loss 1.098 | Valid acc 0.380\n",
            "lr 0.0001 Epoch 19 | Train loss 1.100 | Valid loss 1.098 | Valid acc 0.385\n",
            "lr 0.0001 Epoch 20 | Train loss 1.100 | Valid loss 1.098 | Valid acc 0.387\n",
            "lr 0.0001 Epoch 21 | Train loss 1.100 | Valid loss 1.097 | Valid acc 0.386\n",
            "lr 0.0001 Epoch 22 | Train loss 1.100 | Valid loss 1.097 | Valid acc 0.391\n",
            "lr 0.0001 Epoch 23 | Train loss 1.100 | Valid loss 1.097 | Valid acc 0.395\n",
            "lr 0.0001 Epoch 24 | Train loss 1.100 | Valid loss 1.097 | Valid acc 0.396\n",
            "lr 0.0001 Epoch 25 | Train loss 1.099 | Valid loss 1.097 | Valid acc 0.393\n",
            "lr 0.0001 Epoch 26 | Train loss 1.099 | Valid loss 1.097 | Valid acc 0.391\n",
            "lr 0.0001 Epoch 27 | Train loss 1.099 | Valid loss 1.097 | Valid acc 0.396\n",
            "lr 0.0001 Epoch 28 | Train loss 1.099 | Valid loss 1.097 | Valid acc 0.401\n",
            "lr 0.0001 Epoch 29 | Train loss 1.099 | Valid loss 1.097 | Valid acc 0.399\n",
            "Test loss 1.096 | Test acc 0.410\n",
            "lr 0.0001 Epoch 0 | Train loss 1.073 | Valid loss 1.055 | Valid acc 0.404\n",
            "lr 0.0001 Epoch 1 | Train loss 1.054 | Valid loss 1.055 | Valid acc 0.405\n",
            "lr 0.0001 Epoch 2 | Train loss 1.053 | Valid loss 1.052 | Valid acc 0.406\n",
            "lr 0.0001 Epoch 3 | Train loss 1.053 | Valid loss 1.051 | Valid acc 0.406\n",
            "lr 0.0001 Epoch 4 | Train loss 1.052 | Valid loss 1.051 | Valid acc 0.406\n",
            "lr 0.0001 Epoch 5 | Train loss 1.052 | Valid loss 1.049 | Valid acc 0.406\n",
            "lr 0.0001 Epoch 6 | Train loss 1.052 | Valid loss 1.050 | Valid acc 0.404\n",
            "lr 0.0001 Epoch 7 | Train loss 1.052 | Valid loss 1.047 | Valid acc 0.403\n",
            "lr 0.0001 Epoch 8 | Train loss 1.049 | Valid loss 1.046 | Valid acc 0.402\n",
            "lr 0.0001 Epoch 9 | Train loss 1.049 | Valid loss 1.044 | Valid acc 0.401\n",
            "lr 0.0001 Epoch 10 | Train loss 1.037 | Valid loss 1.048 | Valid acc 0.420\n",
            "lr 0.0001 Epoch 11 | Train loss 1.035 | Valid loss 1.037 | Valid acc 0.428\n",
            "lr 0.0001 Epoch 12 | Train loss 1.014 | Valid loss 1.028 | Valid acc 0.482\n",
            "lr 0.0001 Epoch 13 | Train loss 0.995 | Valid loss 1.030 | Valid acc 0.473\n",
            "lr 0.0001 Epoch 14 | Train loss 0.981 | Valid loss 1.024 | Valid acc 0.500\n",
            "lr 0.0001 Epoch 15 | Train loss 0.969 | Valid loss 1.021 | Valid acc 0.503\n",
            "lr 0.0001 Epoch 16 | Train loss 0.956 | Valid loss 1.026 | Valid acc 0.493\n",
            "lr 0.0001 Epoch 17 | Train loss 0.965 | Valid loss 1.010 | Valid acc 0.529\n",
            "lr 0.0001 Epoch 18 | Train loss 0.950 | Valid loss 1.009 | Valid acc 0.520\n",
            "lr 0.0001 Epoch 19 | Train loss 0.943 | Valid loss 1.010 | Valid acc 0.519\n",
            "lr 0.0001 Epoch 20 | Train loss 0.943 | Valid loss 1.015 | Valid acc 0.509\n",
            "lr 0.0001 Epoch 21 | Train loss 0.927 | Valid loss 1.010 | Valid acc 0.525\n",
            "lr 0.0001 Epoch 22 | Train loss 0.920 | Valid loss 1.008 | Valid acc 0.531\n",
            "lr 0.0001 Epoch 23 | Train loss 0.914 | Valid loss 1.007 | Valid acc 0.532\n",
            "lr 0.0001 Epoch 24 | Train loss 0.907 | Valid loss 1.005 | Valid acc 0.536\n",
            "lr 0.0001 Epoch 25 | Train loss 0.900 | Valid loss 1.005 | Valid acc 0.534\n",
            "lr 0.0001 Epoch 26 | Train loss 0.897 | Valid loss 1.006 | Valid acc 0.530\n",
            "lr 0.0001 Epoch 27 | Train loss 0.898 | Valid loss 1.000 | Valid acc 0.538\n",
            "lr 0.0001 Epoch 28 | Train loss 0.893 | Valid loss 1.004 | Valid acc 0.530\n",
            "lr 0.0001 Epoch 29 | Train loss 0.892 | Valid loss 1.005 | Valid acc 0.532\n",
            "Test loss 0.990 | Test acc 0.537\n",
            "lr 0.0001 Epoch 0 | Train loss 0.905 | Valid loss 1.004 | Valid acc 0.533\n",
            "lr 0.0001 Epoch 1 | Train loss 0.895 | Valid loss 1.011 | Valid acc 0.520\n",
            "lr 0.0001 Epoch 2 | Train loss 0.907 | Valid loss 1.001 | Valid acc 0.527\n",
            "lr 0.0001 Epoch 3 | Train loss 0.895 | Valid loss 1.003 | Valid acc 0.540\n",
            "lr 0.0001 Epoch 4 | Train loss 0.885 | Valid loss 1.002 | Valid acc 0.537\n",
            "lr 0.0001 Epoch 5 | Train loss 0.883 | Valid loss 0.998 | Valid acc 0.538\n",
            "lr 0.0001 Epoch 6 | Train loss 0.881 | Valid loss 0.999 | Valid acc 0.536\n",
            "lr 0.0001 Epoch 7 | Train loss 0.888 | Valid loss 1.001 | Valid acc 0.536\n",
            "lr 0.0001 Epoch 8 | Train loss 0.880 | Valid loss 0.997 | Valid acc 0.538\n",
            "lr 0.0001 Epoch 9 | Train loss 0.875 | Valid loss 0.999 | Valid acc 0.537\n",
            "lr 0.0001 Epoch 10 | Train loss 0.875 | Valid loss 1.002 | Valid acc 0.542\n",
            "lr 0.0001 Epoch 11 | Train loss 0.875 | Valid loss 0.993 | Valid acc 0.544\n",
            "lr 0.0001 Epoch 12 | Train loss 0.871 | Valid loss 0.997 | Valid acc 0.546\n",
            "lr 0.0001 Epoch 13 | Train loss 0.874 | Valid loss 0.992 | Valid acc 0.550\n",
            "lr 0.0001 Epoch 14 | Train loss 0.866 | Valid loss 0.994 | Valid acc 0.538\n",
            "lr 0.0001 Epoch 15 | Train loss 0.865 | Valid loss 0.992 | Valid acc 0.548\n",
            "lr 0.0001 Epoch 16 | Train loss 0.863 | Valid loss 0.994 | Valid acc 0.539\n",
            "lr 0.0001 Epoch 17 | Train loss 0.862 | Valid loss 0.995 | Valid acc 0.542\n",
            "lr 0.0001 Epoch 18 | Train loss 0.860 | Valid loss 0.994 | Valid acc 0.543\n",
            "lr 0.0001 Epoch 19 | Train loss 0.865 | Valid loss 0.991 | Valid acc 0.548\n",
            "lr 0.0001 Epoch 20 | Train loss 0.861 | Valid loss 0.988 | Valid acc 0.547\n",
            "lr 0.0001 Epoch 21 | Train loss 0.857 | Valid loss 0.990 | Valid acc 0.546\n",
            "lr 0.0001 Epoch 22 | Train loss 0.859 | Valid loss 0.995 | Valid acc 0.539\n",
            "lr 0.0001 Epoch 23 | Train loss 0.857 | Valid loss 0.989 | Valid acc 0.548\n",
            "lr 0.0001 Epoch 24 | Train loss 0.854 | Valid loss 0.988 | Valid acc 0.546\n",
            "lr 0.0001 Epoch 25 | Train loss 0.853 | Valid loss 0.988 | Valid acc 0.551\n",
            "lr 0.0001 Epoch 26 | Train loss 0.857 | Valid loss 0.986 | Valid acc 0.555\n",
            "lr 0.0001 Epoch 27 | Train loss 0.852 | Valid loss 0.986 | Valid acc 0.551\n",
            "lr 0.0001 Epoch 28 | Train loss 0.852 | Valid loss 0.990 | Valid acc 0.546\n",
            "lr 0.0001 Epoch 29 | Train loss 0.850 | Valid loss 0.987 | Valid acc 0.545\n",
            "Test loss 0.977 | Test acc 0.555\n",
            "lr 0.001 Epoch 0 | Train loss 1.096 | Valid loss 1.097 | Valid acc 0.384\n",
            "lr 0.001 Epoch 1 | Train loss 1.095 | Valid loss 1.096 | Valid acc 0.383\n",
            "lr 0.001 Epoch 2 | Train loss 1.095 | Valid loss 1.095 | Valid acc 0.377\n",
            "lr 0.001 Epoch 3 | Train loss 1.094 | Valid loss 1.095 | Valid acc 0.375\n",
            "lr 0.001 Epoch 4 | Train loss 1.093 | Valid loss 1.094 | Valid acc 0.370\n",
            "lr 0.001 Epoch 5 | Train loss 1.092 | Valid loss 1.093 | Valid acc 0.370\n",
            "lr 0.001 Epoch 6 | Train loss 1.091 | Valid loss 1.092 | Valid acc 0.363\n",
            "lr 0.001 Epoch 7 | Train loss 1.090 | Valid loss 1.092 | Valid acc 0.361\n",
            "lr 0.001 Epoch 8 | Train loss 1.089 | Valid loss 1.091 | Valid acc 0.361\n",
            "lr 0.001 Epoch 9 | Train loss 1.089 | Valid loss 1.090 | Valid acc 0.366\n",
            "lr 0.001 Epoch 10 | Train loss 1.088 | Valid loss 1.090 | Valid acc 0.356\n",
            "lr 0.001 Epoch 11 | Train loss 1.087 | Valid loss 1.089 | Valid acc 0.348\n",
            "lr 0.001 Epoch 12 | Train loss 1.086 | Valid loss 1.088 | Valid acc 0.346\n",
            "lr 0.001 Epoch 13 | Train loss 1.086 | Valid loss 1.088 | Valid acc 0.335\n",
            "lr 0.001 Epoch 14 | Train loss 1.085 | Valid loss 1.087 | Valid acc 0.322\n",
            "lr 0.001 Epoch 15 | Train loss 1.084 | Valid loss 1.087 | Valid acc 0.312\n",
            "lr 0.001 Epoch 16 | Train loss 1.084 | Valid loss 1.086 | Valid acc 0.313\n",
            "lr 0.001 Epoch 17 | Train loss 1.083 | Valid loss 1.086 | Valid acc 0.306\n",
            "lr 0.001 Epoch 18 | Train loss 1.083 | Valid loss 1.085 | Valid acc 0.307\n",
            "lr 0.001 Epoch 19 | Train loss 1.082 | Valid loss 1.085 | Valid acc 0.311\n",
            "lr 0.001 Epoch 20 | Train loss 1.082 | Valid loss 1.084 | Valid acc 0.319\n",
            "lr 0.001 Epoch 21 | Train loss 1.081 | Valid loss 1.084 | Valid acc 0.322\n",
            "lr 0.001 Epoch 22 | Train loss 1.081 | Valid loss 1.083 | Valid acc 0.323\n",
            "lr 0.001 Epoch 23 | Train loss 1.080 | Valid loss 1.083 | Valid acc 0.336\n",
            "lr 0.001 Epoch 24 | Train loss 1.080 | Valid loss 1.083 | Valid acc 0.337\n",
            "lr 0.001 Epoch 25 | Train loss 1.079 | Valid loss 1.082 | Valid acc 0.345\n",
            "lr 0.001 Epoch 26 | Train loss 1.079 | Valid loss 1.082 | Valid acc 0.350\n",
            "lr 0.001 Epoch 27 | Train loss 1.078 | Valid loss 1.081 | Valid acc 0.354\n",
            "lr 0.001 Epoch 28 | Train loss 1.078 | Valid loss 1.081 | Valid acc 0.363\n",
            "lr 0.001 Epoch 29 | Train loss 1.077 | Valid loss 1.081 | Valid acc 0.366\n",
            "Test loss 1.096 | Test acc 0.414\n",
            "lr 0.001 Epoch 0 | Train loss 1.057 | Valid loss 1.039 | Valid acc 0.394\n",
            "lr 0.001 Epoch 1 | Train loss 1.052 | Valid loss 1.037 | Valid acc 0.398\n",
            "lr 0.001 Epoch 2 | Train loss 1.053 | Valid loss 1.045 | Valid acc 0.398\n",
            "lr 0.001 Epoch 3 | Train loss 1.053 | Valid loss 1.051 | Valid acc 0.404\n",
            "lr 0.001 Epoch 4 | Train loss 1.053 | Valid loss 1.047 | Valid acc 0.402\n",
            "lr 0.001 Epoch 5 | Train loss 1.045 | Valid loss 1.030 | Valid acc 0.478\n",
            "lr 0.001 Epoch 6 | Train loss 1.002 | Valid loss 1.011 | Valid acc 0.512\n",
            "lr 0.001 Epoch 7 | Train loss 0.956 | Valid loss 1.005 | Valid acc 0.528\n",
            "lr 0.001 Epoch 8 | Train loss 0.944 | Valid loss 1.026 | Valid acc 0.505\n",
            "lr 0.001 Epoch 9 | Train loss 0.929 | Valid loss 1.001 | Valid acc 0.537\n",
            "lr 0.001 Epoch 10 | Train loss 0.902 | Valid loss 1.000 | Valid acc 0.540\n",
            "lr 0.001 Epoch 11 | Train loss 0.892 | Valid loss 1.001 | Valid acc 0.530\n",
            "lr 0.001 Epoch 12 | Train loss 0.917 | Valid loss 1.102 | Valid acc 0.439\n",
            "lr 0.001 Epoch 13 | Train loss 1.008 | Valid loss 1.008 | Valid acc 0.526\n",
            "lr 0.001 Epoch 14 | Train loss 0.892 | Valid loss 1.005 | Valid acc 0.529\n",
            "lr 0.001 Epoch 15 | Train loss 0.867 | Valid loss 1.004 | Valid acc 0.532\n",
            "lr 0.001 Epoch 16 | Train loss 0.855 | Valid loss 0.992 | Valid acc 0.543\n",
            "lr 0.001 Epoch 17 | Train loss 0.842 | Valid loss 0.992 | Valid acc 0.543\n",
            "lr 0.001 Epoch 18 | Train loss 0.835 | Valid loss 0.997 | Valid acc 0.540\n",
            "lr 0.001 Epoch 19 | Train loss 0.832 | Valid loss 0.997 | Valid acc 0.532\n",
            "lr 0.001 Epoch 20 | Train loss 0.829 | Valid loss 1.009 | Valid acc 0.511\n",
            "lr 0.001 Epoch 21 | Train loss 0.839 | Valid loss 0.998 | Valid acc 0.533\n",
            "lr 0.001 Epoch 22 | Train loss 0.828 | Valid loss 0.991 | Valid acc 0.538\n",
            "lr 0.001 Epoch 23 | Train loss 0.819 | Valid loss 0.997 | Valid acc 0.522\n",
            "lr 0.001 Epoch 24 | Train loss 0.794 | Valid loss 0.991 | Valid acc 0.520\n",
            "lr 0.001 Epoch 25 | Train loss 0.790 | Valid loss 0.999 | Valid acc 0.520\n",
            "lr 0.001 Epoch 26 | Train loss 0.788 | Valid loss 0.995 | Valid acc 0.528\n",
            "lr 0.001 Epoch 27 | Train loss 0.777 | Valid loss 1.007 | Valid acc 0.521\n",
            "lr 0.001 Epoch 28 | Train loss 0.760 | Valid loss 0.995 | Valid acc 0.532\n",
            "lr 0.001 Epoch 29 | Train loss 0.760 | Valid loss 0.997 | Valid acc 0.530\n",
            "Test loss 0.972 | Test acc 0.568\n",
            "lr 0.001 Epoch 0 | Train loss 0.850 | Valid loss 0.989 | Valid acc 0.554\n",
            "lr 0.001 Epoch 1 | Train loss 0.830 | Valid loss 0.986 | Valid acc 0.542\n",
            "lr 0.001 Epoch 2 | Train loss 0.815 | Valid loss 0.983 | Valid acc 0.546\n",
            "lr 0.001 Epoch 3 | Train loss 0.798 | Valid loss 0.985 | Valid acc 0.540\n",
            "lr 0.001 Epoch 4 | Train loss 0.790 | Valid loss 0.990 | Valid acc 0.530\n",
            "lr 0.001 Epoch 5 | Train loss 0.786 | Valid loss 0.983 | Valid acc 0.540\n",
            "lr 0.001 Epoch 6 | Train loss 0.769 | Valid loss 0.996 | Valid acc 0.522\n",
            "lr 0.001 Epoch 7 | Train loss 0.749 | Valid loss 1.003 | Valid acc 0.526\n",
            "lr 0.001 Epoch 8 | Train loss 0.749 | Valid loss 1.018 | Valid acc 0.503\n",
            "lr 0.001 Epoch 9 | Train loss 0.751 | Valid loss 1.014 | Valid acc 0.511\n",
            "lr 0.001 Epoch 10 | Train loss 0.737 | Valid loss 1.005 | Valid acc 0.525\n",
            "lr 0.001 Epoch 11 | Train loss 0.740 | Valid loss 1.003 | Valid acc 0.525\n",
            "lr 0.001 Epoch 12 | Train loss 0.740 | Valid loss 1.004 | Valid acc 0.524\n",
            "lr 0.001 Epoch 13 | Train loss 0.740 | Valid loss 1.000 | Valid acc 0.532\n",
            "lr 0.001 Epoch 14 | Train loss 0.747 | Valid loss 1.031 | Valid acc 0.495\n",
            "lr 0.001 Epoch 15 | Train loss 0.736 | Valid loss 1.009 | Valid acc 0.520\n",
            "lr 0.001 Epoch 16 | Train loss 0.739 | Valid loss 1.032 | Valid acc 0.495\n",
            "lr 0.001 Epoch 17 | Train loss 0.735 | Valid loss 1.008 | Valid acc 0.525\n",
            "lr 0.001 Epoch 18 | Train loss 0.734 | Valid loss 1.035 | Valid acc 0.488\n",
            "lr 0.001 Epoch 19 | Train loss 0.732 | Valid loss 1.017 | Valid acc 0.510\n",
            "lr 0.001 Epoch 20 | Train loss 0.737 | Valid loss 1.014 | Valid acc 0.519\n",
            "lr 0.001 Epoch 21 | Train loss 0.727 | Valid loss 1.015 | Valid acc 0.515\n",
            "lr 0.001 Epoch 22 | Train loss 0.724 | Valid loss 1.022 | Valid acc 0.510\n",
            "lr 0.001 Epoch 23 | Train loss 0.723 | Valid loss 1.023 | Valid acc 0.514\n",
            "lr 0.001 Epoch 24 | Train loss 0.739 | Valid loss 1.032 | Valid acc 0.490\n",
            "lr 0.001 Epoch 25 | Train loss 0.728 | Valid loss 1.030 | Valid acc 0.496\n",
            "lr 0.001 Epoch 26 | Train loss 0.723 | Valid loss 1.019 | Valid acc 0.513\n",
            "lr 0.001 Epoch 27 | Train loss 0.718 | Valid loss 1.036 | Valid acc 0.492\n",
            "lr 0.001 Epoch 28 | Train loss 0.711 | Valid loss 1.012 | Valid acc 0.520\n",
            "lr 0.001 Epoch 29 | Train loss 0.713 | Valid loss 1.023 | Valid acc 0.517\n",
            "Test loss 0.961 | Test acc 0.576\n",
            "lr 0.01 Epoch 0 | Train loss 1.089 | Valid loss 1.085 | Valid acc 0.461\n",
            "lr 0.01 Epoch 1 | Train loss 1.082 | Valid loss 1.080 | Valid acc 0.395\n",
            "lr 0.01 Epoch 2 | Train loss 1.077 | Valid loss 1.077 | Valid acc 0.400\n",
            "lr 0.01 Epoch 3 | Train loss 1.074 | Valid loss 1.074 | Valid acc 0.403\n",
            "lr 0.01 Epoch 4 | Train loss 1.071 | Valid loss 1.072 | Valid acc 0.405\n",
            "lr 0.01 Epoch 5 | Train loss 1.068 | Valid loss 1.070 | Valid acc 0.403\n",
            "lr 0.01 Epoch 6 | Train loss 1.067 | Valid loss 1.069 | Valid acc 0.403\n",
            "lr 0.01 Epoch 7 | Train loss 1.065 | Valid loss 1.068 | Valid acc 0.403\n",
            "lr 0.01 Epoch 8 | Train loss 1.064 | Valid loss 1.067 | Valid acc 0.403\n",
            "lr 0.01 Epoch 9 | Train loss 1.063 | Valid loss 1.066 | Valid acc 0.403\n",
            "lr 0.01 Epoch 10 | Train loss 1.062 | Valid loss 1.065 | Valid acc 0.403\n",
            "lr 0.01 Epoch 11 | Train loss 1.061 | Valid loss 1.065 | Valid acc 0.403\n",
            "lr 0.01 Epoch 12 | Train loss 1.061 | Valid loss 1.064 | Valid acc 0.403\n",
            "lr 0.01 Epoch 13 | Train loss 1.060 | Valid loss 1.064 | Valid acc 0.403\n",
            "lr 0.01 Epoch 14 | Train loss 1.060 | Valid loss 1.063 | Valid acc 0.403\n",
            "lr 0.01 Epoch 15 | Train loss 1.059 | Valid loss 1.063 | Valid acc 0.403\n",
            "lr 0.01 Epoch 16 | Train loss 1.059 | Valid loss 1.063 | Valid acc 0.403\n",
            "lr 0.01 Epoch 17 | Train loss 1.058 | Valid loss 1.062 | Valid acc 0.403\n",
            "lr 0.01 Epoch 18 | Train loss 1.058 | Valid loss 1.062 | Valid acc 0.403\n",
            "lr 0.01 Epoch 19 | Train loss 1.058 | Valid loss 1.062 | Valid acc 0.403\n",
            "lr 0.01 Epoch 20 | Train loss 1.057 | Valid loss 1.061 | Valid acc 0.403\n",
            "lr 0.01 Epoch 21 | Train loss 1.057 | Valid loss 1.061 | Valid acc 0.403\n",
            "lr 0.01 Epoch 22 | Train loss 1.057 | Valid loss 1.061 | Valid acc 0.403\n",
            "lr 0.01 Epoch 23 | Train loss 1.057 | Valid loss 1.061 | Valid acc 0.403\n",
            "lr 0.01 Epoch 24 | Train loss 1.057 | Valid loss 1.060 | Valid acc 0.403\n",
            "lr 0.01 Epoch 25 | Train loss 1.056 | Valid loss 1.060 | Valid acc 0.403\n",
            "lr 0.01 Epoch 26 | Train loss 1.056 | Valid loss 1.060 | Valid acc 0.403\n",
            "lr 0.01 Epoch 27 | Train loss 1.056 | Valid loss 1.060 | Valid acc 0.403\n",
            "lr 0.01 Epoch 28 | Train loss 1.056 | Valid loss 1.060 | Valid acc 0.403\n",
            "lr 0.01 Epoch 29 | Train loss 1.056 | Valid loss 1.059 | Valid acc 0.403\n",
            "Test loss 1.081 | Test acc 0.455\n",
            "lr 0.01 Epoch 0 | Train loss 1.056 | Valid loss 1.057 | Valid acc 0.404\n",
            "lr 0.01 Epoch 1 | Train loss 1.054 | Valid loss 1.071 | Valid acc 0.385\n",
            "lr 0.01 Epoch 2 | Train loss 1.053 | Valid loss 1.013 | Valid acc 0.534\n",
            "lr 0.01 Epoch 3 | Train loss 1.050 | Valid loss 1.064 | Valid acc 0.376\n",
            "lr 0.01 Epoch 4 | Train loss 1.034 | Valid loss 1.050 | Valid acc 0.466\n",
            "lr 0.01 Epoch 5 | Train loss 0.969 | Valid loss 1.019 | Valid acc 0.512\n",
            "lr 0.01 Epoch 6 | Train loss 0.914 | Valid loss 1.055 | Valid acc 0.474\n",
            "lr 0.01 Epoch 7 | Train loss 0.891 | Valid loss 1.067 | Valid acc 0.467\n",
            "lr 0.01 Epoch 8 | Train loss 0.869 | Valid loss 1.076 | Valid acc 0.453\n",
            "lr 0.01 Epoch 9 | Train loss 0.858 | Valid loss 1.063 | Valid acc 0.470\n",
            "lr 0.01 Epoch 10 | Train loss 0.846 | Valid loss 1.069 | Valid acc 0.464\n",
            "lr 0.01 Epoch 11 | Train loss 0.840 | Valid loss 1.052 | Valid acc 0.472\n",
            "lr 0.01 Epoch 12 | Train loss 0.832 | Valid loss 1.050 | Valid acc 0.483\n",
            "lr 0.01 Epoch 13 | Train loss 0.828 | Valid loss 1.061 | Valid acc 0.466\n",
            "lr 0.01 Epoch 14 | Train loss 0.821 | Valid loss 1.044 | Valid acc 0.485\n",
            "lr 0.01 Epoch 15 | Train loss 0.814 | Valid loss 1.035 | Valid acc 0.498\n",
            "lr 0.01 Epoch 16 | Train loss 0.805 | Valid loss 1.058 | Valid acc 0.472\n",
            "lr 0.01 Epoch 17 | Train loss 0.798 | Valid loss 1.054 | Valid acc 0.474\n",
            "lr 0.01 Epoch 18 | Train loss 0.794 | Valid loss 1.048 | Valid acc 0.487\n",
            "lr 0.01 Epoch 19 | Train loss 0.786 | Valid loss 1.071 | Valid acc 0.460\n",
            "lr 0.01 Epoch 20 | Train loss 0.798 | Valid loss 1.067 | Valid acc 0.460\n",
            "lr 0.01 Epoch 21 | Train loss 0.784 | Valid loss 1.045 | Valid acc 0.496\n",
            "lr 0.01 Epoch 22 | Train loss 0.777 | Valid loss 1.066 | Valid acc 0.468\n",
            "lr 0.01 Epoch 23 | Train loss 0.793 | Valid loss 1.087 | Valid acc 0.429\n",
            "lr 0.01 Epoch 24 | Train loss 0.790 | Valid loss 1.058 | Valid acc 0.466\n",
            "lr 0.01 Epoch 25 | Train loss 0.791 | Valid loss 1.044 | Valid acc 0.489\n",
            "lr 0.01 Epoch 26 | Train loss 0.776 | Valid loss 1.069 | Valid acc 0.459\n",
            "lr 0.01 Epoch 27 | Train loss 0.769 | Valid loss 1.054 | Valid acc 0.481\n",
            "lr 0.01 Epoch 28 | Train loss 0.773 | Valid loss 1.051 | Valid acc 0.481\n",
            "lr 0.01 Epoch 29 | Train loss 0.767 | Valid loss 1.086 | Valid acc 0.438\n",
            "Test loss 1.029 | Test acc 0.510\n",
            "lr 0.01 Epoch 0 | Train loss 1.051 | Valid loss 1.033 | Valid acc 0.500\n",
            "lr 0.01 Epoch 1 | Train loss 1.027 | Valid loss 1.025 | Valid acc 0.505\n",
            "lr 0.01 Epoch 2 | Train loss 0.939 | Valid loss 1.047 | Valid acc 0.473\n",
            "lr 0.01 Epoch 3 | Train loss 0.874 | Valid loss 1.041 | Valid acc 0.476\n",
            "lr 0.01 Epoch 4 | Train loss 0.836 | Valid loss 1.039 | Valid acc 0.496\n",
            "lr 0.01 Epoch 5 | Train loss 0.812 | Valid loss 1.030 | Valid acc 0.507\n",
            "lr 0.01 Epoch 6 | Train loss 0.794 | Valid loss 1.033 | Valid acc 0.500\n",
            "lr 0.01 Epoch 7 | Train loss 0.778 | Valid loss 1.068 | Valid acc 0.460\n",
            "lr 0.01 Epoch 8 | Train loss 0.765 | Valid loss 1.033 | Valid acc 0.500\n",
            "lr 0.01 Epoch 9 | Train loss 0.748 | Valid loss 1.051 | Valid acc 0.480\n",
            "lr 0.01 Epoch 10 | Train loss 0.738 | Valid loss 1.044 | Valid acc 0.491\n",
            "lr 0.01 Epoch 11 | Train loss 0.733 | Valid loss 1.033 | Valid acc 0.502\n",
            "lr 0.01 Epoch 12 | Train loss 0.731 | Valid loss 1.051 | Valid acc 0.480\n",
            "lr 0.01 Epoch 13 | Train loss 0.735 | Valid loss 1.056 | Valid acc 0.480\n",
            "lr 0.01 Epoch 14 | Train loss 0.723 | Valid loss 1.025 | Valid acc 0.515\n",
            "lr 0.01 Epoch 15 | Train loss 0.714 | Valid loss 1.038 | Valid acc 0.495\n",
            "lr 0.01 Epoch 16 | Train loss 0.703 | Valid loss 1.060 | Valid acc 0.467\n",
            "lr 0.01 Epoch 17 | Train loss 0.706 | Valid loss 1.047 | Valid acc 0.489\n",
            "lr 0.01 Epoch 18 | Train loss 0.695 | Valid loss 1.035 | Valid acc 0.497\n",
            "lr 0.01 Epoch 19 | Train loss 0.696 | Valid loss 1.070 | Valid acc 0.465\n",
            "lr 0.01 Epoch 20 | Train loss 0.697 | Valid loss 1.065 | Valid acc 0.462\n",
            "lr 0.01 Epoch 21 | Train loss 0.693 | Valid loss 1.048 | Valid acc 0.482\n",
            "lr 0.01 Epoch 22 | Train loss 0.687 | Valid loss 1.082 | Valid acc 0.453\n",
            "lr 0.01 Epoch 23 | Train loss 0.682 | Valid loss 1.061 | Valid acc 0.460\n",
            "lr 0.01 Epoch 24 | Train loss 0.678 | Valid loss 1.055 | Valid acc 0.482\n",
            "lr 0.01 Epoch 25 | Train loss 0.679 | Valid loss 1.067 | Valid acc 0.462\n",
            "lr 0.01 Epoch 26 | Train loss 0.673 | Valid loss 1.073 | Valid acc 0.455\n",
            "lr 0.01 Epoch 27 | Train loss 0.665 | Valid loss 1.084 | Valid acc 0.446\n",
            "lr 0.01 Epoch 28 | Train loss 0.663 | Valid loss 1.071 | Valid acc 0.448\n",
            "lr 0.01 Epoch 29 | Train loss 0.670 | Valid loss 1.092 | Valid acc 0.428\n",
            "Test loss 1.002 | Test acc 0.534\n",
            "lr 0.1 Epoch 0 | Train loss 1.074 | Valid loss 1.070 | Valid acc 0.403\n",
            "lr 0.1 Epoch 1 | Train loss 1.061 | Valid loss 1.065 | Valid acc 0.403\n",
            "lr 0.1 Epoch 2 | Train loss 1.057 | Valid loss 1.062 | Valid acc 0.403\n",
            "lr 0.1 Epoch 3 | Train loss 1.056 | Valid loss 1.061 | Valid acc 0.403\n",
            "lr 0.1 Epoch 4 | Train loss 1.055 | Valid loss 1.060 | Valid acc 0.403\n",
            "lr 0.1 Epoch 5 | Train loss 1.054 | Valid loss 1.058 | Valid acc 0.403\n",
            "lr 0.1 Epoch 6 | Train loss 1.054 | Valid loss 1.059 | Valid acc 0.403\n",
            "lr 0.1 Epoch 7 | Train loss 1.053 | Valid loss 1.057 | Valid acc 0.403\n",
            "lr 0.1 Epoch 8 | Train loss 1.053 | Valid loss 1.055 | Valid acc 0.401\n",
            "lr 0.1 Epoch 9 | Train loss 1.053 | Valid loss 1.056 | Valid acc 0.403\n",
            "lr 0.1 Epoch 10 | Train loss 1.053 | Valid loss 1.056 | Valid acc 0.403\n",
            "lr 0.1 Epoch 11 | Train loss 1.053 | Valid loss 1.053 | Valid acc 0.401\n",
            "lr 0.1 Epoch 12 | Train loss 1.053 | Valid loss 1.053 | Valid acc 0.403\n",
            "lr 0.1 Epoch 13 | Train loss 1.053 | Valid loss 1.055 | Valid acc 0.403\n",
            "lr 0.1 Epoch 14 | Train loss 1.053 | Valid loss 1.055 | Valid acc 0.403\n",
            "lr 0.1 Epoch 15 | Train loss 1.053 | Valid loss 1.052 | Valid acc 0.402\n",
            "lr 0.1 Epoch 16 | Train loss 1.053 | Valid loss 1.055 | Valid acc 0.403\n",
            "lr 0.1 Epoch 17 | Train loss 1.053 | Valid loss 1.055 | Valid acc 0.403\n",
            "lr 0.1 Epoch 18 | Train loss 1.053 | Valid loss 1.054 | Valid acc 0.403\n",
            "lr 0.1 Epoch 19 | Train loss 1.053 | Valid loss 1.054 | Valid acc 0.403\n",
            "lr 0.1 Epoch 20 | Train loss 1.053 | Valid loss 1.054 | Valid acc 0.403\n",
            "lr 0.1 Epoch 21 | Train loss 1.052 | Valid loss 1.056 | Valid acc 0.403\n",
            "lr 0.1 Epoch 22 | Train loss 1.052 | Valid loss 1.051 | Valid acc 0.401\n",
            "lr 0.1 Epoch 23 | Train loss 1.052 | Valid loss 1.058 | Valid acc 0.403\n",
            "lr 0.1 Epoch 24 | Train loss 1.053 | Valid loss 1.053 | Valid acc 0.402\n",
            "lr 0.1 Epoch 25 | Train loss 1.053 | Valid loss 1.053 | Valid acc 0.402\n",
            "lr 0.1 Epoch 26 | Train loss 1.052 | Valid loss 1.055 | Valid acc 0.403\n",
            "lr 0.1 Epoch 27 | Train loss 1.052 | Valid loss 1.051 | Valid acc 0.403\n",
            "lr 0.1 Epoch 28 | Train loss 1.052 | Valid loss 1.053 | Valid acc 0.402\n",
            "lr 0.1 Epoch 29 | Train loss 1.052 | Valid loss 1.052 | Valid acc 0.402\n",
            "Test loss 1.060 | Test acc 0.411\n",
            "lr 0.1 Epoch 0 | Train loss 1.130 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 1 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 2 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 3 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 4 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 5 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 6 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 7 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 8 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 9 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 10 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 11 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 12 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 13 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 14 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 15 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 16 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 17 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 18 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 19 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 20 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 21 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 22 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 23 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 24 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 25 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 26 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 27 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 28 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 29 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "Test loss 1.139 | Test acc 0.411\n",
            "lr 0.1 Epoch 0 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 1 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 2 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 3 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 4 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 5 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 6 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 7 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 8 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 9 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 10 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 11 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 12 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 13 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 14 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 15 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 16 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 17 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 18 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 19 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 20 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 21 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 22 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 23 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 24 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 25 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 26 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 27 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 28 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "lr 0.1 Epoch 29 | Train loss 1.129 | Valid loss 1.147 | Valid acc 0.403\n",
            "Test loss 1.139 | Test acc 0.411\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNlnDbZtqHgi"
      },
      "source": [
        "- **Subtask 2-1: Completing the Table**\n",
        "\n",
        "We have provided the following table for different combinations of optimizers and learning rate, please write down the **validation accuracy** of your model with different optimizers and learning rates.\n",
        "\n",
        "|         | 0.1  | 0.01 | 0.001|0.0001|\n",
        "|---------|------|------|------|------|\n",
        "| SGD     |    0.354  |    0.403  |   0.303   |   0.409   |\n",
        "| Adam    |   0.486   |    0.519  |    0.51  |    0.549  |\n",
        "| RMSprop |  0.478    |  0.524    |   0.501   |  0.522    |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVVd5b9rzSFA"
      },
      "source": [
        "- **Subtask 2-2: Explaining your Observations**\n",
        "\n",
        "Based on your results, briefly explain your observations, e.g., which optimizer works the best, what is the optimal learning rate for each optimizer?\n",
        "\n",
        "*Your Answer:* The Adam optimizer outperformed SGD overall and won a little superiority compare to RMSprop. Averagely, Adam  works the best.\n",
        "SGD and Adam works well with LR equals to 0.0001. RMSpropwork well when LR is 0.01."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyy7qpHtzYJn"
      },
      "source": [
        "### 3) Compare the Results under Different Epoches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhXQERRizZO6"
      },
      "source": [
        "In this task, we hope to compare the results of our model under different training epoches, and answer a question."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2MuRxBPoBnb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c1fb8a3-f2ba-452a-af65-783835b1aa71"
      },
      "source": [
        "# tune the optimizer type and hyperparameters with the following code as an example\n",
        "batch_size = 128\n",
        "lr = 1e-4\n",
        "EPOCHS = [10,20,30,40,50]\n",
        "for epochs in EPOCHS:\n",
        "    # call your model here\n",
        "    model = RNNClassifier(vocab_size, embedding_dim, hidden_dim, label_size, padding_idx)\n",
        "    optimizer = optim.RMSprop(model.parameters(), lr=1e-4)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model.cuda()\n",
        "    criterion.cuda()\n",
        "\n",
        "    # train and test the model\n",
        "    # you can reuse the following coding block for hyperparameter tuning\n",
        "    # feel free to try more advanced training strategies\n",
        "    best_valid_acc = 0.0\n",
        "    best_state_dict = copy.deepcopy(model.state_dict())\n",
        "    for epoch in range(epochs):\n",
        "        train_loss, train_acc = train(model, train_iter, optimizer, criterion)\n",
        "        valid_loss, valid_acc = evaluate(model, val_iter, criterion)\n",
        "\n",
        "        print('Epoch {} | Train loss {:.3f} | Train acc {:.3f} |Valid loss {:.3f} | Valid acc {:.3f}'.format(epoch, train_loss,train_acc ,valid_loss, valid_acc))\n",
        "\n",
        "        if valid_acc > best_valid_acc:\n",
        "            best_valid_acc = valid_acc\n",
        "            best_state_dict = copy.deepcopy(model.state_dict())\n",
        "    # evaluate the model here\n",
        "    # train the model on the training set, find the best model/hyperparameter with validation set, and apply this best model on the test set\n",
        "\n",
        "    model.load_state_dict(best_state_dict)\n",
        "    test_loss, test_acc = evaluate(model, test_iter, criterion)\n",
        "    print('Test loss {:.3f} | Test acc {:.3f}'.format(test_loss, test_acc))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 | Train loss 1.062 | Train acc 0.419 |Valid loss 1.054 | Valid acc 0.400\n",
            "Epoch 1 | Train loss 1.054 | Train acc 0.423 |Valid loss 1.052 | Valid acc 0.399\n",
            "Epoch 2 | Train loss 1.053 | Train acc 0.423 |Valid loss 1.053 | Valid acc 0.411\n",
            "Epoch 3 | Train loss 1.052 | Train acc 0.429 |Valid loss 1.050 | Valid acc 0.434\n",
            "Epoch 4 | Train loss 1.047 | Train acc 0.454 |Valid loss 1.054 | Valid acc 0.481\n",
            "Epoch 5 | Train loss 1.036 | Train acc 0.484 |Valid loss 1.050 | Valid acc 0.455\n",
            "Epoch 6 | Train loss 1.027 | Train acc 0.503 |Valid loss 1.046 | Valid acc 0.481\n",
            "Epoch 7 | Train loss 1.017 | Train acc 0.515 |Valid loss 1.042 | Valid acc 0.480\n",
            "Epoch 8 | Train loss 1.004 | Train acc 0.537 |Valid loss 1.039 | Valid acc 0.470\n",
            "Epoch 9 | Train loss 0.993 | Train acc 0.548 |Valid loss 1.043 | Valid acc 0.488\n",
            "Test loss 1.038 | Test acc 0.438\n",
            "Epoch 0 | Train loss 1.063 | Train acc 0.412 |Valid loss 1.057 | Valid acc 0.402\n",
            "Epoch 1 | Train loss 1.053 | Train acc 0.423 |Valid loss 1.052 | Valid acc 0.404\n",
            "Epoch 2 | Train loss 1.053 | Train acc 0.423 |Valid loss 1.048 | Valid acc 0.404\n",
            "Epoch 3 | Train loss 1.053 | Train acc 0.423 |Valid loss 1.048 | Valid acc 0.408\n",
            "Epoch 4 | Train loss 1.052 | Train acc 0.423 |Valid loss 1.046 | Valid acc 0.412\n",
            "Epoch 5 | Train loss 1.050 | Train acc 0.439 |Valid loss 1.044 | Valid acc 0.416\n",
            "Epoch 6 | Train loss 1.039 | Train acc 0.480 |Valid loss 1.044 | Valid acc 0.416\n",
            "Epoch 7 | Train loss 1.028 | Train acc 0.499 |Valid loss 1.043 | Valid acc 0.430\n",
            "Epoch 8 | Train loss 1.018 | Train acc 0.518 |Valid loss 1.041 | Valid acc 0.441\n",
            "Epoch 9 | Train loss 1.007 | Train acc 0.535 |Valid loss 1.041 | Valid acc 0.470\n",
            "Epoch 10 | Train loss 0.998 | Train acc 0.547 |Valid loss 1.039 | Valid acc 0.467\n",
            "Epoch 11 | Train loss 0.985 | Train acc 0.561 |Valid loss 1.039 | Valid acc 0.462\n",
            "Epoch 12 | Train loss 0.977 | Train acc 0.564 |Valid loss 1.044 | Valid acc 0.459\n",
            "Epoch 13 | Train loss 0.965 | Train acc 0.582 |Valid loss 1.042 | Valid acc 0.461\n",
            "Epoch 14 | Train loss 0.954 | Train acc 0.593 |Valid loss 1.043 | Valid acc 0.458\n",
            "Epoch 15 | Train loss 0.949 | Train acc 0.597 |Valid loss 1.046 | Valid acc 0.470\n",
            "Epoch 16 | Train loss 0.936 | Train acc 0.613 |Valid loss 1.042 | Valid acc 0.467\n",
            "Epoch 17 | Train loss 0.931 | Train acc 0.620 |Valid loss 1.040 | Valid acc 0.472\n",
            "Epoch 18 | Train loss 0.919 | Train acc 0.632 |Valid loss 1.044 | Valid acc 0.471\n",
            "Epoch 19 | Train loss 0.911 | Train acc 0.640 |Valid loss 1.045 | Valid acc 0.473\n",
            "Test loss 1.011 | Test acc 0.505\n",
            "Epoch 0 | Train loss 1.060 | Train acc 0.416 |Valid loss 1.050 | Valid acc 0.404\n",
            "Epoch 1 | Train loss 1.053 | Train acc 0.423 |Valid loss 1.047 | Valid acc 0.400\n",
            "Epoch 2 | Train loss 1.053 | Train acc 0.422 |Valid loss 1.046 | Valid acc 0.399\n",
            "Epoch 3 | Train loss 1.053 | Train acc 0.423 |Valid loss 1.046 | Valid acc 0.397\n",
            "Epoch 4 | Train loss 1.052 | Train acc 0.423 |Valid loss 1.044 | Valid acc 0.398\n",
            "Epoch 5 | Train loss 1.052 | Train acc 0.422 |Valid loss 1.046 | Valid acc 0.400\n",
            "Epoch 6 | Train loss 1.052 | Train acc 0.421 |Valid loss 1.046 | Valid acc 0.400\n",
            "Epoch 7 | Train loss 1.052 | Train acc 0.420 |Valid loss 1.046 | Valid acc 0.402\n",
            "Epoch 8 | Train loss 1.051 | Train acc 0.425 |Valid loss 1.043 | Valid acc 0.408\n",
            "Epoch 9 | Train loss 1.050 | Train acc 0.433 |Valid loss 1.044 | Valid acc 0.441\n",
            "Epoch 10 | Train loss 1.043 | Train acc 0.467 |Valid loss 1.042 | Valid acc 0.457\n",
            "Epoch 11 | Train loss 1.030 | Train acc 0.498 |Valid loss 1.043 | Valid acc 0.482\n",
            "Epoch 12 | Train loss 1.019 | Train acc 0.516 |Valid loss 1.042 | Valid acc 0.478\n",
            "Epoch 13 | Train loss 1.010 | Train acc 0.528 |Valid loss 1.045 | Valid acc 0.468\n",
            "Epoch 14 | Train loss 0.999 | Train acc 0.543 |Valid loss 1.045 | Valid acc 0.461\n",
            "Epoch 15 | Train loss 0.989 | Train acc 0.556 |Valid loss 1.048 | Valid acc 0.467\n",
            "Epoch 16 | Train loss 0.978 | Train acc 0.566 |Valid loss 1.047 | Valid acc 0.457\n",
            "Epoch 17 | Train loss 0.967 | Train acc 0.581 |Valid loss 1.047 | Valid acc 0.466\n",
            "Epoch 18 | Train loss 0.957 | Train acc 0.591 |Valid loss 1.046 | Valid acc 0.462\n",
            "Epoch 19 | Train loss 0.949 | Train acc 0.596 |Valid loss 1.046 | Valid acc 0.472\n",
            "Epoch 20 | Train loss 0.938 | Train acc 0.611 |Valid loss 1.046 | Valid acc 0.471\n",
            "Epoch 21 | Train loss 0.928 | Train acc 0.622 |Valid loss 1.043 | Valid acc 0.482\n",
            "Epoch 22 | Train loss 0.919 | Train acc 0.631 |Valid loss 1.044 | Valid acc 0.478\n",
            "Epoch 23 | Train loss 0.909 | Train acc 0.640 |Valid loss 1.038 | Valid acc 0.487\n",
            "Epoch 24 | Train loss 0.902 | Train acc 0.648 |Valid loss 1.038 | Valid acc 0.487\n",
            "Epoch 25 | Train loss 0.892 | Train acc 0.658 |Valid loss 1.035 | Valid acc 0.499\n",
            "Epoch 26 | Train loss 0.889 | Train acc 0.660 |Valid loss 1.032 | Valid acc 0.508\n",
            "Epoch 27 | Train loss 0.885 | Train acc 0.663 |Valid loss 1.031 | Valid acc 0.505\n",
            "Epoch 28 | Train loss 0.880 | Train acc 0.670 |Valid loss 1.037 | Valid acc 0.494\n",
            "Epoch 29 | Train loss 0.876 | Train acc 0.675 |Valid loss 1.032 | Valid acc 0.497\n",
            "Test loss 1.008 | Test acc 0.514\n",
            "Epoch 0 | Train loss 1.061 | Train acc 0.422 |Valid loss 1.057 | Valid acc 0.399\n",
            "Epoch 1 | Train loss 1.054 | Train acc 0.422 |Valid loss 1.056 | Valid acc 0.398\n",
            "Epoch 2 | Train loss 1.053 | Train acc 0.422 |Valid loss 1.051 | Valid acc 0.400\n",
            "Epoch 3 | Train loss 1.051 | Train acc 0.438 |Valid loss 1.050 | Valid acc 0.407\n",
            "Epoch 4 | Train loss 1.041 | Train acc 0.477 |Valid loss 1.045 | Valid acc 0.428\n",
            "Epoch 5 | Train loss 1.032 | Train acc 0.490 |Valid loss 1.043 | Valid acc 0.432\n",
            "Epoch 6 | Train loss 1.021 | Train acc 0.509 |Valid loss 1.042 | Valid acc 0.477\n",
            "Epoch 7 | Train loss 1.009 | Train acc 0.530 |Valid loss 1.041 | Valid acc 0.500\n",
            "Epoch 8 | Train loss 0.995 | Train acc 0.549 |Valid loss 1.042 | Valid acc 0.480\n",
            "Epoch 9 | Train loss 0.988 | Train acc 0.554 |Valid loss 1.039 | Valid acc 0.494\n",
            "Epoch 10 | Train loss 0.976 | Train acc 0.574 |Valid loss 1.038 | Valid acc 0.485\n",
            "Epoch 11 | Train loss 0.965 | Train acc 0.584 |Valid loss 1.039 | Valid acc 0.478\n",
            "Epoch 12 | Train loss 0.953 | Train acc 0.596 |Valid loss 1.037 | Valid acc 0.500\n",
            "Epoch 13 | Train loss 0.946 | Train acc 0.603 |Valid loss 1.034 | Valid acc 0.498\n",
            "Epoch 14 | Train loss 0.934 | Train acc 0.613 |Valid loss 1.035 | Valid acc 0.500\n",
            "Epoch 15 | Train loss 0.923 | Train acc 0.627 |Valid loss 1.033 | Valid acc 0.493\n",
            "Epoch 16 | Train loss 0.913 | Train acc 0.637 |Valid loss 1.032 | Valid acc 0.498\n",
            "Epoch 17 | Train loss 0.905 | Train acc 0.642 |Valid loss 1.032 | Valid acc 0.503\n",
            "Epoch 18 | Train loss 0.897 | Train acc 0.653 |Valid loss 1.028 | Valid acc 0.512\n",
            "Epoch 19 | Train loss 0.888 | Train acc 0.662 |Valid loss 1.024 | Valid acc 0.524\n",
            "Epoch 20 | Train loss 0.881 | Train acc 0.670 |Valid loss 1.021 | Valid acc 0.518\n",
            "Epoch 21 | Train loss 0.877 | Train acc 0.672 |Valid loss 1.020 | Valid acc 0.524\n",
            "Epoch 22 | Train loss 0.869 | Train acc 0.680 |Valid loss 1.022 | Valid acc 0.515\n",
            "Epoch 23 | Train loss 0.865 | Train acc 0.684 |Valid loss 1.020 | Valid acc 0.516\n",
            "Epoch 24 | Train loss 0.858 | Train acc 0.690 |Valid loss 1.015 | Valid acc 0.530\n",
            "Epoch 25 | Train loss 0.856 | Train acc 0.694 |Valid loss 1.011 | Valid acc 0.537\n",
            "Epoch 26 | Train loss 0.852 | Train acc 0.697 |Valid loss 1.018 | Valid acc 0.527\n",
            "Epoch 27 | Train loss 0.847 | Train acc 0.704 |Valid loss 1.016 | Valid acc 0.530\n",
            "Epoch 28 | Train loss 0.843 | Train acc 0.708 |Valid loss 1.011 | Valid acc 0.535\n",
            "Epoch 29 | Train loss 0.839 | Train acc 0.712 |Valid loss 1.007 | Valid acc 0.542\n",
            "Epoch 30 | Train loss 0.840 | Train acc 0.710 |Valid loss 1.010 | Valid acc 0.540\n",
            "Epoch 31 | Train loss 0.840 | Train acc 0.710 |Valid loss 1.016 | Valid acc 0.532\n",
            "Epoch 32 | Train loss 0.838 | Train acc 0.712 |Valid loss 1.011 | Valid acc 0.537\n",
            "Epoch 33 | Train loss 0.834 | Train acc 0.715 |Valid loss 1.014 | Valid acc 0.531\n",
            "Epoch 34 | Train loss 0.830 | Train acc 0.719 |Valid loss 1.008 | Valid acc 0.537\n",
            "Epoch 35 | Train loss 0.826 | Train acc 0.723 |Valid loss 1.007 | Valid acc 0.534\n",
            "Epoch 36 | Train loss 0.824 | Train acc 0.727 |Valid loss 1.000 | Valid acc 0.552\n",
            "Epoch 37 | Train loss 0.823 | Train acc 0.729 |Valid loss 1.008 | Valid acc 0.530\n",
            "Epoch 38 | Train loss 0.824 | Train acc 0.725 |Valid loss 1.012 | Valid acc 0.530\n",
            "Epoch 39 | Train loss 0.827 | Train acc 0.724 |Valid loss 1.008 | Valid acc 0.530\n",
            "Test loss 0.977 | Test acc 0.552\n",
            "Epoch 0 | Train loss 1.061 | Train acc 0.422 |Valid loss 1.054 | Valid acc 0.401\n",
            "Epoch 1 | Train loss 1.053 | Train acc 0.422 |Valid loss 1.053 | Valid acc 0.402\n",
            "Epoch 2 | Train loss 1.053 | Train acc 0.421 |Valid loss 1.051 | Valid acc 0.401\n",
            "Epoch 3 | Train loss 1.052 | Train acc 0.427 |Valid loss 1.052 | Valid acc 0.412\n",
            "Epoch 4 | Train loss 1.048 | Train acc 0.456 |Valid loss 1.050 | Valid acc 0.444\n",
            "Epoch 5 | Train loss 1.037 | Train acc 0.489 |Valid loss 1.047 | Valid acc 0.518\n",
            "Epoch 6 | Train loss 1.026 | Train acc 0.510 |Valid loss 1.046 | Valid acc 0.537\n",
            "Epoch 7 | Train loss 1.019 | Train acc 0.517 |Valid loss 1.042 | Valid acc 0.520\n",
            "Epoch 8 | Train loss 1.007 | Train acc 0.535 |Valid loss 1.044 | Valid acc 0.500\n",
            "Epoch 9 | Train loss 0.999 | Train acc 0.545 |Valid loss 1.044 | Valid acc 0.502\n",
            "Epoch 10 | Train loss 0.989 | Train acc 0.556 |Valid loss 1.044 | Valid acc 0.494\n",
            "Epoch 11 | Train loss 0.974 | Train acc 0.574 |Valid loss 1.041 | Valid acc 0.499\n",
            "Epoch 12 | Train loss 0.961 | Train acc 0.587 |Valid loss 1.042 | Valid acc 0.492\n",
            "Epoch 13 | Train loss 0.953 | Train acc 0.594 |Valid loss 1.038 | Valid acc 0.499\n",
            "Epoch 14 | Train loss 0.943 | Train acc 0.603 |Valid loss 1.035 | Valid acc 0.504\n",
            "Epoch 15 | Train loss 0.932 | Train acc 0.616 |Valid loss 1.033 | Valid acc 0.500\n",
            "Epoch 16 | Train loss 0.925 | Train acc 0.627 |Valid loss 1.038 | Valid acc 0.490\n",
            "Epoch 17 | Train loss 0.911 | Train acc 0.639 |Valid loss 1.029 | Valid acc 0.510\n",
            "Epoch 18 | Train loss 0.903 | Train acc 0.649 |Valid loss 1.039 | Valid acc 0.483\n",
            "Epoch 19 | Train loss 0.896 | Train acc 0.656 |Valid loss 1.033 | Valid acc 0.499\n",
            "Epoch 20 | Train loss 0.891 | Train acc 0.660 |Valid loss 1.032 | Valid acc 0.495\n",
            "Epoch 21 | Train loss 0.884 | Train acc 0.668 |Valid loss 1.035 | Valid acc 0.488\n",
            "Epoch 22 | Train loss 0.876 | Train acc 0.675 |Valid loss 1.036 | Valid acc 0.485\n",
            "Epoch 23 | Train loss 0.873 | Train acc 0.677 |Valid loss 1.038 | Valid acc 0.480\n",
            "Epoch 24 | Train loss 0.869 | Train acc 0.683 |Valid loss 1.037 | Valid acc 0.479\n",
            "Epoch 25 | Train loss 0.867 | Train acc 0.683 |Valid loss 1.030 | Valid acc 0.493\n",
            "Epoch 26 | Train loss 0.861 | Train acc 0.690 |Valid loss 1.028 | Valid acc 0.495\n",
            "Epoch 27 | Train loss 0.857 | Train acc 0.693 |Valid loss 1.024 | Valid acc 0.499\n",
            "Epoch 28 | Train loss 0.857 | Train acc 0.693 |Valid loss 1.051 | Valid acc 0.458\n",
            "Epoch 29 | Train loss 0.854 | Train acc 0.697 |Valid loss 1.039 | Valid acc 0.470\n",
            "Epoch 30 | Train loss 0.851 | Train acc 0.700 |Valid loss 1.029 | Valid acc 0.490\n",
            "Epoch 31 | Train loss 0.845 | Train acc 0.706 |Valid loss 1.044 | Valid acc 0.466\n",
            "Epoch 32 | Train loss 0.849 | Train acc 0.701 |Valid loss 1.033 | Valid acc 0.480\n",
            "Epoch 33 | Train loss 0.847 | Train acc 0.703 |Valid loss 1.023 | Valid acc 0.495\n",
            "Epoch 34 | Train loss 0.840 | Train acc 0.712 |Valid loss 1.022 | Valid acc 0.508\n",
            "Epoch 35 | Train loss 0.848 | Train acc 0.702 |Valid loss 1.030 | Valid acc 0.478\n",
            "Epoch 36 | Train loss 0.840 | Train acc 0.710 |Valid loss 1.035 | Valid acc 0.481\n",
            "Epoch 37 | Train loss 0.841 | Train acc 0.708 |Valid loss 1.024 | Valid acc 0.498\n",
            "Epoch 38 | Train loss 0.837 | Train acc 0.713 |Valid loss 1.029 | Valid acc 0.490\n",
            "Epoch 39 | Train loss 0.839 | Train acc 0.712 |Valid loss 1.031 | Valid acc 0.492\n",
            "Epoch 40 | Train loss 0.834 | Train acc 0.715 |Valid loss 1.036 | Valid acc 0.490\n",
            "Epoch 41 | Train loss 0.833 | Train acc 0.716 |Valid loss 1.034 | Valid acc 0.480\n",
            "Epoch 42 | Train loss 0.831 | Train acc 0.719 |Valid loss 1.024 | Valid acc 0.499\n",
            "Epoch 43 | Train loss 0.827 | Train acc 0.723 |Valid loss 1.022 | Valid acc 0.510\n",
            "Epoch 44 | Train loss 0.832 | Train acc 0.717 |Valid loss 1.024 | Valid acc 0.498\n",
            "Epoch 45 | Train loss 0.829 | Train acc 0.720 |Valid loss 1.033 | Valid acc 0.484\n",
            "Epoch 46 | Train loss 0.830 | Train acc 0.719 |Valid loss 1.043 | Valid acc 0.472\n",
            "Epoch 47 | Train loss 0.827 | Train acc 0.722 |Valid loss 1.011 | Valid acc 0.517\n",
            "Epoch 48 | Train loss 0.831 | Train acc 0.717 |Valid loss 1.018 | Valid acc 0.508\n",
            "Epoch 49 | Train loss 0.826 | Train acc 0.722 |Valid loss 1.021 | Valid acc 0.503\n",
            "Test loss 1.037 | Test acc 0.495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JBBjTGd1zis"
      },
      "source": [
        "- **Subtask 3-1: Completing the Table**\n",
        "\n",
        "We have provided the following table, please write down the **training accuracy** and **validation accuracy** of your model under different epoches.\n",
        "\n",
        "|                    |  10  |  20  |  30  |  40  |  50  |\n",
        "|--------------------|------|------|------|------|------|\n",
        "| Training Accuracy  |   0.423   |    0.480  |  0.510    |   0.495   |   0.542   |\n",
        "| Validation Accuracy|   0.428   |    0.460  |  0.544    |    0.507  |   0.563   |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l82_FjXazdod"
      },
      "source": [
        "- **Subtask 3-2: Answering the Question**\n",
        "\n",
        "Is it always better to train a model for more epoches? How can we decide when should we stop training?\n",
        "\n",
        "*Your Answer:*No, if there is more data, more epochs can enhance the robustness of the model. In the case of a certain amount of data, more epochs will sometimes be over-fitting. When the validation accuracy initially drops, We donâ€™t need to stop training immediately, because it may be the saddle point after the gradient update that appears. In this case, we need to further update the weight. Continue the training for a few more epochs. If the validation error still does not decrease, then we can stop training at this time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "066JcRvAze7f"
      },
      "source": [
        "### 4) Compare Different Model Capacities/Configurations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agxhZpHYzjIR"
      },
      "source": [
        "In practice, we may also vary the capacity of our model to find the optimal choice. In this part, please try different configurations of your model, which have different model capacities. Based on your observation, please also answer a question."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKpApa_QoBnb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0c82b18-9ea6-47af-ea79-1aaabbf96b7a"
      },
      "source": [
        "# tune the optimizer type and hyperparameters with the following code as an example\n",
        "batch_size = 128\n",
        "lr = 1e-1\n",
        "EPOCHS = 30\n",
        "for hidden in [64,128,256]:\n",
        "    for embedding in [64,128,256]:\n",
        "        # call your model here\n",
        "        model = RNNClassifier(vocab_size, embedding, hidden, label_size, padding_idx)\n",
        "        optimizer = optim.SGD(model.parameters(), lr=1e-4)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        model.cuda()\n",
        "        criterion.cuda()\n",
        "\n",
        "        # train and test the model\n",
        "        # you can reuse the following coding block for hyperparameter tuning\n",
        "        # feel free to try more advanced training strategies\n",
        "        best_valid_acc = 0.0\n",
        "        best_state_dict = copy.deepcopy(model.state_dict())\n",
        "        for epoch in range(EPOCHS):\n",
        "            train_loss, train_acc = train(model, train_iter, optimizer, criterion)\n",
        "            valid_loss, valid_acc = evaluate(model, val_iter, criterion)\n",
        "\n",
        "            print('hidden{} Epoch {} | Train loss {:.3f} | Valid loss {:.3f} | Valid acc {:.3f}'.format(hidden,epoch, train_loss, valid_loss, valid_acc))\n",
        "\n",
        "            if valid_acc > best_valid_acc:\n",
        "                best_valid_acc = valid_acc\n",
        "                best_state_dict = copy.deepcopy(model.state_dict())\n",
        "        # evaluate the model here\n",
        "        # train the model on the training set, find the best model/hyperparameter with validation set, and apply this best model on the test set\n",
        "\n",
        "        model.load_state_dict(best_state_dict)\n",
        "        test_loss, test_acc = evaluate(model, test_iter, criterion)\n",
        "        print('Test loss {:.3f} | Test acc {:.3f}'.format(test_loss, test_acc))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hidden64 Epoch 0 | Train loss 1.102 | Valid loss 1.102 | Valid acc 0.280\n",
            "hidden64 Epoch 1 | Train loss 1.102 | Valid loss 1.102 | Valid acc 0.287\n",
            "hidden64 Epoch 2 | Train loss 1.102 | Valid loss 1.102 | Valid acc 0.290\n",
            "hidden64 Epoch 3 | Train loss 1.102 | Valid loss 1.101 | Valid acc 0.296\n",
            "hidden64 Epoch 4 | Train loss 1.102 | Valid loss 1.101 | Valid acc 0.306\n",
            "hidden64 Epoch 5 | Train loss 1.102 | Valid loss 1.101 | Valid acc 0.314\n",
            "hidden64 Epoch 6 | Train loss 1.102 | Valid loss 1.101 | Valid acc 0.317\n",
            "hidden64 Epoch 7 | Train loss 1.101 | Valid loss 1.101 | Valid acc 0.328\n",
            "hidden64 Epoch 8 | Train loss 1.101 | Valid loss 1.101 | Valid acc 0.342\n",
            "hidden64 Epoch 9 | Train loss 1.101 | Valid loss 1.101 | Valid acc 0.349\n",
            "hidden64 Epoch 10 | Train loss 1.101 | Valid loss 1.101 | Valid acc 0.354\n",
            "hidden64 Epoch 11 | Train loss 1.101 | Valid loss 1.101 | Valid acc 0.350\n",
            "hidden64 Epoch 12 | Train loss 1.101 | Valid loss 1.100 | Valid acc 0.357\n",
            "hidden64 Epoch 13 | Train loss 1.101 | Valid loss 1.100 | Valid acc 0.363\n",
            "hidden64 Epoch 14 | Train loss 1.101 | Valid loss 1.100 | Valid acc 0.367\n",
            "hidden64 Epoch 15 | Train loss 1.100 | Valid loss 1.100 | Valid acc 0.371\n",
            "hidden64 Epoch 16 | Train loss 1.100 | Valid loss 1.100 | Valid acc 0.380\n",
            "hidden64 Epoch 17 | Train loss 1.100 | Valid loss 1.100 | Valid acc 0.383\n",
            "hidden64 Epoch 18 | Train loss 1.100 | Valid loss 1.100 | Valid acc 0.385\n",
            "hidden64 Epoch 19 | Train loss 1.100 | Valid loss 1.100 | Valid acc 0.384\n",
            "hidden64 Epoch 20 | Train loss 1.100 | Valid loss 1.100 | Valid acc 0.389\n",
            "hidden64 Epoch 21 | Train loss 1.100 | Valid loss 1.100 | Valid acc 0.391\n",
            "hidden64 Epoch 22 | Train loss 1.100 | Valid loss 1.099 | Valid acc 0.391\n",
            "hidden64 Epoch 23 | Train loss 1.100 | Valid loss 1.099 | Valid acc 0.392\n",
            "hidden64 Epoch 24 | Train loss 1.099 | Valid loss 1.099 | Valid acc 0.391\n",
            "hidden64 Epoch 25 | Train loss 1.099 | Valid loss 1.099 | Valid acc 0.391\n",
            "hidden64 Epoch 26 | Train loss 1.099 | Valid loss 1.099 | Valid acc 0.392\n",
            "hidden64 Epoch 27 | Train loss 1.099 | Valid loss 1.099 | Valid acc 0.393\n",
            "hidden64 Epoch 28 | Train loss 1.099 | Valid loss 1.099 | Valid acc 0.395\n",
            "hidden64 Epoch 29 | Train loss 1.099 | Valid loss 1.099 | Valid acc 0.399\n",
            "Test loss 1.099 | Test acc 0.407\n",
            "hidden64 Epoch 0 | Train loss 1.099 | Valid loss 1.096 | Valid acc 0.389\n",
            "hidden64 Epoch 1 | Train loss 1.099 | Valid loss 1.096 | Valid acc 0.389\n",
            "hidden64 Epoch 2 | Train loss 1.098 | Valid loss 1.096 | Valid acc 0.389\n",
            "hidden64 Epoch 3 | Train loss 1.098 | Valid loss 1.096 | Valid acc 0.389\n",
            "hidden64 Epoch 4 | Train loss 1.098 | Valid loss 1.096 | Valid acc 0.389\n",
            "hidden64 Epoch 5 | Train loss 1.098 | Valid loss 1.096 | Valid acc 0.389\n",
            "hidden64 Epoch 6 | Train loss 1.098 | Valid loss 1.096 | Valid acc 0.389\n",
            "hidden64 Epoch 7 | Train loss 1.098 | Valid loss 1.096 | Valid acc 0.389\n",
            "hidden64 Epoch 8 | Train loss 1.098 | Valid loss 1.096 | Valid acc 0.389\n",
            "hidden64 Epoch 9 | Train loss 1.098 | Valid loss 1.096 | Valid acc 0.389\n",
            "hidden64 Epoch 10 | Train loss 1.098 | Valid loss 1.095 | Valid acc 0.389\n",
            "hidden64 Epoch 11 | Train loss 1.098 | Valid loss 1.095 | Valid acc 0.389\n",
            "hidden64 Epoch 12 | Train loss 1.097 | Valid loss 1.095 | Valid acc 0.389\n",
            "hidden64 Epoch 13 | Train loss 1.097 | Valid loss 1.095 | Valid acc 0.389\n",
            "hidden64 Epoch 14 | Train loss 1.097 | Valid loss 1.095 | Valid acc 0.389\n",
            "hidden64 Epoch 15 | Train loss 1.097 | Valid loss 1.095 | Valid acc 0.389\n",
            "hidden64 Epoch 16 | Train loss 1.097 | Valid loss 1.095 | Valid acc 0.389\n",
            "hidden64 Epoch 17 | Train loss 1.097 | Valid loss 1.095 | Valid acc 0.389\n",
            "hidden64 Epoch 18 | Train loss 1.097 | Valid loss 1.095 | Valid acc 0.389\n",
            "hidden64 Epoch 19 | Train loss 1.097 | Valid loss 1.095 | Valid acc 0.389\n",
            "hidden64 Epoch 20 | Train loss 1.097 | Valid loss 1.095 | Valid acc 0.389\n",
            "hidden64 Epoch 21 | Train loss 1.097 | Valid loss 1.094 | Valid acc 0.389\n",
            "hidden64 Epoch 22 | Train loss 1.097 | Valid loss 1.094 | Valid acc 0.389\n",
            "hidden64 Epoch 23 | Train loss 1.096 | Valid loss 1.094 | Valid acc 0.390\n",
            "hidden64 Epoch 24 | Train loss 1.096 | Valid loss 1.094 | Valid acc 0.390\n",
            "hidden64 Epoch 25 | Train loss 1.096 | Valid loss 1.094 | Valid acc 0.390\n",
            "hidden64 Epoch 26 | Train loss 1.096 | Valid loss 1.094 | Valid acc 0.390\n",
            "hidden64 Epoch 27 | Train loss 1.096 | Valid loss 1.094 | Valid acc 0.390\n",
            "hidden64 Epoch 28 | Train loss 1.096 | Valid loss 1.094 | Valid acc 0.390\n",
            "hidden64 Epoch 29 | Train loss 1.096 | Valid loss 1.094 | Valid acc 0.390\n",
            "Test loss 1.092 | Test acc 0.414\n",
            "hidden64 Epoch 0 | Train loss 1.093 | Valid loss 1.092 | Valid acc 0.422\n",
            "hidden64 Epoch 1 | Train loss 1.093 | Valid loss 1.092 | Valid acc 0.423\n",
            "hidden64 Epoch 2 | Train loss 1.093 | Valid loss 1.092 | Valid acc 0.423\n",
            "hidden64 Epoch 3 | Train loss 1.093 | Valid loss 1.092 | Valid acc 0.424\n",
            "hidden64 Epoch 4 | Train loss 1.093 | Valid loss 1.092 | Valid acc 0.424\n",
            "hidden64 Epoch 5 | Train loss 1.093 | Valid loss 1.092 | Valid acc 0.426\n",
            "hidden64 Epoch 6 | Train loss 1.093 | Valid loss 1.092 | Valid acc 0.426\n",
            "hidden64 Epoch 7 | Train loss 1.093 | Valid loss 1.092 | Valid acc 0.427\n",
            "hidden64 Epoch 8 | Train loss 1.092 | Valid loss 1.092 | Valid acc 0.428\n",
            "hidden64 Epoch 9 | Train loss 1.092 | Valid loss 1.092 | Valid acc 0.430\n",
            "hidden64 Epoch 10 | Train loss 1.092 | Valid loss 1.092 | Valid acc 0.431\n",
            "hidden64 Epoch 11 | Train loss 1.092 | Valid loss 1.092 | Valid acc 0.432\n",
            "hidden64 Epoch 12 | Train loss 1.092 | Valid loss 1.091 | Valid acc 0.432\n",
            "hidden64 Epoch 13 | Train loss 1.092 | Valid loss 1.091 | Valid acc 0.433\n",
            "hidden64 Epoch 14 | Train loss 1.092 | Valid loss 1.091 | Valid acc 0.436\n",
            "hidden64 Epoch 15 | Train loss 1.092 | Valid loss 1.091 | Valid acc 0.439\n",
            "hidden64 Epoch 16 | Train loss 1.092 | Valid loss 1.091 | Valid acc 0.439\n",
            "hidden64 Epoch 17 | Train loss 1.092 | Valid loss 1.091 | Valid acc 0.440\n",
            "hidden64 Epoch 18 | Train loss 1.092 | Valid loss 1.091 | Valid acc 0.440\n",
            "hidden64 Epoch 19 | Train loss 1.091 | Valid loss 1.091 | Valid acc 0.441\n",
            "hidden64 Epoch 20 | Train loss 1.091 | Valid loss 1.091 | Valid acc 0.439\n",
            "hidden64 Epoch 21 | Train loss 1.091 | Valid loss 1.091 | Valid acc 0.439\n",
            "hidden64 Epoch 22 | Train loss 1.091 | Valid loss 1.091 | Valid acc 0.440\n",
            "hidden64 Epoch 23 | Train loss 1.091 | Valid loss 1.091 | Valid acc 0.441\n",
            "hidden64 Epoch 24 | Train loss 1.091 | Valid loss 1.091 | Valid acc 0.443\n",
            "hidden64 Epoch 25 | Train loss 1.091 | Valid loss 1.090 | Valid acc 0.444\n",
            "hidden64 Epoch 26 | Train loss 1.091 | Valid loss 1.090 | Valid acc 0.448\n",
            "hidden64 Epoch 27 | Train loss 1.091 | Valid loss 1.090 | Valid acc 0.450\n",
            "hidden64 Epoch 28 | Train loss 1.091 | Valid loss 1.090 | Valid acc 0.452\n",
            "hidden64 Epoch 29 | Train loss 1.091 | Valid loss 1.090 | Valid acc 0.453\n",
            "Test loss 1.090 | Test acc 0.444\n",
            "hidden128 Epoch 0 | Train loss 1.098 | Valid loss 1.100 | Valid acc 0.225\n",
            "hidden128 Epoch 1 | Train loss 1.098 | Valid loss 1.100 | Valid acc 0.230\n",
            "hidden128 Epoch 2 | Train loss 1.098 | Valid loss 1.100 | Valid acc 0.230\n",
            "hidden128 Epoch 3 | Train loss 1.098 | Valid loss 1.100 | Valid acc 0.233\n",
            "hidden128 Epoch 4 | Train loss 1.098 | Valid loss 1.100 | Valid acc 0.233\n",
            "hidden128 Epoch 5 | Train loss 1.097 | Valid loss 1.100 | Valid acc 0.234\n",
            "hidden128 Epoch 6 | Train loss 1.097 | Valid loss 1.100 | Valid acc 0.237\n",
            "hidden128 Epoch 7 | Train loss 1.097 | Valid loss 1.099 | Valid acc 0.245\n",
            "hidden128 Epoch 8 | Train loss 1.097 | Valid loss 1.099 | Valid acc 0.250\n",
            "hidden128 Epoch 9 | Train loss 1.097 | Valid loss 1.099 | Valid acc 0.252\n",
            "hidden128 Epoch 10 | Train loss 1.097 | Valid loss 1.099 | Valid acc 0.257\n",
            "hidden128 Epoch 11 | Train loss 1.097 | Valid loss 1.099 | Valid acc 0.261\n",
            "hidden128 Epoch 12 | Train loss 1.097 | Valid loss 1.099 | Valid acc 0.267\n",
            "hidden128 Epoch 13 | Train loss 1.097 | Valid loss 1.099 | Valid acc 0.278\n",
            "hidden128 Epoch 14 | Train loss 1.096 | Valid loss 1.099 | Valid acc 0.284\n",
            "hidden128 Epoch 15 | Train loss 1.096 | Valid loss 1.099 | Valid acc 0.289\n",
            "hidden128 Epoch 16 | Train loss 1.096 | Valid loss 1.099 | Valid acc 0.300\n",
            "hidden128 Epoch 17 | Train loss 1.096 | Valid loss 1.098 | Valid acc 0.307\n",
            "hidden128 Epoch 18 | Train loss 1.096 | Valid loss 1.098 | Valid acc 0.306\n",
            "hidden128 Epoch 19 | Train loss 1.096 | Valid loss 1.098 | Valid acc 0.311\n",
            "hidden128 Epoch 20 | Train loss 1.096 | Valid loss 1.098 | Valid acc 0.317\n",
            "hidden128 Epoch 21 | Train loss 1.096 | Valid loss 1.098 | Valid acc 0.322\n",
            "hidden128 Epoch 22 | Train loss 1.096 | Valid loss 1.098 | Valid acc 0.326\n",
            "hidden128 Epoch 23 | Train loss 1.095 | Valid loss 1.098 | Valid acc 0.332\n",
            "hidden128 Epoch 24 | Train loss 1.095 | Valid loss 1.098 | Valid acc 0.334\n",
            "hidden128 Epoch 25 | Train loss 1.095 | Valid loss 1.098 | Valid acc 0.343\n",
            "hidden128 Epoch 26 | Train loss 1.095 | Valid loss 1.098 | Valid acc 0.345\n",
            "hidden128 Epoch 27 | Train loss 1.095 | Valid loss 1.098 | Valid acc 0.351\n",
            "hidden128 Epoch 28 | Train loss 1.095 | Valid loss 1.097 | Valid acc 0.354\n",
            "hidden128 Epoch 29 | Train loss 1.095 | Valid loss 1.097 | Valid acc 0.355\n",
            "Test loss 1.098 | Test acc 0.351\n",
            "hidden128 Epoch 0 | Train loss 1.101 | Valid loss 1.099 | Valid acc 0.272\n",
            "hidden128 Epoch 1 | Train loss 1.101 | Valid loss 1.099 | Valid acc 0.277\n",
            "hidden128 Epoch 2 | Train loss 1.101 | Valid loss 1.099 | Valid acc 0.281\n",
            "hidden128 Epoch 3 | Train loss 1.100 | Valid loss 1.099 | Valid acc 0.288\n",
            "hidden128 Epoch 4 | Train loss 1.100 | Valid loss 1.099 | Valid acc 0.289\n",
            "hidden128 Epoch 5 | Train loss 1.100 | Valid loss 1.099 | Valid acc 0.299\n",
            "hidden128 Epoch 6 | Train loss 1.100 | Valid loss 1.099 | Valid acc 0.315\n",
            "hidden128 Epoch 7 | Train loss 1.100 | Valid loss 1.098 | Valid acc 0.317\n",
            "hidden128 Epoch 8 | Train loss 1.100 | Valid loss 1.098 | Valid acc 0.323\n",
            "hidden128 Epoch 9 | Train loss 1.100 | Valid loss 1.098 | Valid acc 0.334\n",
            "hidden128 Epoch 10 | Train loss 1.100 | Valid loss 1.098 | Valid acc 0.353\n",
            "hidden128 Epoch 11 | Train loss 1.099 | Valid loss 1.098 | Valid acc 0.361\n",
            "hidden128 Epoch 12 | Train loss 1.099 | Valid loss 1.098 | Valid acc 0.369\n",
            "hidden128 Epoch 13 | Train loss 1.099 | Valid loss 1.098 | Valid acc 0.380\n",
            "hidden128 Epoch 14 | Train loss 1.099 | Valid loss 1.098 | Valid acc 0.383\n",
            "hidden128 Epoch 15 | Train loss 1.099 | Valid loss 1.098 | Valid acc 0.394\n",
            "hidden128 Epoch 16 | Train loss 1.099 | Valid loss 1.097 | Valid acc 0.405\n",
            "hidden128 Epoch 17 | Train loss 1.099 | Valid loss 1.097 | Valid acc 0.410\n",
            "hidden128 Epoch 18 | Train loss 1.099 | Valid loss 1.097 | Valid acc 0.417\n",
            "hidden128 Epoch 19 | Train loss 1.099 | Valid loss 1.097 | Valid acc 0.424\n",
            "hidden128 Epoch 20 | Train loss 1.098 | Valid loss 1.097 | Valid acc 0.431\n",
            "hidden128 Epoch 21 | Train loss 1.098 | Valid loss 1.097 | Valid acc 0.441\n",
            "hidden128 Epoch 22 | Train loss 1.098 | Valid loss 1.097 | Valid acc 0.451\n",
            "hidden128 Epoch 23 | Train loss 1.098 | Valid loss 1.097 | Valid acc 0.450\n",
            "hidden128 Epoch 24 | Train loss 1.098 | Valid loss 1.097 | Valid acc 0.457\n",
            "hidden128 Epoch 25 | Train loss 1.098 | Valid loss 1.097 | Valid acc 0.470\n",
            "hidden128 Epoch 26 | Train loss 1.098 | Valid loss 1.096 | Valid acc 0.471\n",
            "hidden128 Epoch 27 | Train loss 1.098 | Valid loss 1.096 | Valid acc 0.470\n",
            "hidden128 Epoch 28 | Train loss 1.098 | Valid loss 1.096 | Valid acc 0.466\n",
            "hidden128 Epoch 29 | Train loss 1.097 | Valid loss 1.096 | Valid acc 0.470\n",
            "Test loss 1.096 | Test acc 0.438\n",
            "hidden128 Epoch 0 | Train loss 1.101 | Valid loss 1.100 | Valid acc 0.352\n",
            "hidden128 Epoch 1 | Train loss 1.101 | Valid loss 1.100 | Valid acc 0.354\n",
            "hidden128 Epoch 2 | Train loss 1.101 | Valid loss 1.099 | Valid acc 0.359\n",
            "hidden128 Epoch 3 | Train loss 1.101 | Valid loss 1.099 | Valid acc 0.366\n",
            "hidden128 Epoch 4 | Train loss 1.101 | Valid loss 1.099 | Valid acc 0.368\n",
            "hidden128 Epoch 5 | Train loss 1.100 | Valid loss 1.099 | Valid acc 0.371\n",
            "hidden128 Epoch 6 | Train loss 1.100 | Valid loss 1.099 | Valid acc 0.378\n",
            "hidden128 Epoch 7 | Train loss 1.100 | Valid loss 1.099 | Valid acc 0.383\n",
            "hidden128 Epoch 8 | Train loss 1.100 | Valid loss 1.099 | Valid acc 0.386\n",
            "hidden128 Epoch 9 | Train loss 1.100 | Valid loss 1.099 | Valid acc 0.386\n",
            "hidden128 Epoch 10 | Train loss 1.100 | Valid loss 1.099 | Valid acc 0.388\n",
            "hidden128 Epoch 11 | Train loss 1.100 | Valid loss 1.098 | Valid acc 0.386\n",
            "hidden128 Epoch 12 | Train loss 1.100 | Valid loss 1.098 | Valid acc 0.387\n",
            "hidden128 Epoch 13 | Train loss 1.099 | Valid loss 1.098 | Valid acc 0.391\n",
            "hidden128 Epoch 14 | Train loss 1.099 | Valid loss 1.098 | Valid acc 0.391\n",
            "hidden128 Epoch 15 | Train loss 1.099 | Valid loss 1.098 | Valid acc 0.391\n",
            "hidden128 Epoch 16 | Train loss 1.099 | Valid loss 1.098 | Valid acc 0.391\n",
            "hidden128 Epoch 17 | Train loss 1.099 | Valid loss 1.098 | Valid acc 0.391\n",
            "hidden128 Epoch 18 | Train loss 1.099 | Valid loss 1.098 | Valid acc 0.391\n",
            "hidden128 Epoch 19 | Train loss 1.099 | Valid loss 1.098 | Valid acc 0.391\n",
            "hidden128 Epoch 20 | Train loss 1.099 | Valid loss 1.098 | Valid acc 0.392\n",
            "hidden128 Epoch 21 | Train loss 1.099 | Valid loss 1.097 | Valid acc 0.391\n",
            "hidden128 Epoch 22 | Train loss 1.098 | Valid loss 1.097 | Valid acc 0.392\n",
            "hidden128 Epoch 23 | Train loss 1.098 | Valid loss 1.097 | Valid acc 0.393\n",
            "hidden128 Epoch 24 | Train loss 1.098 | Valid loss 1.097 | Valid acc 0.392\n",
            "hidden128 Epoch 25 | Train loss 1.098 | Valid loss 1.097 | Valid acc 0.392\n",
            "hidden128 Epoch 26 | Train loss 1.098 | Valid loss 1.097 | Valid acc 0.394\n",
            "hidden128 Epoch 27 | Train loss 1.098 | Valid loss 1.097 | Valid acc 0.395\n",
            "hidden128 Epoch 28 | Train loss 1.098 | Valid loss 1.097 | Valid acc 0.396\n",
            "hidden128 Epoch 29 | Train loss 1.098 | Valid loss 1.097 | Valid acc 0.397\n",
            "Test loss 1.096 | Test acc 0.405\n",
            "hidden256 Epoch 0 | Train loss 1.098 | Valid loss 1.100 | Valid acc 0.296\n",
            "hidden256 Epoch 1 | Train loss 1.098 | Valid loss 1.100 | Valid acc 0.302\n",
            "hidden256 Epoch 2 | Train loss 1.098 | Valid loss 1.099 | Valid acc 0.312\n",
            "hidden256 Epoch 3 | Train loss 1.098 | Valid loss 1.099 | Valid acc 0.316\n",
            "hidden256 Epoch 4 | Train loss 1.098 | Valid loss 1.099 | Valid acc 0.328\n",
            "hidden256 Epoch 5 | Train loss 1.097 | Valid loss 1.099 | Valid acc 0.334\n",
            "hidden256 Epoch 6 | Train loss 1.097 | Valid loss 1.099 | Valid acc 0.341\n",
            "hidden256 Epoch 7 | Train loss 1.097 | Valid loss 1.099 | Valid acc 0.352\n",
            "hidden256 Epoch 8 | Train loss 1.097 | Valid loss 1.099 | Valid acc 0.354\n",
            "hidden256 Epoch 9 | Train loss 1.097 | Valid loss 1.099 | Valid acc 0.359\n",
            "hidden256 Epoch 10 | Train loss 1.097 | Valid loss 1.099 | Valid acc 0.366\n",
            "hidden256 Epoch 11 | Train loss 1.097 | Valid loss 1.099 | Valid acc 0.368\n",
            "hidden256 Epoch 12 | Train loss 1.097 | Valid loss 1.098 | Valid acc 0.372\n",
            "hidden256 Epoch 13 | Train loss 1.097 | Valid loss 1.098 | Valid acc 0.376\n",
            "hidden256 Epoch 14 | Train loss 1.097 | Valid loss 1.098 | Valid acc 0.381\n",
            "hidden256 Epoch 15 | Train loss 1.096 | Valid loss 1.098 | Valid acc 0.385\n",
            "hidden256 Epoch 16 | Train loss 1.096 | Valid loss 1.098 | Valid acc 0.388\n",
            "hidden256 Epoch 17 | Train loss 1.096 | Valid loss 1.098 | Valid acc 0.391\n",
            "hidden256 Epoch 18 | Train loss 1.096 | Valid loss 1.098 | Valid acc 0.388\n",
            "hidden256 Epoch 19 | Train loss 1.096 | Valid loss 1.098 | Valid acc 0.389\n",
            "hidden256 Epoch 20 | Train loss 1.096 | Valid loss 1.098 | Valid acc 0.393\n",
            "hidden256 Epoch 21 | Train loss 1.096 | Valid loss 1.098 | Valid acc 0.395\n",
            "hidden256 Epoch 22 | Train loss 1.096 | Valid loss 1.098 | Valid acc 0.398\n",
            "hidden256 Epoch 23 | Train loss 1.096 | Valid loss 1.097 | Valid acc 0.399\n",
            "hidden256 Epoch 24 | Train loss 1.096 | Valid loss 1.097 | Valid acc 0.402\n",
            "hidden256 Epoch 25 | Train loss 1.095 | Valid loss 1.097 | Valid acc 0.402\n",
            "hidden256 Epoch 26 | Train loss 1.095 | Valid loss 1.097 | Valid acc 0.402\n",
            "hidden256 Epoch 27 | Train loss 1.095 | Valid loss 1.097 | Valid acc 0.401\n",
            "hidden256 Epoch 28 | Train loss 1.095 | Valid loss 1.097 | Valid acc 0.401\n",
            "hidden256 Epoch 29 | Train loss 1.095 | Valid loss 1.097 | Valid acc 0.401\n",
            "Test loss 1.097 | Test acc 0.409\n",
            "hidden256 Epoch 0 | Train loss 1.096 | Valid loss 1.099 | Valid acc 0.326\n",
            "hidden256 Epoch 1 | Train loss 1.096 | Valid loss 1.099 | Valid acc 0.328\n",
            "hidden256 Epoch 2 | Train loss 1.096 | Valid loss 1.099 | Valid acc 0.322\n",
            "hidden256 Epoch 3 | Train loss 1.096 | Valid loss 1.098 | Valid acc 0.324\n",
            "hidden256 Epoch 4 | Train loss 1.096 | Valid loss 1.098 | Valid acc 0.325\n",
            "hidden256 Epoch 5 | Train loss 1.096 | Valid loss 1.098 | Valid acc 0.325\n",
            "hidden256 Epoch 6 | Train loss 1.096 | Valid loss 1.098 | Valid acc 0.324\n",
            "hidden256 Epoch 7 | Train loss 1.095 | Valid loss 1.098 | Valid acc 0.322\n",
            "hidden256 Epoch 8 | Train loss 1.095 | Valid loss 1.098 | Valid acc 0.330\n",
            "hidden256 Epoch 9 | Train loss 1.095 | Valid loss 1.098 | Valid acc 0.330\n",
            "hidden256 Epoch 10 | Train loss 1.095 | Valid loss 1.098 | Valid acc 0.332\n",
            "hidden256 Epoch 11 | Train loss 1.095 | Valid loss 1.098 | Valid acc 0.327\n",
            "hidden256 Epoch 12 | Train loss 1.095 | Valid loss 1.098 | Valid acc 0.329\n",
            "hidden256 Epoch 13 | Train loss 1.095 | Valid loss 1.098 | Valid acc 0.326\n",
            "hidden256 Epoch 14 | Train loss 1.095 | Valid loss 1.097 | Valid acc 0.327\n",
            "hidden256 Epoch 15 | Train loss 1.095 | Valid loss 1.097 | Valid acc 0.330\n",
            "hidden256 Epoch 16 | Train loss 1.095 | Valid loss 1.097 | Valid acc 0.327\n",
            "hidden256 Epoch 17 | Train loss 1.094 | Valid loss 1.097 | Valid acc 0.330\n",
            "hidden256 Epoch 18 | Train loss 1.094 | Valid loss 1.097 | Valid acc 0.329\n",
            "hidden256 Epoch 19 | Train loss 1.094 | Valid loss 1.097 | Valid acc 0.328\n",
            "hidden256 Epoch 20 | Train loss 1.094 | Valid loss 1.097 | Valid acc 0.325\n",
            "hidden256 Epoch 21 | Train loss 1.094 | Valid loss 1.097 | Valid acc 0.323\n",
            "hidden256 Epoch 22 | Train loss 1.094 | Valid loss 1.097 | Valid acc 0.323\n",
            "hidden256 Epoch 23 | Train loss 1.094 | Valid loss 1.097 | Valid acc 0.323\n",
            "hidden256 Epoch 24 | Train loss 1.094 | Valid loss 1.097 | Valid acc 0.322\n",
            "hidden256 Epoch 25 | Train loss 1.094 | Valid loss 1.096 | Valid acc 0.325\n",
            "hidden256 Epoch 26 | Train loss 1.094 | Valid loss 1.096 | Valid acc 0.327\n",
            "hidden256 Epoch 27 | Train loss 1.094 | Valid loss 1.096 | Valid acc 0.329\n",
            "hidden256 Epoch 28 | Train loss 1.093 | Valid loss 1.096 | Valid acc 0.331\n",
            "hidden256 Epoch 29 | Train loss 1.093 | Valid loss 1.096 | Valid acc 0.332\n",
            "Test loss 1.098 | Test acc 0.353\n",
            "hidden256 Epoch 0 | Train loss 1.103 | Valid loss 1.106 | Valid acc 0.207\n",
            "hidden256 Epoch 1 | Train loss 1.102 | Valid loss 1.106 | Valid acc 0.207\n",
            "hidden256 Epoch 2 | Train loss 1.102 | Valid loss 1.105 | Valid acc 0.206\n",
            "hidden256 Epoch 3 | Train loss 1.102 | Valid loss 1.105 | Valid acc 0.206\n",
            "hidden256 Epoch 4 | Train loss 1.102 | Valid loss 1.105 | Valid acc 0.206\n",
            "hidden256 Epoch 5 | Train loss 1.102 | Valid loss 1.105 | Valid acc 0.206\n",
            "hidden256 Epoch 6 | Train loss 1.102 | Valid loss 1.105 | Valid acc 0.206\n",
            "hidden256 Epoch 7 | Train loss 1.102 | Valid loss 1.105 | Valid acc 0.206\n",
            "hidden256 Epoch 8 | Train loss 1.101 | Valid loss 1.105 | Valid acc 0.206\n",
            "hidden256 Epoch 9 | Train loss 1.101 | Valid loss 1.104 | Valid acc 0.206\n",
            "hidden256 Epoch 10 | Train loss 1.101 | Valid loss 1.104 | Valid acc 0.206\n",
            "hidden256 Epoch 11 | Train loss 1.101 | Valid loss 1.104 | Valid acc 0.206\n",
            "hidden256 Epoch 12 | Train loss 1.101 | Valid loss 1.104 | Valid acc 0.206\n",
            "hidden256 Epoch 13 | Train loss 1.101 | Valid loss 1.104 | Valid acc 0.207\n",
            "hidden256 Epoch 14 | Train loss 1.101 | Valid loss 1.104 | Valid acc 0.207\n",
            "hidden256 Epoch 15 | Train loss 1.101 | Valid loss 1.104 | Valid acc 0.206\n",
            "hidden256 Epoch 16 | Train loss 1.101 | Valid loss 1.104 | Valid acc 0.206\n",
            "hidden256 Epoch 17 | Train loss 1.100 | Valid loss 1.103 | Valid acc 0.207\n",
            "hidden256 Epoch 18 | Train loss 1.100 | Valid loss 1.103 | Valid acc 0.206\n",
            "hidden256 Epoch 19 | Train loss 1.100 | Valid loss 1.103 | Valid acc 0.209\n",
            "hidden256 Epoch 20 | Train loss 1.100 | Valid loss 1.103 | Valid acc 0.207\n",
            "hidden256 Epoch 21 | Train loss 1.100 | Valid loss 1.103 | Valid acc 0.212\n",
            "hidden256 Epoch 22 | Train loss 1.100 | Valid loss 1.103 | Valid acc 0.210\n",
            "hidden256 Epoch 23 | Train loss 1.100 | Valid loss 1.103 | Valid acc 0.211\n",
            "hidden256 Epoch 24 | Train loss 1.100 | Valid loss 1.103 | Valid acc 0.213\n",
            "hidden256 Epoch 25 | Train loss 1.099 | Valid loss 1.103 | Valid acc 0.216\n",
            "hidden256 Epoch 26 | Train loss 1.099 | Valid loss 1.102 | Valid acc 0.216\n",
            "hidden256 Epoch 27 | Train loss 1.099 | Valid loss 1.102 | Valid acc 0.219\n",
            "hidden256 Epoch 28 | Train loss 1.099 | Valid loss 1.102 | Valid acc 0.218\n",
            "hidden256 Epoch 29 | Train loss 1.099 | Valid loss 1.102 | Valid acc 0.220\n",
            "Test loss 1.104 | Test acc 0.184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fp2QC2Pzkja"
      },
      "source": [
        "- **Subtask 4-1: Completing the Table**\n",
        "\n",
        "Please write down the **validation accuracy** of your model under different model capacities (i.e., specified by the word embedding dimension and the hidden layer dimension).\n",
        "\n",
        "|Embedding dim / Hidden dim |  64  |  128  |  256 |\n",
        "|---------------------------|------|-------|------|\n",
        "| 64                        |  0.52    |    0.486   |  0.555    |\n",
        "| 128                       |  0.496    |    0.516   |   0.508   |\n",
        "| 256                       |  0. 518   |      0.540 |  0.572    |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY-OzP6E4JWU"
      },
      "source": [
        "- **Subtask 4-2: Answering the Question**\n",
        "\n",
        "Is it always better to increase model capacities in this case? Is it always better to increase model capacities in general? How to decide a proper model capacity in practice?\n",
        "\n",
        "*Your Answer:* In this case, it's not always better to increase model capacity. But we cannot  deny that increasing capacity does help the performance of model overall.A model that has insufficient capacity will lead to under-fitting. However, the larger the model, the more the number of intermediate layers and the more calculation parameters, which will cause a greater loss in computational efficiency. At the same time, if the model is too large, it will also cause the gradient vanishing and gradient explosion in the training phase, and the parameters are not easy to adjust.\n",
        "\n"
      ]
    }
  ]
}